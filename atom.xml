<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>知安</title>
  
  <subtitle>要么庸俗，要么孤独</subtitle>
  <link href="https://xin0203xin0203.github.io/atom.xml" rel="self"/>
  
  <link href="https://xin0203xin0203.github.io/"/>
  <updated>2024-12-19T01:34:51.000Z</updated>
  <id>https://xin0203xin0203.github.io/</id>
  
  <author>
    <name>知安</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>十四、Flink组件搭建之Scala环境搭建（一）</title>
    <link href="https://xin0203xin0203.github.io/posts/e7ef9c46.html"/>
    <id>https://xin0203xin0203.github.io/posts/e7ef9c46.html</id>
    <published>2023-12-18T15:31:57.214Z</published>
    <updated>2024-12-19T01:34:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-shapes modern"><p>介绍：<br>Scala 是一门多范式（multi-paradigm）的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。<br>Scala 运行在 Java 虚拟机上，并兼容现有的 Java 程序。<br>Scala 源代码被编译成 Java 字节码，所以它可以运行于 JVM 之上，并可以调用现有的 Java 类库。</p></div><div class="tip bolt"><p>参考文件：</p></div><p><a href="https://mp.weixin.qq.com/s?__biz=MzI4MDQzMzYyMg==&amp;mid=2247485228&amp;idx=1&amp;sn=a1924a0895d668ec77e9621cf1effa5e&amp;chksm=ebb9c195dcce4883e064380ee281c69c78c96b49bdcc075ee3fbd5c9930b83fd221bf5c50ccb&amp;scene=21#wechat_redirect">Scala环境搭建-视频教程</a></p><h1 id="一、Window-下搭建开发环境"><a href="#一、Window-下搭建开发环境" class="headerlink" title="一、Window 下搭建开发环境"></a>一、Window 下搭建开发环境</h1><h2 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h2><p>准保JDK8安装成功，并成功配置环境变量：<code>JAVA_HOME</code>, <code>Path</code><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673011843389-4846b1c8-c4cb-4be7-b65c-10469055d563.png#averageHue=%23f3f2f1&amp;clientId=uba40e7b7-93dd-4&amp;from=drop&amp;height=646&amp;id=u4e02822a&amp;originHeight=658&amp;originWidth=619&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=38675&amp;status=done&amp;style=none&amp;taskId=u35bf3c0f-ce93-4895-9d8f-4fe1b96bef3&amp;title=&amp;width=608" alt="640.png"></p><h2 id="2-下载"><a href="#2-下载" class="headerlink" title="2. 下载"></a>2. 下载</h2><p><a href="https://scala-lang.org/download/2.13.6.html"><strong>Scala 2.13.6</strong></a><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673016414858-05a93ae9-c025-4e90-87b5-440774854280.png#averageHue=%23fefefd&amp;clientId=uba40e7b7-93dd-4&amp;from=drop&amp;id=u601cab17&amp;originHeight=380&amp;originWidth=835&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=28497&amp;status=done&amp;style=none&amp;taskId=u164319eb-e29d-46fa-84eb-c413da3f9da&amp;title=" alt="a4f72964-ea59-49a0-900a-aacbc6874f89.png"></p><h2 id="3-解压"><a href="#3-解压" class="headerlink" title="3. 解压"></a>3. 解压</h2><p>解压到自己文件目录里，然后记住文件路径</p><h2 id="4-配置环境变量"><a href="#4-配置环境变量" class="headerlink" title="4. 配置环境变量"></a>4. 配置环境变量</h2><p>配置Scala 环境变量：<code>SCALA_HOME</code> 和 <code>Path</code><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673016561291-7edd584f-67b7-4f8b-8532-ef482bbcbd82.png#averageHue=%23f0efee&amp;clientId=uba40e7b7-93dd-4&amp;from=drop&amp;id=uf8ad1d69&amp;originHeight=666&amp;originWidth=644&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=35723&amp;status=done&amp;style=none&amp;taskId=u1a43a331-144b-4812-b0ea-64dc40ba3fc&amp;title=" alt="1.PNG"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673016565697-9609aadb-67c0-4cf9-95e6-a391bb240e63.png#averageHue=%23f3f2f0&amp;clientId=uba40e7b7-93dd-4&amp;from=drop&amp;height=677&amp;id=ud3448b0f&amp;originHeight=564&amp;originWidth=527&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=23818&amp;status=done&amp;style=none&amp;taskId=u21f88428-4131-4f12-9582-eaa70397d3e&amp;title=&amp;width=633" alt="2.PNG"></p><h2 id="5-验证安装是否成功"><a href="#5-验证安装是否成功" class="headerlink" title="5. 验证安装是否成功"></a>5. 验证安装是否成功</h2><p>按下键盘的Win+R后，输入cmd回车，输入Scala，如果能进入 <code>Scala</code> 交互环境，则代表安装成功：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673016633239-0f47e29d-223b-4f1b-bbb1-4f8cc114a582.png#averageHue=%231f1f1f&amp;clientId=uba40e7b7-93dd-4&amp;from=drop&amp;id=u2fffa6fb&amp;originHeight=512&amp;originWidth=979&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=11087&amp;status=done&amp;style=none&amp;taskId=uf6b631da-cb0e-4aae-8527-442bbcc6a24&amp;title=" alt="3.PNG"></p><h1 id="二、Linux-下搭建开发环境"><a href="#二、Linux-下搭建开发环境" class="headerlink" title="二、Linux 下搭建开发环境"></a>二、Linux 下搭建开发环境</h1><h2 id="1-JDK环境准备"><a href="#1-JDK环境准备" class="headerlink" title="1. JDK环境准备"></a>1. JDK环境准备</h2><p><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed&amp;inner=pYJji">一、集群环境搭建高可用版本配置</a></p><h2 id="2-下载解压并改名"><a href="#2-下载解压并改名" class="headerlink" title="2. 下载解压并改名"></a>2. 下载解压并改名</h2><p><strong><a href="https://scala-lang.org/download/2.13.6.html">Scala</a>压缩包——&gt;scala-2.13.6.tgz</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf scala-<span class="number">2.13</span><span class="number">.6</span>.tgz </span><br><span class="line">mv scala-<span class="number">2.13</span><span class="number">.6</span>.tgz scala</span><br></pre></td></tr></table></figure></p><h2 id="3-配置环境变量"><a href="#3-配置环境变量" class="headerlink" title="3. 配置环境变量"></a>3. 配置环境变量</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"># 添加以下内容</span><br><span class="line">export SCALA_HOME=/opt/scala</span><br><span class="line">export PATH=$PATH:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure><h2 id="4-更新环境变量"><a href="#4-更新环境变量" class="headerlink" title="4. 更新环境变量"></a>4. 更新环境变量</h2><p>使得配置的环境变量立即生效：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><h2 id="5-验证安装是否成功-1"><a href="#5-验证安装是否成功-1" class="headerlink" title="5. 验证安装是否成功"></a>5. 验证安装是否成功</h2><p>输入<code>scala</code>，如果能进入 Scala 交互环境，则代表安装成功<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673018721033-ce50cbd6-bfe5-4629-8218-a71f7b76c292.png#averageHue=%23040302&amp;clientId=uba40e7b7-93dd-4&amp;from=drop&amp;height=184&amp;id=u3d69efc6&amp;originHeight=142&amp;originWidth=580&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=6318&amp;status=done&amp;style=none&amp;taskId=u204acc93-09a7-44da-b777-607ab3b0a53&amp;title=&amp;width=750" alt="捕获.PNG"></p><h1 id="三、Scala-的Hello-world-案例"><a href="#三、Scala-的Hello-world-案例" class="headerlink" title="三、Scala 的Hello world 案例"></a>三、Scala 的Hello world 案例</h1><h2 id="1-创建一个Maven工程"><a href="#1-创建一个Maven工程" class="headerlink" title="1. 创建一个Maven工程"></a>1. 创建一个Maven工程</h2><p>参考文件：<br><a href="https://www.yuque.com/yuqueyonghub89qji/whl8ua/yf1fllg7ivf7yv8h?view=doc_embed">1. 安装指南</a></p><h2 id="2-引入依赖"><a href="#2-引入依赖" class="headerlink" title="2. 引入依赖"></a>2. 引入依赖</h2><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">flink.version</span>&gt;</span>1.13.0<span class="tag">&lt;/<span class="name">flink.version</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">target.java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target.java.version</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">scala.binary.version</span>&gt;</span>2.12<span class="tag">&lt;/<span class="name">scala.binary.version</span>&gt;</span></span></span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-scala_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-scala_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span></span><br></pre></td></tr></table></figure><p>等待下载。。。</p><h2 id="3-创建项目的源文件目录"><a href="#3-创建项目的源文件目录" class="headerlink" title="3. 创建项目的源文件目录"></a>3. 创建项目的源文件目录</h2><p>在 <code>main</code> 下创建一个文件夹作为 <code>scala</code> 源文件的根目录, 比如目录名: <code>scala</code>, 然后标记为源文件根目录<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673021063073-07077ee0-2d43-430d-a92b-9374277fb831.png#averageHue=%232e3845&amp;clientId=u530254e3-1a9c-4&amp;from=drop&amp;height=317&amp;id=u7707aaef&amp;originHeight=187&amp;originWidth=267&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=37568&amp;status=done&amp;style=none&amp;taskId=u646fb508-f4aa-483a-a73d-87cb501b44d&amp;title=&amp;width=452" alt="2.PNG"></p><h2 id="4-下载scala组件工具"><a href="#4-下载scala组件工具" class="headerlink" title="4. 下载scala组件工具"></a>4. 下载scala组件工具</h2><p><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673021159509-c8a99853-1cc3-4099-bdfd-01af3638d40a.png#averageHue=%23383c41&amp;clientId=u530254e3-1a9c-4&amp;from=drop&amp;id=uc13fd20c&amp;originHeight=713&amp;originWidth=983&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=68470&amp;status=done&amp;style=none&amp;taskId=u42330566-902f-4c38-bd3e-5340c16d192&amp;title=" alt="1.PNG"></p><h2 id="5-引入scala组件工具"><a href="#5-引入scala组件工具" class="headerlink" title="5. 引入scala组件工具"></a>5. 引入scala组件工具</h2><p><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673021205156-8b1d9962-75c4-4bce-9ee1-f4776c920f07.png#averageHue=%233d444a&amp;clientId=u530254e3-1a9c-4&amp;from=drop&amp;height=663&amp;id=uac9a82b4&amp;originHeight=714&amp;originWidth=515&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=202908&amp;status=done&amp;style=none&amp;taskId=u8ec6da13-d142-4ef1-8f72-e32d0bc6d27&amp;title=&amp;width=478" alt="1a4e41ef43002d13b72f0549a388e90.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673021246301-55cb56ce-b859-4550-a120-95ae118860b2.png#averageHue=%233c4043&amp;clientId=u530254e3-1a9c-4&amp;from=drop&amp;height=472&amp;id=ud49d66c8&amp;originHeight=638&amp;originWidth=647&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=31065&amp;status=done&amp;style=none&amp;taskId=u7342fa3a-b7f5-422e-a79f-b5f2d17d668&amp;title=&amp;width=479" alt="3.PNG"></p><h2 id="4-创建Scala-的类"><a href="#4-创建Scala-的类" class="headerlink" title="4. 创建Scala 的类"></a>4. 创建Scala 的类</h2><p><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673021113873-f049a220-9fb7-4384-99bd-5bfc8d7f2642.png#averageHue=%23404853&amp;clientId=u530254e3-1a9c-4&amp;from=drop&amp;height=263&amp;id=udd682feb&amp;originHeight=182&amp;originWidth=334&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=6098&amp;status=done&amp;style=none&amp;taskId=uf543e95b-2cb2-44bb-8f73-5513165470c&amp;title=&amp;width=483" alt="捕获.PNG"></p><h2 id="5-编写程序"><a href="#5-编写程序" class="headerlink" title="5. 编写程序"></a>5. 编写程序</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">object HelloWorld &#123;</span><br><span class="line">  def <span class="title function_">main</span><span class="params">(args:Array[String])</span>:Unit = &#123;</span><br><span class="line">    println(<span class="string">&quot;Hello Scala&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="6-运行"><a href="#6-运行" class="headerlink" title="6. 运行"></a>6. 运行</h2><p><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673021039738-b7f90108-b0e4-4ee2-82a1-c29441689e02.png#averageHue=%232f3a49&amp;clientId=u530254e3-1a9c-4&amp;from=drop&amp;height=214&amp;id=ub60b93f2&amp;originHeight=195&amp;originWidth=679&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=149050&amp;status=done&amp;style=none&amp;taskId=u5b2c1696-edeb-4dcd-906b-3705d5a69c1&amp;title=&amp;width=746" alt="捕获.PNG"></p><h1 id="拓展统计单词计算"><a href="#拓展统计单词计算" class="headerlink" title="拓展统计单词计算"></a>拓展统计单词计算</h1><p><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673024696331-315de340-84e1-4214-ae34-abbc1d8179d8.png#averageHue=%23353f4b&amp;clientId=u530254e3-1a9c-4&amp;from=drop&amp;id=uf9d1fe06&amp;originHeight=350&amp;originWidth=243&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=89792&amp;status=done&amp;style=none&amp;taskId=u1f79d7a4-ae70-438e-aac6-bda8020210a&amp;title=" alt="捕获.PNG"></p><h2 id="1-准备数据"><a href="#1-准备数据" class="headerlink" title="1. 准备数据"></a>1. 准备数据</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hello python</span><br><span class="line">hello scala</span><br><span class="line">hello java</span><br><span class="line">hello hadoop</span><br><span class="line">hello word</span><br><span class="line">hello spark</span><br></pre></td></tr></table></figure><h2 id="2-编写程序"><a href="#2-编写程序" class="headerlink" title="2. 编写程序"></a>2. 编写程序</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.com</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala.&#123;ExecutionEnvironment, createTypeInformation&#125;</span><br><span class="line"></span><br><span class="line">object BatchWordCount &#123;</span><br><span class="line">  def <span class="title function_">main</span><span class="params">(args: Array[String])</span>: Unit = &#123;</span><br><span class="line">    <span class="comment">// 1. 创建一个执行环境</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">env</span> <span class="operator">=</span> ExecutionEnvironment.getExecutionEnvironment</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 2. 读取文本文件数据</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">lineDataSet</span> <span class="operator">=</span> env.readTextFile(<span class="string">&quot;input/test.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 对数据集中进行转换处理</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">wordAndOne</span> <span class="operator">=</span> lineDataSet.flatMap(_.split(<span class="string">&quot; &quot;</span>)).map(word=&gt;(word, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 按照单词进行分组</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">wordAndOneGroup</span> <span class="operator">=</span> wordAndOne.groupBy(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5. 对分组数据进行sum聚合统计</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">sum</span> <span class="operator">=</span> wordAndOneGroup.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 6. 打印</span></span><br><span class="line">    sum.print()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="报错提醒"><a href="#报错提醒" class="headerlink" title="报错提醒"></a>报错提醒</h2><h3 id="报错原因：由于scala的版本不对"><a href="#报错原因：由于scala的版本不对" class="headerlink" title="报错原因：由于scala的版本不对"></a><strong>报错原因：</strong>由于scala的版本不对</h3><p><code>Error:scalac: Error: scala.collection.mutable.Set$.apply(Lscala/collection/Seq；)</code><br>解决方案：<br><a href="https://blog.csdn.net/Miraitowa_Neo/article/details/123232229">Error:scalac: Error: scala.collection.mutable.Set$.apply(Lscala/collection/Seq；)_编不出代码的女程序员的博客-CSDN博客_lscala/collection/seq</a></p><h3 id="报错原因：java与scala的版本冲突导致"><a href="#报错原因：java与scala的版本冲突导致" class="headerlink" title="**报错原因：java与scala的版本冲突导致"></a>**报错原因：java与<a href="https://so.csdn.net/so/search?q=scala&amp;spm=1001.2101.3001.7020">scala</a>的版本冲突导致</h3><p>解决方案：<br><a href="https://blog.csdn.net/miaohui8023/article/details/105327734">Error:scalac: error while loading package, Scala signature package has wrong version_miaohui8023的博客-CSDN博客</a></p><h2 id="3-运行结果"><a href="#3-运行结果" class="headerlink" title="3. 运行结果"></a>3. 运行结果</h2><p><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1673024619752-3ba0946b-3931-44f5-ab63-a51384fca7ae.png#averageHue=%232f3d4d&amp;clientId=u530254e3-1a9c-4&amp;from=drop&amp;id=u565ec8cd&amp;originHeight=267&amp;originWidth=821&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=281691&amp;status=done&amp;style=none&amp;taskId=u454a3ad7-588a-4512-9570-9e831f3a317&amp;title=" alt="捕获.PNG"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-shapes modern&quot;&gt;&lt;p&gt;介绍：&lt;br&gt;Scala 是一门多范式（multi-paradigm）的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。&lt;br&gt;Sca</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://xin0203xin0203.github.io/posts/0.html"/>
    <id>https://xin0203xin0203.github.io/posts/0.html</id>
    <published>2023-12-18T15:31:57.200Z</published>
    <updated>2023-12-19T01:35:12.535Z</updated>
    
    <content type="html"><![CDATA[<p>前置准备：<br><a href="https://www.yuque.com/u25360462/nt1ri1/kusqdo?view=doc_embed">一、集群环境搭建高可用版本配置</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/ifi3zw34ztgm4bqt?view=doc_embed">（一）Scala环境搭建</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/fbyk58l02whdr677?view=doc_embed">(二) Flink集群环境搭建(Local模式)</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/dxmlft2waa775lkm?view=doc_embed">(三) Flink集群环境搭建(Standalone模式)</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/lne7tfikcbvkww26?view=doc_embed">(四) HA-Flink集群环境搭建(Standalone模式)</a><br>需要的安装包：<a href="https://archive.apache.org/dist/flink/">flink</a>压缩包——&gt;flink-1.13.0-bin-scala_2.12.tgz</p><h1 id="HA-Yarn模式"><a href="#HA-Yarn模式" class="headerlink" title="HA-Yarn模式"></a>HA-Yarn模式</h1><h3 id="1-1-修改集群配置"><a href="#1-1-修改集群配置" class="headerlink" title="1.1 修改集群配置"></a>1.1 修改集群配置</h3><h4 id="1-1-1-vim-HADOOP-HOME-etc-hadoop-yarn-site-xml"><a href="#1-1-1-vim-HADOOP-HOME-etc-hadoop-yarn-site-xml" class="headerlink" title="1.1.1 vim $HADOOP_HOME/etc/hadoop/yarn-site.xml"></a>1.1.1 vim $HADOOP_HOME/etc/hadoop/yarn-site.xml</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--关闭yarn的内存检查--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.am.max-attempts&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="number">4</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h4 id="1-1-2-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件"><a href="#1-1-2-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件" class="headerlink" title="1.1.2 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件"></a>1.1.2 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#配置Flink的主节点</span><br><span class="line">jobmanager.rpc.address: master</span><br><span class="line"># 配置使用zookeeper来开启高可用模式</span><br><span class="line">high-availability: zookeeper</span><br><span class="line"># 配置zookeeper的地址，采用zookeeper集群时，可以使用逗号来分隔多个节点地址</span><br><span class="line">high-availability.zookeeper.quorum: master:<span class="number">2181</span>,slave1:<span class="number">2181</span>,slave2:<span class="number">2181</span></span><br><span class="line"># 在zookeeper上存储flink集群元信息的路径</span><br><span class="line">high-availability.zookeeper.path.root: /ha-flink</span><br><span class="line"># 持久化存储JobManager元数据的地址，zookeeper上存储的只是指向该元数据的指针信息</span><br><span class="line">high-availability.storageDir: hdfs:<span class="comment">//hacluster:8020/flink/recovery</span></span><br><span class="line">#（hacluster与HAHadoop中的core-site.xml里的hadoop集群在zookeeper上注册的节点名一致）</span><br><span class="line"># 将已完成的作业上传到此目录中，让任务历史服务器进行监控</span><br><span class="line">jobmanager.archive.fs.dir: hdfs:<span class="comment">//hacluster:8020/flink-jobhistory</span></span><br><span class="line">historyserver.web.address: master</span><br><span class="line">historyserver.web.port: <span class="number">18082</span></span><br><span class="line"># 任务历史服务器监控目录中已存档的作业</span><br><span class="line">historyserver.archive.fs.dir: hdfs:<span class="comment">//hacluster:8020/flink-jobhistory</span></span><br><span class="line">historyserver.web.refresh-interval: <span class="number">10000</span></span><br><span class="line">#比StandAlone模式多了</span><br><span class="line">yarn.application-attempts: <span class="number">10</span></span><br></pre></td></tr></table></figure><p>除了上面的配置之外，Flink 还可以使用以下可选参数来优化集群性能：</p><ul><li><strong>jobmanager.heap.size</strong>：JobManager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.heap.size</strong>：Taskmanager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.numberOfTaskSlots</strong>：Taskmanager 上 slots 的数量，通常设置为 CPU 核心的数量，或其一半。</li><li><strong>parallelism.default</strong>：任务默认的并行度。</li><li><strong>io.tmp.dirs</strong>：存储临时文件的路径，如果没有配置，则默认采用服务器的临时目录，如 LInux 的 /tmp 目录。<h4 id="1-1-3-修改-masters-文件，指定JobManager节点"><a href="#1-1-3-修改-masters-文件，指定JobManager节点" class="headerlink" title="1.1.3 修改 masters 文件，指定JobManager节点"></a>1.1.3 修改 masters 文件，指定JobManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">master:<span class="number">8081</span></span><br><span class="line">slave1:<span class="number">8081</span></span><br></pre></td></tr></table></figure><h4 id="1-1-4-修改-slaves（workers）-文件，添加TaskManager节点"><a href="#1-1-4-修改-slaves（workers）-文件，添加TaskManager节点" class="headerlink" title="1.1.4 修改 slaves（workers） 文件，添加TaskManager节点"></a>1.1.4 修改 slaves（workers） 文件，添加TaskManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-2-导入Flink依赖flink-shaded-hadoop包到Flink-lib中去（各个节点Flink的lib）"><a href="#1-2-导入Flink依赖flink-shaded-hadoop包到Flink-lib中去（各个节点Flink的lib）" class="headerlink" title="1.2 导入Flink依赖flink-shaded-hadoop包到Flink/lib中去（各个节点Flink的lib）"></a>1.2 导入Flink依赖<strong>flink-shaded-hadoop</strong>包到Flink/lib中去（各个节点Flink的lib）</h3><strong>将文件下载本地，再将文件的后缀篡改为jar，在上传群集文件当中（.txt—&gt;.jar）</strong><br><a href="https://www.yuque.com/attachments/yuque/0/2023/txt/33576317/1676461700287-df65f88c-00ec-4a79-9a33-83f71af0a1d4.txt">flink-shaded-hadoop-2-uber-2.8.3-10.0.txt</a><h3 id="1-3-分发Flink给其他节点"><a href="#1-3-分发Flink给其他节点" class="headerlink" title="1.3 分发Flink给其他节点"></a>1.3 分发Flink给其他节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r $FLINK_HOME/ slave1:/opt/</span><br><span class="line">scp -r $FLINK_HOME/ slave2:/opt/</span><br></pre></td></tr></table></figure><h3 id="1-4-在HDFS上创建HIstory目录"><a href="#1-4-在HDFS上创建HIstory目录" class="headerlink" title="1.4 在HDFS上创建HIstory目录"></a>1.4 在<strong>HDFS</strong>上<strong>创建</strong>HIstory目录</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /flink</span><br><span class="line">hdfs dfs -mkdir /flink/recovery</span><br><span class="line">hdfs dfs -mkdir /flink-jobhistory</span><br><span class="line">hdfs dfs -chmod <span class="number">777</span> /flink-jobhistory</span><br></pre></td></tr></table></figure><h3 id="1-5-启动"><a href="#1-5-启动" class="headerlink" title="1.5 启动"></a>1.5 启动</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 启动HAHadoop集群</span><br><span class="line">[huser@master ~]$ ./opt/bin/start-dfs.sh--&gt;  <span class="string">&#x27;脚本启动&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-6-启动Flink集群和任务历史服务器"><a href="#1-6-启动Flink集群和任务历史服务器" class="headerlink" title="1.6 启动Flink集群和任务历史服务器"></a>1.6 启动Flink集群和任务历史服务器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[huser@master ~]$ start-cluster.sh</span><br><span class="line">[huser@master ~]$ historyserver.sh start</span><br><span class="line"><span class="meta">#jps</span></span><br><span class="line">#主节点多出:</span><br><span class="line"><span class="number">3835</span> StandaloneSessionClusterEntrypoint</span><br><span class="line"><span class="number">4148</span> TaskManagerRunner</span><br><span class="line">#其他节点多出：</span><br><span class="line"><span class="number">3437</span> TaskManagerRunner</span><br></pre></td></tr></table></figure><h3 id="1-7-查看web端"><a href="#1-7-查看web端" class="headerlink" title="1.7 查看web端"></a>1.7 查看web端</h3>两个 JobManager 和 任务历史服务器的端口号分别为 8081 、8081和 18082，界面应该如下：<br>访问 <a href="http://192.168.33.151:8081">http://192.168.33.151:8081</a>或<a href="http://192.168.33.150:8081">http://192.168.33.150:8081</a>,<a href="http://192.168.33.150:18082">http://192.168.33.150:18082</a><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676462763256-60f6f434-cf8b-4065-8e83-f49cfad24db3.png#averageHue=%23fbfbfa&amp;clientId=uec47b960-6911-4&amp;from=ui&amp;id=ucb39e37d&amp;originHeight=853&amp;originWidth=1808&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=62330&amp;status=done&amp;style=none&amp;taskId=ua48356e6-5943-428f-a62c-3717ed19ef3&amp;title=" alt="Snipaste_2023-02-15_20-05-43.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676462802475-5f2887ba-1976-4ad7-8d4a-6e21a1f57011.png#averageHue=%23fbfafa&amp;clientId=uec47b960-6911-4&amp;from=ui&amp;id=udae1af25&amp;originHeight=911&amp;originWidth=1822&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61825&amp;status=done&amp;style=none&amp;taskId=u2de4e3f7-1d47-4151-8e66-8a17e380ea6&amp;title=" alt="Snipaste_2023-02-15_20-05-43.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676462828392-4bbb4a02-c0bb-4afb-814e-57172f10371c.png#averageHue=%23fbfbfb&amp;clientId=uec47b960-6911-4&amp;from=ui&amp;id=u79f7325e&amp;originHeight=842&amp;originWidth=1822&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=57209&amp;status=done&amp;style=none&amp;taskId=u75a6e051-3847-4852-9169-4dcc78f3044&amp;title=" alt="Snipaste_2023-02-15_20-05-43.png"><h3 id="1-8-HA测试"><a href="#1-8-HA测试" class="headerlink" title="1.8 HA测试"></a>1.8 HA测试</h3>注意：在测试的时候，内存先调大，推荐3G内存执行任务；另外，就是网页端无法进去的情况，修改系统文件中System32/drivers/etc/hosts，调整网络IP和虚拟机的用户名是否对准，或者有没有重复的。<br><strong>流计算词频统计案例源码：</strong><br><strong>将文件下载本地，再将文件的后缀篡改为jar，在上传群集文件当中（.txt—&gt;.jar）</strong><br><a href="https://www.yuque.com/attachments/yuque/0/2023/txt/33576317/1676461700284-5c77fac5-f291-43f5-85b2-d06bd0185868.txt">flink_scala-1.0-SNAPSHOT.txt</a><br>提交作业：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.</span>虚拟机内开启端口</span><br><span class="line">[huser@master ~]$ nc -lk <span class="number">5555</span></span><br><span class="line"># <span class="number">2.</span>运行Flink的Jar包</span><br><span class="line">flink run -m yarn-cluster -ys <span class="number">1</span> -c cs -d flink_scala<span class="number">-1.0</span>-SNAPSHOT.jar master <span class="number">5555</span></span><br><span class="line"></span><br><span class="line">注意：这个时候我们使用flink run的时候，它会默认找这个文件，然后根据这个文件找到刚才我们创建的那个永久的Flink集群，这个文件里面保存的就是刚才启动的那个Flink集群在YARN中对应的applicationid</span><br><span class="line"></span><br><span class="line">#两个master节点随便一个会多出Yarnjob服务</span><br><span class="line"><span class="number">26696</span> YarnJobClusterEntrypoint</span><br><span class="line">#进去<span class="number">8088</span>网页会发现有新的任务</span><br><span class="line">#进度条后面有一个ApplocationMaster点击</span><br><span class="line">#然后就会进入了Flink的Job页面</span><br><span class="line"></span><br><span class="line">#找出哪个master节点有YarnJobClusterEntrypoint服务然后Kill掉一个</span><br><span class="line">kill <span class="number">-9</span> YarnJobClusterEntrypoint服务端口</span><br><span class="line">#重新进入刚刚的FlinkWeb页端</span><br><span class="line">会跳回<span class="number">8088</span>端口</span><br><span class="line">#然后查看另一个master </span><br><span class="line">jps</span><br><span class="line">#是否出现</span><br><span class="line">YarnJobClusterEntrypoint服务</span><br><span class="line">#然后再点击进度条后面的ApplocationMaster就可以重新进入Flink另一个master的JOb端</span><br></pre></td></tr></table></figure>访问端口<a href="http://192.168.33.152:8088(例">http://192.168.33.152:8088(例</a>)<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676469906270-ced64677-e0ae-4bc9-a594-cc443c23c7a0.png#averageHue=%23ddba7c&amp;clientId=u81e4375d-ee9d-4&amp;from=ui&amp;id=udd521d76&amp;originHeight=1000&amp;originWidth=1802&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=164598&amp;status=done&amp;style=none&amp;taskId=u6708cd0e-3383-4b18-8d9f-2c70fe6fb59&amp;title=" alt="Snipaste_2023-02-15_22-03-23.png"><br>往下操作<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676469938570-518c852e-5b6f-495a-ade0-79800a9cc9c8.png#averageHue=%23faf9f9&amp;clientId=u81e4375d-ee9d-4&amp;from=ui&amp;id=u9536f47d&amp;originHeight=1002&amp;originWidth=1824&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=62352&amp;status=done&amp;style=none&amp;taskId=u694d9db8-2423-49cd-accc-89cbf4e3a7b&amp;title=" alt="Snipaste_2023-02-15_22-03-42.png"><br>运行过程中将正在服务的JobManager给kill掉，测试是否高可用<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill <span class="number">-9</span> YarnJobClusterEntrypoint服务端口</span><br></pre></td></tr></table></figure>此时hadoop01的8081无法访问，hadoop02会进行接管（重新提交刚才被中断的作业），这个过程需要稍等一会儿<br>再次输入数据后可以从结果看出是一个新作业：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676469951148-7e863fc8-edda-47a5-9d45-7cfbe4cda616.png#averageHue=%231b1917&amp;clientId=u81e4375d-ee9d-4&amp;from=ui&amp;id=u6550542b&amp;originHeight=860&amp;originWidth=1147&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=105446&amp;status=done&amp;style=none&amp;taskId=ud7aa2ebb-2161-4e7e-9a55-892ff2c7619&amp;title=" alt="Snipaste_2023-02-15_22-04-27.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676469959235-bce2fe1d-a20d-4934-8edb-e133093befb3.png#averageHue=%23fbfbfa&amp;clientId=u81e4375d-ee9d-4&amp;from=ui&amp;id=ud6d253e2&amp;originHeight=345&amp;originWidth=962&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=21993&amp;status=done&amp;style=none&amp;taskId=u8ec83d57-9a06-4232-8602-8190f603704&amp;title=" alt="Snipaste_2023-02-15_22-04-39.png"><br>结束任务后可以在任务历史服务器WebUI中进行查看：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676461674361-59a57d45-997a-4181-8249-fa9c64733ece.png#averageHue=%23fbfbfa&amp;clientId=ua26ddcb6-7483-4&amp;from=paste&amp;height=200&amp;id=uf77f14ca&amp;originHeight=207&amp;originWidth=1556&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=13833&amp;status=done&amp;style=none&amp;taskId=ub4d7bf44-3575-4f2b-880c-e04aabc0198&amp;title=&amp;width=1504" alt="image.png"><h3 id="1-9-关闭命令"><a href="#1-9-关闭命令" class="headerlink" title="1.9 关闭命令"></a>1.9 关闭命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前置准备：&lt;br&gt;&lt;a href=&quot;https://www.yuque.com/u25360462/nt1ri1/kusqdo?view=doc_embed&quot;&gt;一、集群环境搭建高可用版本配置&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.yuque.com/yuq</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://xin0203xin0203.github.io/posts/0.html"/>
    <id>https://xin0203xin0203.github.io/posts/0.html</id>
    <published>2023-12-18T15:31:57.182Z</published>
    <updated>2023-12-19T01:35:12.535Z</updated>
    
    <content type="html"><![CDATA[<p>前置准备：<br><a href="https://www.yuque.com/u25360462/nt1ri1/kusqdo?view=doc_embed">一、集群环境搭建高可用版本配置</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/ifi3zw34ztgm4bqt?view=doc_embed">（一）Scala环境搭建</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/fbyk58l02whdr677?view=doc_embed">(二) Flink集群环境搭建(Local模式)</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/dxmlft2waa775lkm?view=doc_embed">(三) Flink集群环境搭建(Standalone模式)</a><br>需要的安装包：<a href="https://archive.apache.org/dist/flink/">flink</a>压缩包——&gt;flink-1.13.0-bin-scala_2.12.tgz</p><h1 id="HA-StandAlone模式"><a href="#HA-StandAlone模式" class="headerlink" title="HA-StandAlone模式"></a>HA-StandAlone模式</h1><h3 id="1-1-修改集群配置"><a href="#1-1-修改集群配置" class="headerlink" title="1.1 修改集群配置"></a>1.1 修改集群配置</h3><h4 id="1-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件"><a href="#1-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件" class="headerlink" title="1.1.1 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件"></a>1.1.1 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#配置Flink的主节点</span><br><span class="line">jobmanager.rpc.address: master</span><br><span class="line"># 配置使用zookeeper来开启高可用模式</span><br><span class="line">high-availability: zookeeper</span><br><span class="line"># 配置zookeeper的地址，采用zookeeper集群时，可以使用逗号来分隔多个节点地址</span><br><span class="line">high-availability.zookeeper.quorum: master:<span class="number">2181</span>,slave1:<span class="number">2181</span>,slave2:<span class="number">2181</span></span><br><span class="line"># 在zookeeper上存储flink集群元信息的路径</span><br><span class="line">high-availability.zookeeper.path.root: /ha-flink</span><br><span class="line"># 持久化存储JobManager元数据的地址，zookeeper上存储的只是指向该元数据的指针信息</span><br><span class="line">high-availability.storageDir: hdfs:<span class="comment">//hacluster:8020/flink/recovery</span></span><br><span class="line">#（hacluster与HAHadoop中的core-site.xml里的hadoop集群在zookeeper上注册的节点名一致）</span><br><span class="line"># 将已完成的作业上传到此目录中，让任务历史服务器进行监控</span><br><span class="line">jobmanager.archive.fs.dir: hdfs:<span class="comment">//hacluster:8020/flink-jobhistory</span></span><br><span class="line">historyserver.web.address: master</span><br><span class="line">historyserver.web.port: <span class="number">18082</span></span><br><span class="line"># 任务历史服务器监控目录中已存档的作业</span><br><span class="line">historyserver.archive.fs.dir: hdfs:<span class="comment">//hacluster:8020/flink-jobhistory</span></span><br><span class="line">historyserver.web.refresh-interval: <span class="number">10000</span></span><br></pre></td></tr></table></figure><p>除了上面的配置之外，Flink 还可以使用以下可选参数来优化集群性能：</p><ul><li><strong>jobmanager.heap.size</strong>：JobManager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.heap.size</strong>：Taskmanager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.numberOfTaskSlots</strong>：Taskmanager 上 slots 的数量，通常设置为 CPU 核心的数量，或其一半。</li><li><strong>parallelism.default</strong>：任务默认的并行度。</li><li><strong>io.tmp.dirs</strong>：存储临时文件的路径，如果没有配置，则默认采用服务器的临时目录，如 LInux 的 /tmp 目录。<h4 id="1-1-2-修改-masters-文件，指定JobManager节点"><a href="#1-1-2-修改-masters-文件，指定JobManager节点" class="headerlink" title="1.1.2 修改 masters 文件，指定JobManager节点"></a>1.1.2 修改 masters 文件，指定JobManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">master:<span class="number">8081</span></span><br><span class="line">slave1:<span class="number">8081</span></span><br></pre></td></tr></table></figure><h4 id="1-1-3-修改-slaves（workers）-文件，添加TaskManager节点"><a href="#1-1-3-修改-slaves（workers）-文件，添加TaskManager节点" class="headerlink" title="1.1.3 修改 slaves（workers） 文件，添加TaskManager节点"></a>1.1.3 修改 slaves（workers） 文件，添加TaskManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-2-导入Flink依赖flink-shaded-hadoop包到Flink-lib中去（各个节点Flink的lib）"><a href="#1-2-导入Flink依赖flink-shaded-hadoop包到Flink-lib中去（各个节点Flink的lib）" class="headerlink" title="1.2 导入Flink依赖flink-shaded-hadoop包到Flink/lib中去（各个节点Flink的lib）"></a>1.2 导入Flink依赖<strong>flink-shaded-hadoop</strong>包到Flink/lib中去（各个节点Flink的lib）</h3><strong>将文件下载本地，再将文件的后缀篡改为jar，在上传群集文件当中（.txt—&gt;.jar）</strong><br><a href="https://www.yuque.com/attachments/yuque/0/2023/txt/33576317/1676461093792-9afc6989-aa00-46ce-aebc-2578461d1c97.txt">flink-shaded-hadoop-2-uber-2.8.3-10.0.txt</a><h3 id="1-3-分发Flink给其他节点"><a href="#1-3-分发Flink给其他节点" class="headerlink" title="1.3 分发Flink给其他节点"></a>1.3 分发Flink给其他节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r $FLINK_HOME/ slave1:/opt/</span><br><span class="line">scp -r $FLINK_HOME/ slave2:/opt/</span><br></pre></td></tr></table></figure><h3 id="1-4-在HDFS上创建HIstory目录"><a href="#1-4-在HDFS上创建HIstory目录" class="headerlink" title="1.4 在HDFS上创建HIstory目录"></a>1.4 在<strong>HDFS</strong>上<strong>创建</strong>HIstory目录</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /flink</span><br><span class="line">hdfs dfs -mkdir /flink/recovery</span><br><span class="line">hdfs dfs -mkdir /flink-jobhistory</span><br><span class="line">hdfs dfs -chmod <span class="number">777</span> /flink-jobhistory</span><br></pre></td></tr></table></figure><h3 id="1-5-启动"><a href="#1-5-启动" class="headerlink" title="1.5 启动"></a>1.5 启动</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 启动HAHadoop集群</span><br><span class="line">[huser@master ~]$ ./opt/bin/start-dfs.sh--&gt;  <span class="string">&#x27;脚本启动&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-6-启动Flink集群和任务历史服务器"><a href="#1-6-启动Flink集群和任务历史服务器" class="headerlink" title="1.6 启动Flink集群和任务历史服务器"></a>1.6 启动Flink集群和任务历史服务器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[huser@master ~]$ start-cluster.sh</span><br><span class="line">[huser@master ~]$ historyserver.sh start</span><br><span class="line"><span class="meta">#jps</span></span><br><span class="line">#主节点多出:</span><br><span class="line"><span class="number">3835</span> StandaloneSessionClusterEntrypoint</span><br><span class="line"><span class="number">4148</span> TaskManagerRunner</span><br><span class="line">#其他节点多出：</span><br><span class="line"><span class="number">3437</span> TaskManagerRunner</span><br></pre></td></tr></table></figure><h3 id="1-7-查看web端"><a href="#1-7-查看web端" class="headerlink" title="1.7 查看web端"></a>1.7 查看web端</h3>启动成功后，访问 <a href="http://192.168.33.151:8081">http://192.168.33.151:8081</a>或<a href="http://192.168.33.150:8081">http://192.168.33.150:8081</a><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676451724146-e2477fcb-6135-4182-83f0-6619f1287f56.png#averageHue=%23fcfcfc&amp;clientId=u837ef046-2fb6-4&amp;from=paste&amp;height=922&amp;id=u79ba204e&amp;originHeight=922&amp;originWidth=1811&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=55644&amp;status=done&amp;style=none&amp;taskId=ue9d0252a-ba3a-490f-88d1-60f5c498583&amp;title=&amp;width=1811" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676451706030-12e9e8e0-6ed4-4572-ae0b-f0e999ecce25.png#averageHue=%23f7f7f7&amp;clientId=u837ef046-2fb6-4&amp;from=paste&amp;height=825&amp;id=u8f41c3a1&amp;originHeight=825&amp;originWidth=1821&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61117&amp;status=done&amp;style=none&amp;taskId=u143203ca-8ae8-4e7e-bb5d-271f3b08c62&amp;title=&amp;width=1821" alt="image.png"><h3 id="1-8-HA测试"><a href="#1-8-HA测试" class="headerlink" title="1.8 HA测试"></a>1.8 HA测试</h3><strong>流计算词频统计案例源码：</strong><br><strong>将文件下载本地，再将文件的后缀篡改为jar，在上传群集文件当中（.txt—&gt;.jar）</strong><br><a href="https://www.yuque.com/attachments/yuque/0/2023/txt/33576317/1676452304638-4248c58f-a2be-479e-b4f8-30660c34f5c1.txt">flink_scala-1.0-SNAPSHOT.txt</a><br>提交作业：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.</span>虚拟机内开启端口</span><br><span class="line">[huser@master ~]$ nc -lk <span class="number">5555</span></span><br><span class="line"># <span class="number">2.</span>提交作业</span><br><span class="line">[huser@master ~]$ flink run -c cs flink_scala<span class="number">-1.0</span>-SNAPSHOT.jar master <span class="number">5555</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>     格式        class_path   jar_name          node_name   nc_端口  <span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>输入数据以及结果：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676461010604-02911a94-0330-4759-b8b9-aecc6634e469.png#averageHue=%23120f0d&amp;clientId=ua26ddcb6-7483-4&amp;from=paste&amp;height=162&amp;id=uecdcc0ea&amp;originHeight=162&amp;originWidth=1138&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=20028&amp;status=done&amp;style=none&amp;taskId=udd4f25a1-5b14-4bae-af5a-3c1605810bc&amp;title=&amp;width=1138" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676460987877-d766354f-126a-4435-97b7-6809695c138e.png#averageHue=%23fefefd&amp;clientId=ua26ddcb6-7483-4&amp;from=paste&amp;height=922&amp;id=u0d197667&amp;originHeight=922&amp;originWidth=1824&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=87108&amp;status=done&amp;style=none&amp;taskId=u1b331ac4-c06a-4112-aec4-ac632e5c292&amp;title=&amp;width=1824" alt="image.png"><br>运行过程中将正在服务的JobManager给kill掉，测试是否高可用<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill <span class="number">-9</span> 端口号</span><br></pre></td></tr></table></figure>此时hadoop01的8081无法访问，hadoop02会进行接管（重新提交刚才被中断的作业），这个过程需要稍等一会儿<br>再次输入数据后可以从结果看出是一个新作业：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676461617105-bd7bb917-9e94-427e-8d2b-843d6b302d69.png#averageHue=%230a0704&amp;clientId=ua26ddcb6-7483-4&amp;from=paste&amp;height=65&amp;id=ub93a9e3a&amp;originHeight=65&amp;originWidth=422&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=3071&amp;status=done&amp;style=none&amp;taskId=u834c81b9-2049-4a9c-b8db-2eaf41754d7&amp;title=&amp;width=422" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676461626555-28b2406c-465f-4b31-be96-550eb81ff934.png#averageHue=%23fdfdfc&amp;clientId=ua26ddcb6-7483-4&amp;from=paste&amp;height=242&amp;id=u0448460c&amp;originHeight=166&amp;originWidth=293&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=6544&amp;status=done&amp;style=none&amp;taskId=ua57dd8d5-2fac-4973-84c2-ddd628febd6&amp;title=&amp;width=427" alt="image.png"><br>结束任务后可以在任务历史服务器WebUI中进行查看：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676461674361-59a57d45-997a-4181-8249-fa9c64733ece.png#averageHue=%23fbfbfa&amp;clientId=ua26ddcb6-7483-4&amp;from=paste&amp;height=200&amp;id=uf77f14ca&amp;originHeight=207&amp;originWidth=1556&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=13833&amp;status=done&amp;style=none&amp;taskId=ub4d7bf44-3575-4f2b-880c-e04aabc0198&amp;title=&amp;width=1504" alt="image.png"><h3 id="1-9-关闭命令"><a href="#1-9-关闭命令" class="headerlink" title="1.9 关闭命令"></a>1.9 关闭命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前置准备：&lt;br&gt;&lt;a href=&quot;https://www.yuque.com/u25360462/nt1ri1/kusqdo?view=doc_embed&quot;&gt;一、集群环境搭建高可用版本配置&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.yuque.com/yuq</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://xin0203xin0203.github.io/posts/0.html"/>
    <id>https://xin0203xin0203.github.io/posts/0.html</id>
    <published>2023-12-18T15:31:57.170Z</published>
    <updated>2023-12-19T01:35:12.535Z</updated>
    
    <content type="html"><![CDATA[<p>前置准备：<br><a href="https://www.yuque.com/u25360462/nt1ri1/kusqdo?view=doc_embed">一、集群环境搭建高可用版本配置</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/ifi3zw34ztgm4bqt?view=doc_embed">（一）Scala环境搭建</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/fbyk58l02whdr677?view=doc_embed">(二) Flink集群环境搭建(Local模式)</a><br>需要的安装包：<a href="https://archive.apache.org/dist/flink/">flink</a>压缩包——&gt;flink-1.13.0-bin-scala_2.12.tgz</p><h1 id="StandAlone模式"><a href="#StandAlone模式" class="headerlink" title="StandAlone模式"></a>StandAlone模式</h1><h3 id="1-1-修改集群配置"><a href="#1-1-修改集群配置" class="headerlink" title="1.1 修改集群配置"></a>1.1 修改集群配置</h3><h4 id="1-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件"><a href="#1-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件" class="headerlink" title="1.1.1 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件"></a>1.1.1 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">jobmanager.rpc.address: master</span><br><span class="line"># 将已完成的作业上传到此目录中，让任务历史服务器进行监控</span><br><span class="line">jobmanager.archive.fs.dir: hdfs:<span class="comment">//hacluster:8020/flink-jobhistory</span></span><br><span class="line">historyserver.web.address: master</span><br><span class="line">historyserver.web.port: <span class="number">18082</span></span><br><span class="line"># # 任务历史服务器监控目录中已存档的作业</span><br><span class="line">historyserver.archive.fs.dir: hdfs:<span class="comment">//hacluster:8020/flink-jobhistory</span></span><br><span class="line">historyserver.web.refresh-interval: <span class="number">10000</span></span><br></pre></td></tr></table></figure><p>除了上面的配置之外，Flink 还可以使用以下可选参数来优化集群性能：</p><ul><li><strong>jobmanager.heap.size</strong>：JobManager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.heap.size</strong>：Taskmanager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.numberOfTaskSlots</strong>：Taskmanager 上 slots 的数量，通常设置为 CPU 核心的数量，或其一半。</li><li><strong>parallelism.default</strong>：任务默认的并行度。</li><li><strong>io.tmp.dirs</strong>：存储临时文件的路径，如果没有配置，则默认采用服务器的临时目录，如 LInux 的 /tmp 目录。<h4 id="1-1-2-修改-masters-文件，指定JobManager节点"><a href="#1-1-2-修改-masters-文件，指定JobManager节点" class="headerlink" title="1.1.2 修改 masters 文件，指定JobManager节点"></a>1.1.2 修改 masters 文件，指定JobManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master:<span class="number">8081</span></span><br></pre></td></tr></table></figure><h4 id="1-1-3-修改-slaves（workers）-文件，添加TaskManager节点"><a href="#1-1-3-修改-slaves（workers）-文件，添加TaskManager节点" class="headerlink" title="1.1.3 修改 slaves（workers） 文件，添加TaskManager节点"></a>1.1.3 修改 slaves（workers） 文件，添加TaskManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-2-分发Flink给其他节点"><a href="#1-2-分发Flink给其他节点" class="headerlink" title="1.2 分发Flink给其他节点"></a>1.2 分发Flink给其他节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r $FLINK_HOME/ slave1:/opt/</span><br><span class="line">scp -r $FLINK_HOME/ slave2:/opt/</span><br></pre></td></tr></table></figure><h3 id="1-3-在HDFS上创建HIstory目录"><a href="#1-3-在HDFS上创建HIstory目录" class="headerlink" title="1.3 在HDFS上创建HIstory目录"></a>1.3 在<strong>HDFS</strong>上<strong>创建</strong>HIstory目录</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /flink-jobhistory</span><br><span class="line">hdfs dfs -chmod <span class="number">777</span> /flink-jobhistory</span><br></pre></td></tr></table></figure><h3 id="1-3-启动"><a href="#1-3-启动" class="headerlink" title="1.3 启动"></a>1.3 启动</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#启动HAHadoop集群</span><br><span class="line">[huser@master ~]$ ./opt/bin/start-dfs.sh--&gt;  <span class="string">&#x27;脚本启动&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-4-启动Flink集群和任务历史服务器"><a href="#1-4-启动Flink集群和任务历史服务器" class="headerlink" title="1.4 启动Flink集群和任务历史服务器"></a>1.4 启动Flink集群和任务历史服务器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[huser@master ~]$ start-cluster.sh</span><br><span class="line">[huser@master ~]$ historyserver.sh start</span><br><span class="line"><span class="meta">#jps</span></span><br><span class="line">#主节点多出:</span><br><span class="line"><span class="number">3835</span> StandaloneSessionClusterEntrypoint</span><br><span class="line"><span class="number">4148</span> TaskManagerRunner</span><br><span class="line">#其他节点多出：</span><br><span class="line"><span class="number">3437</span> TaskManagerRunner</span><br></pre></td></tr></table></figure><h3 id="1-5-查看web端"><a href="#1-5-查看web端" class="headerlink" title="1.5 查看web端"></a>1.5 查看web端</h3>启动成功后，访问 <a href="http://master:8081">http://master:8081</a>或<a href="http://192.168.33.150:8081">http://192.168.33.150:8081</a><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676451724146-e2477fcb-6135-4182-83f0-6619f1287f56.png#averageHue=%23fcfcfc&amp;clientId=u837ef046-2fb6-4&amp;from=paste&amp;height=922&amp;id=u79ba204e&amp;originHeight=922&amp;originWidth=1811&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=55644&amp;status=done&amp;style=none&amp;taskId=ue9d0252a-ba3a-490f-88d1-60f5c498583&amp;title=&amp;width=1811" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676451706030-12e9e8e0-6ed4-4572-ae0b-f0e999ecce25.png#averageHue=%23f7f7f7&amp;clientId=u837ef046-2fb6-4&amp;from=paste&amp;height=825&amp;id=u8f41c3a1&amp;originHeight=825&amp;originWidth=1821&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=61117&amp;status=done&amp;style=none&amp;taskId=u143203ca-8ae8-4e7e-bb5d-271f3b08c62&amp;title=&amp;width=1821" alt="image.png"><h3 id="1-6-关闭命令"><a href="#1-6-关闭命令" class="headerlink" title="1.6 关闭命令"></a>1.6 关闭命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前置准备：&lt;br&gt;&lt;a href=&quot;https://www.yuque.com/u25360462/nt1ri1/kusqdo?view=doc_embed&quot;&gt;一、集群环境搭建高可用版本配置&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.yuque.com/yuq</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>十四、Flink组件搭建之Flink集群环境搭建(Local模式)(二)</title>
    <link href="https://xin0203xin0203.github.io/posts/3cc2c9ad.html"/>
    <id>https://xin0203xin0203.github.io/posts/3cc2c9ad.html</id>
    <published>2023-12-18T15:31:57.149Z</published>
    <updated>2024-12-19T01:34:51.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Flink的简介："><a href="#Flink的简介：" class="headerlink" title="Flink的简介："></a>Flink的简介：</h1><p>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。<br>Apache Flink的数据流编程模型在有限和无限数据集上提供单次事件（event-at-a-time）处理。在基础层面，Flink程序由流和转换组成。<br>Apache Flink的API：有界或无界数据流的数据流API、用于有界数据集的数据集API、表API。</p><h3 id="数据流的运行流程"><a href="#数据流的运行流程" class="headerlink" title="数据流的运行流程"></a>数据流的运行流程</h3><p>Flink程序在执行后被映射到流数据流，每个Flink数据流以一个或多个源（数据输入，例如消息队列或文件系统）开始，并以一个或多个接收器（数据输出，如消息队列、文件系统或数据库等）结束。Flink可以对流执行任意数量的变换，这些流可以被编排为有向无环数据流图，允许应用程序分支和合并数据流。</p><h3 id="Flink的数据源和接收器"><a href="#Flink的数据源和接收器" class="headerlink" title="Flink的数据源和接收器"></a>Flink的数据源和接收器</h3><p>Flink提供现成的源和<a href="https://baike.baidu.com/item/%E6%8E%A5%E6%94%B6%E8%BF%9E%E6%8E%A5%E5%99%A8/3533010?fromModule=lemma_inlink">接收连接器</a>，包括Apache Kafka、Amazon Kinesis、HDFS和Apache Cassandra等。<br>Flink程序可以作为集群内的分布式系统运行，也可以以独立模式或在YARN、Mesos、基于Docker的环境和其他资源管理框架下进行部署。</p><h3 id="Flink的状态-state"><a href="#Flink的状态-state" class="headerlink" title="Flink的状态(state)"></a>Flink的状态(state)</h3><p>Flink检查点和容错：检查点是应用程序状态和源流中位置的自动异步快照。在发生故障的情况下，启用了检查点的Flink程序将在恢复时从上一个完成的检查点恢复处理，确保Flink在应用程序中保持一致性（exactly-once）状态语义。检查点机制暴露应用程序代码的接口，以便将外部系统包括在检查点机制中（如打开和提交数据库系统的事务）。<br>Flink保存点的机制是一种手动触发的检查点。用户可以生成保存点，停止正在运行的Flink程序，然后从流中的相同应用程序状态和位置恢复程序。 保存点可以在不丢失应用程序状态的情况下对Flink程序或Flink群集进行更新。</p><h3 id="Flink的数据流API"><a href="#Flink的数据流API" class="headerlink" title="Flink的数据流API"></a>Flink的数据流API</h3><p>Flink的数据流API支持有界或无界数据流上的转换（如过滤器、聚合和窗口函数），包含了20多种不同类型的转换，可以在Java和Scala中使用。<br>有状态流处理程序的一个简单Scala示例是从连续输入流发出字数并在5秒窗口中对数据进行分组的应用： [4] </p><h3 id="Apache-Beam"><a href="#Apache-Beam" class="headerlink" title="Apache Beam"></a>Apache Beam</h3><p>Apache Beam“提供了一种高级统一编程模型，允许（开发人员）实现可在在任何执行引擎上运行批处理和流数据处理作业”。Apache Flink-on-Beam运行器是功能最丰富的、由Beam社区维护的能力矩阵。<br>data Artisans与Apache Flink社区一起，与Beam社区密切合作，开发了一个强大的Flink runner。</p><h3 id="数据集API"><a href="#数据集API" class="headerlink" title="数据集API"></a>数据集API</h3><p>Flink的数据集API支持对有界数据集进行转换（如过滤、映射、连接和分组），包含了20多种不同类型的转换。 该API可用于Java、Scala和实验性的Python API。Flink的数据集API在概念上与数据流API类似。 [3] </p><h3 id="表API和SQL"><a href="#表API和SQL" class="headerlink" title="表API和SQL"></a>表API和SQL</h3><p>Flink的表API是一种类似SQL的表达式语言，用于关系流和批处理，可以嵌入Flink的Java和Scala数据集和数据流API中。表API和SQL接口在关系表抽象上运行，可以从外部数据源或现有数据流和数据集创建表。表API支持<a href="https://baike.baidu.com/item/%E5%85%B3%E7%B3%BB%E8%BF%90%E7%AE%97%E7%AC%A6/352774?fromModule=lemma_inlink">关系运算符</a>，如表上的选择、聚合和连接等。<br>也可以使用常规SQL查询表。表API提供了和SQL相同的功能，可以在同一程序中混合使用。将表转换回数据集或数据流时，由<a href="https://baike.baidu.com/item/%E5%85%B3%E7%B3%BB%E8%BF%90%E7%AE%97%E7%AC%A6/352774?fromModule=lemma_inlink">关系运算符</a>和SQL查询定义的逻辑计划将使用Apache Calcite进行优化，并转换为数据集或数据流程序。</p><p>前置准备：<br><a href="https://www.yuque.com/u25360462/nt1ri1/kusqdo?view=doc_embed">一、集群环境搭建高可用版本配置</a><br><a href="https://www.yuque.com/yuqueyonghub89qji/xc0gbs/ifi3zw34ztgm4bqt?view=doc_embed">（一）Scala环境搭建</a><br>需要的安装包：<a href="https://archive.apache.org/dist/flink/">flink</a>压缩包——&gt;flink-1.13.0-bin-scala_2.12.tgz</p><h2 id="1-本地启动"><a href="#1-本地启动" class="headerlink" title="1. 本地启动"></a>1. 本地启动</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf flink<span class="number">-1.13</span><span class="number">.0</span>-bin-scala_2<span class="number">.12</span>.tgz -C /opt/</span><br><span class="line">mv flink<span class="number">-1.13</span><span class="number">.0</span> flink</span><br></pre></td></tr></table></figure><h3 id="1-2-配置Flink环境变量"><a href="#1-2-配置Flink环境变量" class="headerlink" title="1.2 配置Flink环境变量"></a>1.2 配置Flink环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"># Flink</span><br><span class="line"><span class="keyword">export</span> FLINK_HOME=/opt/flink</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$FLINK_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="1-3-加载环境变量"><a href="#1-3-加载环境变量" class="headerlink" title="1.3 加载环境变量"></a>1.3 加载环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="1-4-开启Flink集群"><a href="#1-4-开启Flink集群" class="headerlink" title="1.4 开启Flink集群"></a>1.4 开启Flink集群</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/start-cluster.sh</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon on host slave1.</span><br><span class="line">Starting taskexecutor daemon on host slave1.</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">[huser@master ~]$ jps</span><br><span class="line"><span class="number">10369</span> StandaloneSessionClusterEntrypoint</span><br><span class="line"><span class="number">10680</span> TaskManagerRunner</span><br><span class="line"><span class="number">10717</span> Jps</span><br></pre></td></tr></table></figure><h3 id="1-5-访问-Web-UI"><a href="#1-5-访问-Web-UI" class="headerlink" title="1.5 访问 Web UI"></a>1.5 访问 Web UI</h3><p>启动成功后，访问 <a href="http://master:8081">http://master:8081</a>或<a href="http://192.168.33.150:8081">http://192.168.33.150:8081</a><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1674734330071-a33d5b08-183b-4aa0-87fe-6a48d1f84f8a.png#averageHue=%23fafafa&amp;clientId=ud06bda3c-a0f0-4&amp;from=paste&amp;height=671&amp;id=u22d7dd91&amp;originHeight=1007&amp;originWidth=1916&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=106498&amp;status=done&amp;style=none&amp;taskId=ubab717bd-5437-4850-9efd-af276fa1471&amp;title=&amp;width=1277.3333333333333" alt="image.png"></p><h3 id="1-6-关闭Flink集群"><a href="#1-6-关闭Flink集群" class="headerlink" title="1.6 关闭Flink集群"></a>1.6 关闭Flink集群</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="function">Stopping taskexecutor <span class="title">daemon</span> <span class="params">(pid: <span class="number">2901</span>)</span> on host slave1.</span></span><br><span class="line"><span class="function">Stopping standalonesession <span class="title">daemon</span> <span class="params">(pid: <span class="number">2635</span>)</span> on host slave1.</span></span><br><span class="line"><span class="function">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="2-远程集群启动"><a href="#2-远程集群启动" class="headerlink" title="2. 远程集群启动"></a>2. 远程集群启动</h1><h3 id="2-1-修改集群配置"><a href="#2-1-修改集群配置" class="headerlink" title="2.1 修改集群配置"></a>2.1 修改集群配置</h3><h4 id="2-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件"><a href="#2-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件" class="headerlink" title="2.1.1 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件"></a>2.1.1 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jobmanager.rpc.address: master</span><br></pre></td></tr></table></figure><h4 id="2-1-2-修改-masters-文件，指定JobManager节点"><a href="#2-1-2-修改-masters-文件，指定JobManager节点" class="headerlink" title="2.1.2 修改 masters 文件，指定JobManager节点"></a>2.1.2 修改 masters 文件，指定JobManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">master:<span class="number">8081</span></span><br><span class="line">slave1:<span class="number">8081</span></span><br></pre></td></tr></table></figure><h4 id="2-1-3-修改-slaves（workers）-文件，添加TaskManager节点"><a href="#2-1-3-修改-slaves（workers）-文件，添加TaskManager节点" class="headerlink" title="2.1.3 修改 slaves（workers） 文件，添加TaskManager节点"></a>2.1.3 修改 slaves（workers） 文件，添加TaskManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="2-2-分发Flink给其他节点"><a href="#2-2-分发Flink给其他节点" class="headerlink" title="2.2 分发Flink给其他节点"></a>2.2 分发Flink给其他节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r $FLINK_HOME/ slave1:/opt/</span><br><span class="line">scp -r $FLINK_HOME/ slave2:/opt/</span><br></pre></td></tr></table></figure><h3 id="2-3-启动命令"><a href="#2-3-启动命令" class="headerlink" title="2.3 启动命令"></a>2.3 启动命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/start-cluster.sh</span><br></pre></td></tr></table></figure><h3 id="2-4-查看节点"><a href="#2-4-查看节点" class="headerlink" title="2.4 查看节点"></a>2.4 查看节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#jps多出:</span></span><br><span class="line"><span class="number">4658</span> StandaloneSessionClusterEntrypoint</span><br><span class="line"><span class="number">4978</span> TaskManagerRunner</span><br></pre></td></tr></table></figure><h3 id="2-5-查看开发端口IP"><a href="#2-5-查看开发端口IP" class="headerlink" title="2.5 查看开发端口IP"></a>2.5 <strong>查看开发端口IP</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">netstat -nltp</span><br><span class="line"># 注意：要用此命令，必须先下载组件</span><br><span class="line">yum install -y nc  OR  yum install -y netcat</span><br><span class="line"># 如果不行，就下载组件</span><br><span class="line">yum -y install net-tools</span><br><span class="line"><span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">(Not all processes could be identified, non-owned process info</span></span><br><span class="line"><span class="string"> will not be shown, you would have to be root to see it all.)</span></span><br><span class="line"><span class="string">Active Internet connections (only servers)</span></span><br><span class="line"><span class="string">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    </span></span><br><span class="line"><span class="string">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -                   </span></span><br><span class="line"><span class="string">tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      -                   </span></span><br><span class="line"><span class="string">tcp6       0      0 192.168.33.150:33308    :::*                    LISTEN      9630/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::34909                :::*                    LISTEN      9630/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::34273                :::*                    LISTEN      9630/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::43715                :::*                    LISTEN      9281/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::6123                 :::*                    LISTEN      9281/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::8081                 :::*                    LISTEN      9281/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::22                   :::*                    LISTEN      -                   </span></span><br><span class="line"><span class="string">tcp6       0      0 :::39481                :::*                    LISTEN      9281/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 ::1:25                  :::*                    LISTEN      -  </span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="2-6-查看web端"><a href="#2-6-查看web端" class="headerlink" title="2.6 查看web端"></a>2.6 查看web端</h3><p>启动成功后，访问 <a href="http://master:8081">http://master:8081</a>或<a href="http://192.168.33.150:8081">http://192.168.33.150:8081</a><br><img src="https://cdn.nlark.com/yuque/0/2023/png/33576317/1676444068752-e82b4997-1f17-4ff0-9e12-56fa25e34ee3.png#averageHue=%23fcfbfb&amp;clientId=ubc49e345-800f-4&amp;from=paste&amp;height=971&amp;id=ud09f432b&amp;originHeight=971&amp;originWidth=1830&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=58307&amp;status=done&amp;style=none&amp;taskId=ub737f5e6-3457-492b-b1f2-a65bcf5a574&amp;title=&amp;width=1830" alt="image.png"></p><h3 id="2-7-关闭命令"><a href="#2-7-关闭命令" class="headerlink" title="2.7 关闭命令"></a>2.7 关闭命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Flink的简介：&quot;&gt;&lt;a href=&quot;#Flink的简介：&quot; class=&quot;headerlink&quot; title=&quot;Flink的简介：&quot;&gt;&lt;/a&gt;Flink的简介：&lt;/h1&gt;&lt;p&gt;Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>八、DataX组件搭建--数据迁移工具</title>
    <link href="https://xin0203xin0203.github.io/posts/28f6f62f.html"/>
    <id>https://xin0203xin0203.github.io/posts/28f6f62f.html</id>
    <published>2023-12-17T17:15:29.888Z</published>
    <updated>2024-12-18T12:45:30.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-dove modern"><p>简介： <a href="https://blog.csdn.net/weixin_46902396/article/details/121904705?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166731346816782395330610%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166731346816782395330610&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-121904705-null-null.142^v62^pc_rank_34_queryrelevant25,201^v3^control_1,213^v1^control&amp;utm_term=DataX&amp;spm=1018.2226.3001.4187"><strong>DataX</strong></a>是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。</p></div><div class="tip cogs"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note info simple"><p>需要的安装包：<a href="http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz"><strong>DataX</strong></a>包—-&gt;<strong>datax.tar.gz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf datax.tar.gz -C /opt/software/</span><br><span class="line"><span class="meta"># 这里解压出来的名字刚好是datax，所以不用改名</span></span><br></pre></td></tr></table></figure><h3 id="1-2-运行自检脚本"><a href="#1-2-运行自检脚本" class="headerlink" title="1.2 运行自检脚本"></a>1.2 运行自检脚本</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/datax.py job/job.json</span><br></pre></td></tr></table></figure><h3 id="1-3-部署datax到本地后首次执行任务报错"><a href="#1-3-部署datax到本地后首次执行任务报错" class="headerlink" title="1.3 部署datax到本地后首次执行任务报错"></a>1.3 部署datax到本地后首次执行任务报错</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-11-02 12:53:46.815 [main] WARN  ConfigParser - 插件[streamreader,streamwriter]加载失败，1s后重试... Exception:Code:[Common-00], Describe:[您提供的配置文件存在错误信息，请检查您的作业配置 .] - 配置信息错误，您提供的配置文件[/opt/datax/plugin/reader/._drdsreader/plugin.json]不存在. 请检查您的配置文件. </span></span><br><span class="line"><span class="string">2022-11-02 12:53:47.834 [main] ERROR Engine - </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">经DataX智能分析,该任务最可能的错误原因是:</span></span><br><span class="line"><span class="string">com.alibaba.datax.common.exception.DataXException: Code:[Common-00], Describe:[您提供的配置文件存在错误信息，请检查您的作业配置 .] - 配置信息错误，您提供的配置文件[/opt/datax/plugin/reader/._drdsreader/plugin.json]不存在. 请检查您的配置文件.</span></span><br><span class="line"><span class="string">at com.alibaba.datax.common.exception.DataXException.asDataXException(DataXException.java:26)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.common.util.Configuration.from(Configuration.java:95)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.util.ConfigParser.parseOnePluginConfig(ConfigParser.java:153)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.util.ConfigParser.parsePluginConfig(ConfigParser.java:125)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.util.ConfigParser.parse(ConfigParser.java:63)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.Engine.entry(Engine.java:137)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.Engine.main(Engine.java:204)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">解决方案：</span><br><span class="line"><span class="built_in">cd</span> /plugin/reader</span><br><span class="line"><span class="built_in">rm</span> -rf  ./._*</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /plugin/writer</span><br><span class="line"><span class="built_in">rm</span> -rf  ./._*</span><br></pre></td></tr></table></figure><h2 id="2-基本使用"><a href="#2-基本使用" class="headerlink" title="2. 基本使用"></a>2. 基本使用</h2><h3 id="2-1-从stream读取数据并打印到控制台"><a href="#2-1-从stream读取数据并打印到控制台" class="headerlink" title="2.1 从stream读取数据并打印到控制台"></a>2.1 从stream读取数据并打印到控制台</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">python /opt/datax/bin/datax.py -r streamreader -w streamwriter</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">DataX</span> (DATAX-OPENSOURCE<span class="number">-3.0</span>), From Alibaba !</span><br><span class="line"><span class="built_in">Copyright</span> (C) <span class="number">2010</span><span class="number">-2017</span>, Alibaba Group. All Rights Reserved.</span><br><span class="line"></span><br><span class="line">Please refer to the streamreader document:</span><br><span class="line">     https:<span class="comment">//github.com/alibaba/DataX/blob/master/streamreader/doc/streamreader.md </span></span><br><span class="line"></span><br><span class="line">Please refer to the streamwriter document:</span><br><span class="line">     https:<span class="comment">//github.com/alibaba/DataX/blob/master/streamwriter/doc/streamwriter.md </span></span><br><span class="line"> </span><br><span class="line">Please save the following configuration as a json file <span class="keyword">and</span>  use</span><br><span class="line">     python &#123;DATAX_HOME&#125;/bin/datax.py &#123;JSON_FILE_NAME&#125;.json </span><br><span class="line">to run the job.</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;job&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;streamreader&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [], </span><br><span class="line">                        <span class="string">&quot;sliceRecordCount&quot;</span>: <span class="string">&quot;&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, </span><br><span class="line">                <span class="string">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;streamwriter&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;encoding&quot;</span>: <span class="string">&quot;&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;print&quot;</span>: <span class="literal">true</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ], </span><br><span class="line">        <span class="string">&quot;setting&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;channel&quot;</span>: <span class="string">&quot;&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="2-2-根据模板编写json文件-新建一个data目录下stream2stream-json文件"><a href="#2-2-根据模板编写json文件-新建一个data目录下stream2stream-json文件" class="headerlink" title="2.2 根据模板编写json文件,新建一个data目录下stream2stream.json文件"></a>2.2 根据模板编写json文件,新建一个data目录下stream2stream.json文件</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;job&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;streamreader&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;type&quot;</span>:<span class="string">&quot;string&quot;</span>,</span><br><span class="line">                                <span class="string">&quot;value&quot;</span>:<span class="string">&quot;xiaokang-微信公众号:小康新鲜事儿&quot;</span></span><br><span class="line">                            &#125;,</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;type&quot;</span>:<span class="string">&quot;string&quot;</span>,</span><br><span class="line">                                <span class="string">&quot;value&quot;</span>:<span class="string">&quot;你好，世界-DataX&quot;</span></span><br><span class="line">                            &#125;</span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;sliceRecordCount&quot;</span>: <span class="string">&quot;10&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, </span><br><span class="line">                <span class="string">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;streamwriter&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;encoding&quot;</span>: <span class="string">&quot;utf-8&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;print&quot;</span>: <span class="literal">true</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ], </span><br><span class="line">        <span class="string">&quot;setting&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;channel&quot;</span>: <span class="string">&quot;2&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-运行Job"><a href="#2-3-运行Job" class="headerlink" title="2.3 运行Job"></a>2.3 运行Job</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/datax/bin/datax.py data/stream2stream.json</span><br></pre></td></tr></table></figure><h2 id="3-MySQL数据导入到HDFS"><a href="#3-MySQL数据导入到HDFS" class="headerlink" title="3. MySQL数据导入到HDFS"></a>3. MySQL数据导入到HDFS</h2><h3 id="3-1-查看官方json配置模板"><a href="#3-1-查看官方json配置模板" class="headerlink" title="3.1 查看官方json配置模板"></a>3.1 查看官方json配置模板</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python /opt/datax/bin/datax.py -r mysqlreader -w hdfswriter</span><br></pre></td></tr></table></figure><h3 id="3-2-根据模板编写json文件-data目录下mysql2hdfs-json文件"><a href="#3-2-根据模板编写json文件-data目录下mysql2hdfs-json文件" class="headerlink" title="3.2 根据模板编写json文件,data目录下mysql2hdfs.json文件"></a>3.2 根据模板编写json文件,data目录下mysql2hdfs.json文件</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;job&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mysqlreader&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            <span class="string">&quot;help_keyword_id&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;name&quot;</span></span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;connection&quot;</span>: [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;jdbcUrl&quot;</span>: [</span><br><span class="line">                                    <span class="string">&quot;jdbc:mysql://192.168.33.147:3306/mysql&quot;</span></span><br><span class="line">                                ], </span><br><span class="line">                                <span class="string">&quot;table&quot;</span>: [</span><br><span class="line">                                    <span class="string">&quot;help_keyword&quot;</span></span><br><span class="line">                                ]</span><br><span class="line">                            &#125;</span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;password&quot;</span>: <span class="string">&quot;1&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;username&quot;</span>: <span class="string">&quot;root&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, </span><br><span class="line">                <span class="string">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;hdfswriter&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;name&quot;</span>:<span class="string">&quot;help_keyword_id&quot;</span>,</span><br><span class="line">                                <span class="string">&quot;type&quot;</span>:<span class="string">&quot;int&quot;</span></span><br><span class="line">                            &#125;,</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;name&quot;</span>:<span class="string">&quot;name&quot;</span>,</span><br><span class="line">                                <span class="string">&quot;type&quot;</span>:<span class="string">&quot;string&quot;</span></span><br><span class="line">                            &#125;</span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;defaultFS&quot;</span>: <span class="string">&quot;hdfs://192.168.33.147:9000&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fieldDelimiter&quot;</span>: <span class="string">&quot;|&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fileName&quot;</span>: <span class="string">&quot;keyword.txt&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fileType&quot;</span>: <span class="string">&quot;text&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/datax&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;writeMode&quot;</span>: <span class="string">&quot;append&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ], </span><br><span class="line">        <span class="string">&quot;setting&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;channel&quot;</span>: <span class="string">&quot;3&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-3-运行Job"><a href="#3-3-运行Job" class="headerlink" title="3.3 运行Job"></a>3.3 运行Job</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/datax/bin/datax.py data/mysql2hdfs.json</span><br></pre></td></tr></table></figure><h2 id="4-HDFS数据导出到MySQL"><a href="#4-HDFS数据导出到MySQL" class="headerlink" title="4. HDFS数据导出到MySQL"></a>4. HDFS数据导出到MySQL</h2><h3 id="4-1-将3-2中导入的文件重命名并在数据库创建表"><a href="#4-1-将3-2中导入的文件重命名并在数据库创建表" class="headerlink" title="4.1 将3.2中导入的文件重命名并在数据库创建表"></a>4.1 将3.2中导入的文件重命名并在数据库创建表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">mv</span> /datax/keyword.txt__4c0e0d04_e503_437a_a1e3_49db49cbaaed /datax/keyword.txt</span><br></pre></td></tr></table></figure><h3 id="4-2-创建表"><a href="#4-2-创建表" class="headerlink" title="4.2 创建表"></a>4.2 创建表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE help_keyword_from_hdfs_datax LIKE help_keyword;</span><br></pre></td></tr></table></figure><h3 id="4-3-查看官方json配置模板"><a href="#4-3-查看官方json配置模板" class="headerlink" title="4.3 查看官方json配置模板"></a>4.3 查看官方json配置模板</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python /opt/datax/bin/datax.py -r hdfsreader -w mysqlwriter</span><br></pre></td></tr></table></figure><h3 id="4-4-根据模板编写json文件，data目录下hdfs2mysql-json文件"><a href="#4-4-根据模板编写json文件，data目录下hdfs2mysql-json文件" class="headerlink" title="4.4 根据模板编写json文件，data目录下hdfs2mysql.json文件"></a>4.4 根据模板编写json文件，data目录下hdfs2mysql.json文件</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;job&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;hdfsreader&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            <span class="string">&quot;*&quot;</span></span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;defaultFS&quot;</span>: <span class="string">&quot;hdfs://192.168.33.147:9000&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;encoding&quot;</span>: <span class="string">&quot;UTF-8&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fieldDelimiter&quot;</span>: <span class="string">&quot;|&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fileType&quot;</span>: <span class="string">&quot;text&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/datax/keyword.txt&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, </span><br><span class="line">                <span class="string">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mysqlwriter&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            <span class="string">&quot;help_keyword_id&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;name&quot;</span></span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;connection&quot;</span>: [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;jdbcUrl&quot;</span>: <span class="string">&quot;jdbc:mysql://192.168.33.147:3306/mysql&quot;</span>, </span><br><span class="line">                                <span class="string">&quot;table&quot;</span>: [<span class="string">&quot;help_keyword_from_hdfs_datax&quot;</span>]</span><br><span class="line">                            &#125;</span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;password&quot;</span>: <span class="string">&quot;1&quot;</span>,  </span><br><span class="line">                        <span class="string">&quot;username&quot;</span>: <span class="string">&quot;root&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;writeMode&quot;</span>: <span class="string">&quot;insert&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ], </span><br><span class="line">        <span class="string">&quot;setting&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;channel&quot;</span>: <span class="string">&quot;3&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-5-运行Job"><a href="#4-5-运行Job" class="headerlink" title="4.5 运行Job"></a>4.5 运行Job</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/datax/bin/datax.py data/hdfs2mysql.json</span><br></pre></td></tr></table></figure><h2 id="5-DataX-Web安装"><a href="#5-DataX-Web安装" class="headerlink" title="5. DataX Web安装"></a>5. DataX Web安装</h2><h3 id="5-1-Maven安装"><a href="#5-1-Maven安装" class="headerlink" title="5.1 Maven安装"></a>5.1 Maven安装</h3><div class="note green anzhiyufont anzhiyu-icon-dove modern"><p>简介：<strong>Maven</strong>是一个跨平台的项目管理工具。作为Apache组织的一个颇为成功的开源项目，其主要服务于基于Java平台的项目创建，依赖管理和项目信息管理。maven是Apache的顶级项目，解释为“专家，内行”，它是一个项目管理的工具，maven自身是纯java开发的，可以使用maven对java项目进行构建、依赖管理。</p></div><div class="note info simple"><p>需要的安装包：<strong>1.<a href="https://archive.apache.org/dist/maven/maven-3/">Maven</a>包—-&gt;apache-maven-3.6.3-bin.tar.gz</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>2.<a href="https://github.com/WeiYe-Jing/datax-web/archive/v-2.1.2.tar.gz">datax-web</a>包—-&gt;datax-web-v-2.1.2.tar.gz</strong></p></div><h4 id="5-1-1-准备工作"><a href="#5-1-1-准备工作" class="headerlink" title="5.1.1 准备工作"></a>5.1.1 准备工作</h4><h5 id="1-解压并改名"><a href="#1-解压并改名" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-maven-3.6.3-bin.tar.gz -C /opt/</span><br><span class="line"><span class="built_in">mv</span> apache-maven-3.6.3 maven</span><br></pre></td></tr></table></figure><h4 id="5-1-2-配置Sqoop环境变量"><a href="#5-1-2-配置Sqoop环境变量" class="headerlink" title="5.1.2 配置Sqoop环境变量"></a>5.1.2 配置Sqoop环境变量</h4><h5 id="1-配置Sqoop环境变量"><a href="#1-配置Sqoop环境变量" class="headerlink" title="1. 配置Sqoop环境变量"></a>1. 配置Sqoop环境变量</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="comment"># maven</span></span><br><span class="line"><span class="built_in">export</span> MAVEN_HOME=/opt/maven</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$MAVEN_HOME</span>/bin</span><br></pre></td></tr></table></figure><h5 id="2-加载环境变量"><a href="#2-加载环境变量" class="headerlink" title="2. 加载环境变量"></a>2. 加载环境变量</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h4 id="5-1-3-修改配置"><a href="#5-1-3-修改配置" class="headerlink" title="5.1.3 修改配置"></a>5.1.3 修改配置</h4><h5 id="1-创建本地目录"><a href="#1-创建本地目录" class="headerlink" title="1. 创建本地目录"></a>1. 创建本地目录</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/maven/maven_repository</span><br></pre></td></tr></table></figure><h5 id="2-配置setting-xml"><a href="#2-配置setting-xml" class="headerlink" title="2. 配置setting.xml"></a>2. 配置setting.xml</h5><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 配置本地仓库地址 --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">localRepository</span>&gt;</span>/opt/maven/maven_repository<span class="tag">&lt;/<span class="name">localRepository</span>&gt;</span></span></span><br><span class="line">&lt;!-- 阿里云仓库 --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>nexus-aliyun<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>Nexus aliyun<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span></span><br><span class="line">&lt;!-- <span class="title class_">Java</span>的<span class="variable constant_">JDK</span>版本 --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">profile</span>&gt;</span>    </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>jdk-1.8<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">activation</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">activeByDefault</span>&gt;</span>true<span class="tag">&lt;/<span class="name">activeByDefault</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">jdk</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">jdk</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">activation</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">maven.compiler.compilerVersion</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.compilerVersion</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h4 id="5-1-4-验证"><a href="#5-1-4-验证" class="headerlink" title="5.1.4 验证"></a>5.1.4 验证</h4><h5 id="1-查看版本"><a href="#1-查看版本" class="headerlink" title="1. 查看版本"></a>1. 查看版本</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mvn -version</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Apache Maven 3.6.3 (cecedd343002696d0abb50b32b541b8a6ba2883f)</span></span><br><span class="line"><span class="string">Maven home: /opt/maven</span></span><br><span class="line"><span class="string">Java version: 1.8.0_341, vendor: Oracle Corporation, runtime: /usr/java/jdk1.8.0_341-amd64/jre</span></span><br><span class="line"><span class="string">Default locale: zh_CN, platform encoding: UTF-8</span></span><br><span class="line"><span class="string">OS name: &quot;linux&quot;, version: &quot;3.10.0-862.el7.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot;</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h5 id="2-打包jar到本地仓库（自己先准备一个jar包）"><a href="#2-打包jar到本地仓库（自己先准备一个jar包）" class="headerlink" title="2. 打包jar到本地仓库（自己先准备一个jar包）"></a>2. 打包jar到本地仓库（自己先准备一个jar包）</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mvn install:install-file -Dfile=/opt/bin/mysql-connector-java-5.1.37.jar  -DgroupId=cool.huser -DartifactId=mysql-connector -Dversion=5.1.37 -Dpackaging=jar</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">[INFO] Installing /opt/bin/mysql-connector-java-5.1.37.jar to /opt/maven/maven_repository/cool/huser/mysql-connector/5.1.37/mysql-connector-5.1.37.jar</span></span><br><span class="line"><span class="string">[INFO] Installing /tmp/mvninstall987975586380233206.pom to /opt/maven/maven_repository/cool/huser/mysql-connector/5.1.37/mysql-connector-5.1.37.pom</span></span><br><span class="line"><span class="string">[INFO] ------------------------------------------------------------------------</span></span><br><span class="line"><span class="string">[INFO] BUILD SUCCESS</span></span><br><span class="line"><span class="string">[INFO] ------------------------------------------------------------------------</span></span><br><span class="line"><span class="string">[INFO] Total time:  19.473 s</span></span><br><span class="line"><span class="string">[INFO] Finished at: 2022-11-02T15:09:33+08:00</span></span><br><span class="line"><span class="string">[INFO] -----</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="5-2-DataX-Web安装"><a href="#5-2-DataX-Web安装" class="headerlink" title="5.2 DataX Web安装"></a>5.2 DataX Web安装</h3><h4 id="5-2-1-准备工作"><a href="#5-2-1-准备工作" class="headerlink" title="5.2.1 准备工作"></a>5.2.1 准备工作</h4><h5 id="1-解压并改名-1"><a href="#1-解压并改名-1" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf datax-web-v<span class="number">-2.1</span><span class="number">.2</span>.tar.gz -C /opt/</span><br><span class="line">mv datax-web-v<span class="number">-2.1</span><span class="number">.2</span> datax-web</span><br></pre></td></tr></table></figure><h5 id="2-编译打包"><a href="#2-编译打包" class="headerlink" title="2. 编译打包"></a>2. 编译打包</h5><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">huser@master</span> <span class="string">datax-web</span>]<span class="string">$</span> <span class="string">mvn</span> <span class="string">clean</span> <span class="string">install</span></span><br><span class="line"><span class="string">‘’‘</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="attr">Reactor Summary for datax-web 2.1.2:</span></span><br><span class="line">[<span class="string">INFO</span>] </span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-web</span> <span class="string">..........................................</span> <span class="string">SUCCESS</span> [  <span class="number">2.238</span> <span class="string">s</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-rpc</span> <span class="string">..........................................</span> <span class="string">SUCCESS</span> [<span class="number">03</span><span class="string">:21</span> <span class="string">min</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-core</span> <span class="string">.........................................</span> <span class="string">SUCCESS</span> [<span class="number">03</span><span class="string">:20</span> <span class="string">min</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-admin</span> <span class="string">........................................</span> <span class="string">SUCCESS</span> [<span class="number">11</span><span class="string">:10</span> <span class="string">min</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-executor</span> <span class="string">.....................................</span> <span class="string">SUCCESS</span> [ <span class="number">13.001</span> <span class="string">s</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-assembly</span> <span class="string">.....................................</span> <span class="string">SUCCESS</span> [ <span class="number">10.013</span> <span class="string">s</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">------------------------------------------------------------------------</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="string">BUILD</span> <span class="string">SUCCESS</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="string">------------------------------------------------------------------------</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="attr">Total time:</span>  <span class="number">18</span><span class="string">:28</span> <span class="string">min</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="attr">Finished at:</span> <span class="number">2022-11-02T15:32:04+08:00</span></span><br><span class="line">[<span class="string">INFO</span>]</span><br><span class="line"><span class="string">’‘’</span></span><br></pre></td></tr></table></figure><h4 id="5-2-2-安装部署"><a href="#5-2-2-安装部署" class="headerlink" title="5.2.2 安装部署"></a>5.2.2 安装部署</h4><h5 id="1-权限，不然不能执行"><a href="#1-权限，不然不能执行" class="headerlink" title="1. 权限，不然不能执行"></a><font color=red>1. 权限，不然不能执行</font></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> -R 777 install.sh s*</span><br></pre></td></tr></table></figure><h5 id="2-执行安装脚本"><a href="#2-执行安装脚本" class="headerlink" title="2. 执行安装脚本"></a>2. 执行安装脚本</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./install.sh</span><br><span class="line">’‘’</span><br><span class="line">出现以下界面说明DataX Web安装成功</span><br><span class="line">2022-11-02 15:45:37.890 [INFO] (108159)  Start to build directory</span><br><span class="line">2022-11-02 15:45:37.893 [INFO] (108159) Creating directory: [/opt/datax-web/modules/datax-executor/bin/../logs].</span><br><span class="line">2022-11-02 15:45:37.946 [INFO] (108159) Directory or file: [/opt/datax-web/modules/datax-executor/bin/../conf] has been exist</span><br><span class="line">2022-11-02 15:45:37.950 [INFO] (108159) Creating directory: [/opt/datax-web/modules/datax-executor/bin/../data].</span><br><span class="line">2022-11-02 15:45:37.989 [INFO] (108159) Creating directory: [/opt/datax-web/modules/datax-executor/bin/../json].</span><br><span class="line">2022-11-02 15:45:38.027 [INFO] (108078)  <span class="comment">####### Finish To Install Modules ######</span></span><br><span class="line">‘’‘</span><br></pre></td></tr></table></figure><h4 id="5-2-3-运行查看"><a href="#5-2-3-运行查看" class="headerlink" title="5.2.3 运行查看"></a>5.2.3 运行查看</h4><h5 id="1-启动datax-admin和datax-executor服务"><a href="#1-启动datax-admin和datax-executor服务" class="headerlink" title="1. 启动datax-admin和datax-executor服务"></a><strong>1. 启动datax-admin和datax-executor服务</strong></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./start-all.sh </span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-11-02 15:47:42.408 [INFO] (108231)  ####### Begin To Start Module: [datax-admin] ######</span></span><br><span class="line"><span class="string">2022-11-02 15:47:42.415 [INFO] (108239) load environment variables</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.091 [INFO] (108239) DATAX-ADMIN has been started in process</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.102 [INFO] (108396)  ####### Begin To Start Module: [datax-executor] ######</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.110 [INFO] (108404) load environment variables</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.592 [INFO] (108404) /usr/java/jdk1.8.0_341-amd64/bin/java</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.595 [INFO] (108404) Waiting DATAX-EXEXUTOR to start complete ...</span></span><br><span class="line"><span class="string">2022-11-02 15:48:06.153 [ERROR] (108223)  Start Modules [datax-executor] Failed!</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h5 id="2-查看启动是否成功"><a href="#2-查看启动是否成功" class="headerlink" title="2. 查看启动是否成功"></a>2. 查看启动是否成功</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">jps</span></span><br><span class="line"><span class="string">DataXExecutorApplication</span></span><br><span class="line"><span class="string">DataXAdminApplication</span></span><br><span class="line"><span class="string">Nailgun</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h5 id="3-WebUI查看-默认账号密码为：admin-123456"><a href="#3-WebUI查看-默认账号密码为：admin-123456" class="headerlink" title="3. WebUI查看,默认账号密码为：admin    123456"></a>3. WebUI查看,默认账号密码为：<strong>admin    123456</strong></h5><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span>huser@master bin<span class="punctuation">]</span>$ tail <span class="number">-50</span>f /opt/datax-web/modules/datax-admin/bin/console.out</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"><span class="number">16</span><span class="punctuation">:</span><span class="number">09</span><span class="punctuation">:</span><span class="number">10.035</span> admin <span class="punctuation">[</span>main<span class="punctuation">]</span> INFO  c.w.d.a.DataXAdminApplication - Access URLs<span class="punctuation">:</span></span><br><span class="line">----------------------------------------------------------</span><br><span class="line">Local-API<span class="punctuation">:</span> http<span class="punctuation">:</span><span class="comment">//127.0.0.1:9527/doc.html</span></span><br><span class="line">External-API<span class="punctuation">:</span> http<span class="punctuation">:</span><span class="comment">//192.168.33.147:9527/doc.html</span></span><br><span class="line">web-URL<span class="punctuation">:</span> http<span class="punctuation">:</span><span class="comment">//127.0.0.1:9527/index.html</span></span><br><span class="line">----------------------------------------------------------</span><br><span class="line"><span class="number">16</span><span class="punctuation">:</span><span class="number">09</span><span class="punctuation">:</span><span class="number">19.671</span> admin <span class="punctuation">[</span>http-nio<span class="number">-9527</span>-exec<span class="number">-1</span><span class="punctuation">]</span> INFO  o.a.c.c.C.<span class="punctuation">[</span>.<span class="punctuation">[</span>.<span class="punctuation">[</span>/<span class="punctuation">]</span> - Initializing Spring DispatcherServlet &#x27;dispatcherServlet&#x27;</span><br><span class="line"><span class="number">16</span><span class="punctuation">:</span><span class="number">09</span><span class="punctuation">:</span><span class="number">19.672</span> admin <span class="punctuation">[</span>http-nio<span class="number">-9527</span>-exec<span class="number">-1</span><span class="punctuation">]</span> INFO  o.s.w.s.DispatcherServlet - Initializing Servlet &#x27;dispatcherServlet&#x27;</span><br><span class="line"><span class="number">16</span><span class="punctuation">:</span><span class="number">09</span><span class="punctuation">:</span><span class="number">19.686</span> admin <span class="punctuation">[</span>http-nio<span class="number">-9527</span>-exec<span class="number">-1</span><span class="punctuation">]</span> INFO  o.s.w.s.DispatcherServlet - Completed initialization in <span class="number">14</span> ms</span><br><span class="line">&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>datax-web</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7lZ96.png" alt="datax-web" title="datax-web"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-dove modern&quot;&gt;&lt;p&gt;简介： &lt;a href=&quot;https://blog.csdn.net/weixin_46902396/article/details/121904705</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之Scala环境搭建(一)</title>
    <link href="https://xin0203xin0203.github.io/posts/411e35e9.html"/>
    <id>https://xin0203xin0203.github.io/posts/411e35e9.html</id>
    <published>2023-12-17T17:15:29.810Z</published>
    <updated>2024-12-18T15:44:44.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-inbox modern"><p>简介: 是一种多范式的编程语言，其设计的初衷是要集成面向对象编程和函数式编程的各种特性 。Scala 运 行 于Java平台（ Java 虚 拟 机 ）， 并 兼 容 现 有 的 Java 程 序 。</p></div><div class="tip error"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note success simple"><p>需要的安装包：<a href="https://www.scala-lang.org/download/2.11.12.html"><strong>Scala</strong></a>压缩包——&gt;<strong>scala-2.12.8.tgz</strong></p></div><h2 id="1-解压并改名"><a href="#1-解压并改名" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf scala<span class="number">-2.12</span><span class="number">.8</span>.tgz -C /opt/</span><br><span class="line">mv scala<span class="number">-2.12</span><span class="number">.8</span> scala</span><br></pre></td></tr></table></figure><h2 id="2-配置Scala环境变量"><a href="#2-配置Scala环境变量" class="headerlink" title="2. 配置Scala环境变量"></a>2. 配置Scala环境变量</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># scala</span></span><br><span class="line"><span class="keyword">export</span> SCALA_HOME=/opt/kafka</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/<span class="function">profile  <span class="title">slave2</span><span class="params">(slave1)</span>:/etc/profile</span></span><br></pre></td></tr></table></figure><h2 id="3-验证安装是否成功"><a href="#3-验证安装是否成功" class="headerlink" title="3. 验证安装是否成功"></a>3. 验证安装是否成功</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">scala</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Welcome to Scala 2.12.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_341).</span></span><br><span class="line"><span class="string">Type in expressions for evaluation. Or try :help.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; 11+6</span></span><br><span class="line"><span class="string">res0: Int = 17</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; 5</span></span><br><span class="line"><span class="string">res1: Int = 5</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-inbox modern&quot;&gt;&lt;p&gt;简介: 是一种多范式的编程语言，其设计的初衷是要集成面向对象编程和函数式编程的各种特性 。Scala 运 行 于Java平台（ Java 虚 拟 机 </summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之HA-Spark集群环境搭建(Yarn模式)(五)</title>
    <link href="https://xin0203xin0203.github.io/posts/924eec38.html"/>
    <id>https://xin0203xin0203.github.io/posts/924eec38.html</id>
    <published>2023-12-17T17:15:29.774Z</published>
    <updated>2024-12-18T19:24:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-shapes modern"><p>简介: <a href="https://so.csdn.net/so/search?q=Spark&amp;spm=1001.2101.3001.7020"><strong>Spark</strong></a>客户端直接连接Yarn，不需要额外构建Spark集群。有yarn-client和yarn-cluster两种模式，主要区别在于：Driver程序的运行节点。<br><a href="https://so.csdn.net/so/search?q=yarn&amp;spm=1001.2101.3001.7020"><strong>yarn</strong></a>-client：Driver程序运行在客户端，适用于交互、调试，希望立即看到app的输出。</p></div><div class="tip bolt"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%B8%89)Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Standalone%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/u25360462/nt1ri1/fchs9onh27cscex1?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7M9dh.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十三、Spark组件搭建之Spark集群环境搭建(Standalone模式)(三)</div>            <div class="tag-link-sitename">简介:SparkStandalone是**Master-Slaves架构的集群模式**，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E5%9B%9B)HA-Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Standalone%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/u25360462/nt1ri1/drrs4br8o8b4q51g?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MWsm.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十三、Spark组件搭建之HA-Spark集群环境搭建(Standalone模式)(四)</div>            <div class="tag-link-sitename">简介:SparkStandalone是**Master-Slaves架构的集群模式**，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-集群配置"><a href="#1-集群配置" class="headerlink" title="1. 集群配置"></a>1. 集群配置</h2><h3 id="1-1-配置spark-env-sh-SPARK-HOME-conf-目录下"><a href="#1-1-配置spark-env-sh-SPARK-HOME-conf-目录下" class="headerlink" title="1.1 配置spark-env.sh,${SPARK_HOME}/conf/目录下"></a>1.1 配置<strong>spark-env.sh</strong>,<code>$&#123;SPARK_HOME&#125;/conf/</code>目录下</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 添加:</span><br><span class="line"><span class="keyword">export</span> JAVA_HOME=/usr/java/jdk1<span class="number">.8</span><span class="number">.0</span>_341-amd64</span><br><span class="line"><span class="keyword">export</span> SCALA_HOME=/opt/scala</span><br><span class="line">YARN_CONF_DIR=/opt/hadoop/etc/hadoop</span><br><span class="line"><span class="keyword">export</span> SPARK_HISTORY_OPTS=<span class="string">&quot;-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=24 -Dspark.history.fs.logDirectory=hdfs://master:9000/spark-jobhistory&quot;</span></span><br><span class="line"><span class="keyword">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 -Dspark.deploy.zookeeper.dir=/opt/spark/data/&quot;</span></span><br></pre></td></tr></table></figure><h3 id="1-2-配置spark-defaults-conf"><a href="#1-2-配置spark-defaults-conf" class="headerlink" title="1.2 配置spark-defaults.conf"></a>1.2 <strong>配置spark-defaults.conf</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># spark.master                     spark:<span class="comment">//master:7077</span></span></span><br><span class="line">spark.master                     spark:<span class="comment">//master:7077,slave1:7077</span></span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line">spark.eventLog.dir               hdfs:<span class="comment">//master:9000/spark-jobhistory</span></span><br><span class="line">spark.yarn.historyServer.address               master:<span class="number">18080</span></span><br></pre></td></tr></table></figure><h3 id="1-3-配置workers-lt-font-color-red-gt-（如果配置，可以跳过）-lt-font-gt"><a href="#1-3-配置workers-lt-font-color-red-gt-（如果配置，可以跳过）-lt-font-gt" class="headerlink" title="1.3 配置workers&lt;/font color=red&gt;（如果配置，可以跳过）&lt;/font&gt;"></a>1.3 <strong>配置workers</strong>&lt;/font color=red&gt;（如果配置，可以跳过）&lt;/font&gt;</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-4-配置hadoop的yarn-site-xml"><a href="#1-4-配置hadoop的yarn-site-xml" class="headerlink" title="1.4 配置hadoop的yarn-site.xml"></a>1.4 <strong>配置hadoop的yarn-site.xml</strong></h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 由于测试环境的虚拟机内存太少, 防止将来任务被意外杀死, 做如下配置 --&gt;</span><br><span class="line">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是<span class="literal">true</span> --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是<span class="literal">true</span> --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://master:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="1-5-拷贝到slave1和slave2节点"><a href="#1-5-拷贝到slave1和slave2节点" class="headerlink" title="1.5 拷贝到slave1和slave2节点"></a>1.5 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/spark/<span class="function">conf  <span class="title">slave2</span><span class="params">(slave1)</span>:/opt/spark/</span></span><br><span class="line"><span class="function">sudo scp -r /opt/hadoop/etc/hadoop/yarn-site.xml  slave2(slave1):/opt/hadoop/etc/hadoop/</span></span><br></pre></td></tr></table></figure><h2 id="2-启动群集"><a href="#2-启动群集" class="headerlink" title="2. 启动群集"></a>2. 启动群集</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ HA-spark-allstart.sh(脚本)</span><br><span class="line">-------------------------&lt;-- <span class="string">&#x27;或者&#x27;</span> --&gt;-------------------------</span><br><span class="line"><span class="comment"># 启动ha-hadoop集群</span></span><br><span class="line">[huser@master bin]$ ./startdfs.sh(脚本)</span><br><span class="line"><span class="comment"># 在master启动spark集群</span></span><br><span class="line">[huser@master sbin]$ ./start-all.sh</span><br><span class="line"><span class="comment"># 在slave1上启动备Master</span></span><br><span class="line">[huser@slave1 sbin]$ ./start-master.sh</span><br><span class="line"><span class="comment"># 在master上启动任务历史服务器</span></span><br><span class="line">[huser@master sbin]$ ./start-history-server.sh</span><br></pre></td></tr></table></figure><h2 id="3-查看集群"><a href="#3-查看集群" class="headerlink" title="3. 查看集群"></a>3. 查看集群</h2><h3 id="3-1-jps进程查看"><a href="#3-1-jps进程查看" class="headerlink" title="3.1 jps进程查看"></a>3.1 jps进程查看</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">-----------master jps--------------</span><br><span class="line"><span class="number">27136</span> Master</span><br><span class="line"><span class="number">24961</span> QuorumPeerMain</span><br><span class="line"><span class="number">25937</span> NodeManager</span><br><span class="line"><span class="number">25587</span> JournalNode</span><br><span class="line"><span class="number">27203</span> Worker</span><br><span class="line"><span class="number">26149</span> JobHistoryServer</span><br><span class="line"><span class="number">27591</span> Jps</span><br><span class="line"><span class="number">25209</span> NameNode</span><br><span class="line"><span class="number">25785</span> DFSZKFailoverController</span><br><span class="line"><span class="number">25342</span> DataNode</span><br><span class="line">-----------slave1 jps--------------</span><br><span class="line"><span class="number">14130</span> Worker</span><br><span class="line"><span class="number">14195</span> Master</span><br><span class="line"><span class="number">14307</span> Jps</span><br><span class="line"><span class="number">12982</span> DataNode</span><br><span class="line"><span class="number">13190</span> DFSZKFailoverController</span><br><span class="line"><span class="number">12791</span> QuorumPeerMain</span><br><span class="line"><span class="number">13431</span> NodeManager</span><br><span class="line"><span class="number">13085</span> JournalNode</span><br><span class="line"><span class="number">12894</span> NameNode</span><br><span class="line"><span class="number">13342</span> ResourceManager</span><br><span class="line">-----------slave2 jps--------------</span><br><span class="line"><span class="number">14016</span> ResourceManager</span><br><span class="line"><span class="number">14818</span> Jps</span><br><span class="line"><span class="number">13638</span> DFSZKFailoverController</span><br><span class="line"><span class="number">13431</span> DataNode</span><br><span class="line"><span class="number">14679</span> Worker</span><br><span class="line"><span class="number">13534</span> JournalNode</span><br><span class="line"><span class="number">14142</span> NodeManager</span><br><span class="line"><span class="number">13247</span> QuorumPeerMain</span><br><span class="line"><span class="number">13343</span> NameNode</span><br></pre></td></tr></table></figure><h3 id="3-2-Web-UI查看"><a href="#3-2-Web-UI查看" class="headerlink" title="3.2 Web UI查看"></a>3.2 Web UI查看</h3><p>查看master日志信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@master sbin]$ <span class="built_in">cat</span> /opt/spark/logs/spark-huser-org.apache.spark.deploy.master.Master-1-master.out | grep MasterWebUI</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">22/11/08 16:37:29 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://master:8081</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>通过启动日志可以看到master的MasterWebUI的端口号为8081</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MKeQ.png" alt="HA-spark--Standalone--master--MasterWebUI" title="HA-spark--Standalone--master--MasterWebUI"></p><p>查看slave1日志信息<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 sbin]$ cat /opt/spark/logs/spark-huser-org.apache.spark.deploy.master.Master<span class="number">-1</span>-slave1.out | grep MasterWebUI</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">22</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">16</span>:<span class="number">37</span>:<span class="number">39</span> INFO MasterWebUI: Bound MasterWebUI to <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>, <span class="keyword">and</span> started at http:<span class="comment">//slave1:8082</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>通过启动日志可以看到slave1的MasterWebUI的端口号为8082</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--slave1--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MUTt.png" alt="HA-spark--Standalone--slave1--MasterWebUI" title="HA-spark--Standalone--slave1--MasterWebUI"></p><p>master上的任务历史服务器端口号为18080</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7M6fC.png" alt="HA-spark--Standalone--master--HistoryServer" title="HA-spark--Standalone--master--HistoryServer"></p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BHA-Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Yarn%E6%A8%A1%E5%BC%8F)-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/qOWSgXY8y7Lk0JOELoie_Q)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MgKu.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">HA-Spark集群环境搭建(Yarn模式)</div>            <div class="tag-link-sitename">HA-Spark集群环境搭建(Yarn模式)-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="4-计算-PI"><a href="#4-计算-PI" class="headerlink" title="4. 计算 PI"></a>4. 计算 PI</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[huser@master spark]$ bin/spark-submit --master yarn --class org.apache.spark.examples.SparkPi /opt/spark/examples/jars/spark-examples_2.12-3.1.3.jar 1000</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--executor-memory 1G 指定每个executor可用内存为1G</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--total-executor-cores 8 指定所有executor使用的cpu核数为8个</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--executor-cores 2 表示每个executor使用的 cpu 的核数</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Pi is roughly 3.1415244714152446</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,024 INFO server.AbstractConnector: Stopped Spark@182b435b&#123;HTTP/1.1, (http/1.1)&#125;&#123;0.0.0.0:4040&#125;</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,059 INFO ui.SparkUI: Stopped Spark web UI at http://master:4040</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,111 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,353 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,353 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,447 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,420 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,529 INFO memory.MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,530 INFO storage.BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,585 INFO storage.BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,596 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,615 INFO spark.SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,691 INFO util.ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,691 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-6860512e-a45c-4717-b9a4-5eb730761572</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,728 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-b5d11fa0-c090-4ef7-b1fb-5d8fb95e7edd</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>报错：<br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BSpark%20%E5%BC%82%E5%B8%B8%E6%80%BB%E7%BB%93%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95_%E7%81%B5%E4%BD%91666%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2%5D(https:/blog.csdn.net/onway_goahead/article/details/107688786?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-5-107688786-blog-107319283.pc_relevant_3mothn_strategy_recovery&spm=1001.2101.3001.4242.4&utm_relevant_index=7)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7M7Bo.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Spark 异常总结及解决办法</div>            <div class="tag-link-sitename">前言总结Spark开发中遇到的异常及解决办法，之前也写过几篇，之所以不再一个异常写一篇博客，是因为现在Spark</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><p>WebUI查看应用执行资源分配情况：</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone(yarn)--master--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MrFv.png" alt="HA-spark--Standalone(yarn)--master--MasterWebUI" title="HA-spark--Standalone(yarn)--master--MasterWebUI"></p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone(yarn)--slave1--yarn</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MVnE.png" alt="HA-spark--Standalone(yarn)--slave1--yarn" title="HA-spark--Standalone(yarn)--slave1--yarn"></p><p>最终计算结果如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">469</span> INFO scheduler.TaskSetManager: Finished task <span class="number">997.0</span> in stage <span class="number">0.0</span> (TID <span class="number">997</span>) in <span class="number">35</span> <span class="function">ms on <span class="title">master</span> <span class="params">(executor <span class="number">2</span>)</span> <span class="params">(<span class="number">998</span>/<span class="number">1000</span>)</span></span></span><br><span class="line"><span class="function">2022-11-09 18:<span class="number">22</span>:<span class="number">38</span>,<span class="number">469</span> INFO scheduler.TaskSetManager: Finished task <span class="number">998.0</span> in stage <span class="number">0.0</span> (TID <span class="number">998</span>) in <span class="number">21</span> ms on slave2 (executor <span class="number">1</span>) (<span class="number">999</span>/<span class="number">1000</span>)</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">500</span> INFO scheduler.TaskSetManager: Finished task <span class="number">999.0</span> in stage <span class="number">0.0</span> (TID <span class="number">999</span>) in <span class="number">36</span> ms on master (executor <span class="number">2</span>) (<span class="number">1000</span>/<span class="number">1000</span>)</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">506</span> INFO scheduler.DAGScheduler: ResultStage <span class="number">0</span> (reduce at SparkPi.scala:<span class="number">38</span>) finished in <span class="number">28.572</span> s</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">501</span> INFO cluster.YarnScheduler: Removed TaskSet <span class="number">0.0</span>, whose tasks have all completed, from pool </span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">546</span> INFO scheduler.DAGScheduler: Job <span class="number">0</span> is finished. Cancelling potential speculative or zombie tasks for this job</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">552</span> INFO cluster.YarnScheduler: Killing all running tasks in stage <span class="number">0</span>: Stage finished</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">570</span> INFO scheduler.DAGScheduler: Job <span class="number">0</span> finished: reduce at SparkPi.scala:<span class="number">38</span>, took <span class="number">29.256770</span> s</span></span><br><span class="line"><span class="function">Pi is roughly <span class="number">3.14160799141608</span></span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">756</span> INFO server.AbstractConnector: Stopped Spark@<span class="number">182b</span>435b&#123;</span>HTTP/<span class="number">1.1</span>, (http/<span class="number">1.1</span>)&#125;&#123;<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">4040</span>&#125;</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">768</span> INFO ui.SparkUI: Stopped Spark web UI at http:<span class="comment">//master:4040</span></span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">804</span> INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">889</span> INFO cluster.YarnClientSchedulerBackend: Shutting down all executors</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">890</span> INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">915</span> INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">558</span> INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">792</span> INFO memory.MemoryStore: MemoryStore cleared</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">797</span> INFO storage.BlockManager: BlockManager stopped</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">818</span> INFO storage.BlockManagerMaster: BlockManagerMaster stopped</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">830</span> INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">900</span> INFO spark.SparkContext: Successfully stopped SparkContext</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">931</span> INFO util.ShutdownHookManager: Shutdown hook called</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">932</span> INFO util.ShutdownHookManager: Deleting directory /tmp/spark<span class="number">-93</span>c34fa9-d1bb<span class="number">-4574</span>-a749<span class="number">-68424b</span>2b6b52</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">936</span> INFO util.ShutdownHookManager: Deleting directory /tmp/spark<span class="number">-2726b</span>04f<span class="number">-7</span>a71<span class="number">-44</span>d0<span class="number">-91</span>ce-a027bb47ea76</span><br></pre></td></tr></table></figure></p><p><strong>通过slave1上YARN的8088可以查看历史任务</strong></p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone(yarn)--slave1--yarn</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MYzY.png" alt="HA-spark--Standalone(yarn)--slave1--yarn" title="HA-spark--Standalone(yarn)--slave1--yarn"></p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone(yarn)--slave1--HistoryServer</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MhB9.png" alt="HA-spark--Standalone(yarn)--slave1--HistoryServer" title="HA-spark--Standalone(yarn)--slave1--HistoryServer"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-shapes modern&quot;&gt;&lt;p&gt;简介: &lt;a href=&quot;https://so.csdn.net/so/search?q=Spark&amp;amp;spm=1001.2101.3001.</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之HA-Spark集群环境搭建(Standalone模式)(四)</title>
    <link href="https://xin0203xin0203.github.io/posts/1ec96998.html"/>
    <id>https://xin0203xin0203.github.io/posts/1ec96998.html</id>
    <published>2023-12-17T17:15:29.748Z</published>
    <updated>2024-12-14T17:48:48.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-shapes modern"><p>简介:SparkStandalone是<strong>Master-Slaves架构的集群模式</strong>，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</p><ul><li>spark的集群主要有三种运行模式<a href="https://cn.bing.com/search?q=sparkstandalone%E6%A8%A1%E5%BC%8F&amp;qs=n&amp;form=QBRE&amp;sp=-1&amp;pq=sparkstandalone%E6%A8%A1%E5%BC%8F&amp;sc=0-17&amp;sk=&amp;cvid=D98F9B81667C42C1A400D5113697851B&amp;ghsh=0&amp;ghacc=0&amp;ghpl="><strong>standalone</strong></a><strong>、</strong><a href="yarn"><strong>yarn</strong></a><strong>、</strong><a href="https://blog.csdn.net/chikoucha6215/article/details/100855233?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166784048216782417079675%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166784048216782417079675&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-100855233-null-null.142^v63^pc_rank_34_queryrelevant25,201^v3^control_1,213^v1^control&amp;utm_term=mesos&amp;spm=1018.2226.3001.4187"><strong>mesos</strong></a>，其中常被使用的是standalone和yarn</li><li>standalone模式，是spark自己实现的，它是一个资源调度<a href="https://so.csdn.net/so/search?q=%E6%A1%86%E6%9E%B6&amp;spm=1001.2101.3001.7020">框架</a>。</li><li>spark应用程序有一个Driver驱动，Driver可以运行在Client上也可以运行在master上。如果你使用spark-shell去提交job的话它会是运行在master上的，如果你使用spark-submit或者IDEA开发工具方式运行，那么它是运行在Client上的。这样我们知道了，Client的主体作用就是运行Driver。而master除了资源调度的作用还可以运行Driver。</li></ul></div><div class="tip bolt"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%B8%89)Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Standalone%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/u25360462/nt1ri1/fchs9onh27cscex1?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7M9dh.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十三、Spark组件搭建之Spark集群环境搭建(Standalone模式)(三)</div>            <div class="tag-link-sitename">简介:SparkStandalone是**Master-Slaves架构的集群模式**，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-集群配置"><a href="#1-集群配置" class="headerlink" title="1. 集群配置"></a>1. 集群配置</h2><h3 id="1-1-配置spark-env-sh-SPARK-HOME-conf-目录下"><a href="#1-1-配置spark-env-sh-SPARK-HOME-conf-目录下" class="headerlink" title="1.1 配置spark-env.sh,${SPARK_HOME}/conf/ 目录下"></a>1.1 <strong>配置spark-env.sh</strong>,<code>$&#123;SPARK_HOME&#125;/conf/</code> 目录下</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> JAVA_HOME=/usr/java/jdk1<span class="number">.8</span><span class="number">.0</span>_341-amd64</span><br><span class="line"># 添加:</span><br><span class="line"><span class="keyword">export</span> SCALA_HOME=/opt/scala</span><br><span class="line"><span class="keyword">export</span> SPARK_HISTORY_OPTS=<span class="string">&quot;-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=24 -Dspark.history.fs.logDirectory=hdfs://master:9000/spark-jobhistory&quot;</span></span><br><span class="line"><span class="keyword">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 -Dspark.deploy.zookeeper.dir=/opt/spark/data/&quot;</span></span><br></pre></td></tr></table></figure><h3 id="1-2-配置spark-defaults-conf"><a href="#1-2-配置spark-defaults-conf" class="headerlink" title="1.2 配置spark-defaults.conf"></a>1.2 <strong>配置spark-defaults.conf</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># spark.master                     spark:<span class="comment">//master:7077</span></span></span><br><span class="line">spark.master                     spark:<span class="comment">//master:7077,slave1:7077</span></span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line">spark.eventLog.dir               hdfs:<span class="comment">//master:9000/spark-jobhistory</span></span><br></pre></td></tr></table></figure><h3 id="1-3-配置workers（如果配置，可以跳过）"><a href="#1-3-配置workers（如果配置，可以跳过）" class="headerlink" title="1.3 配置workers（如果配置，可以跳过）"></a>1.3 <strong>配置workers</strong><font color=red>（如果配置，可以跳过）</font></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-4-拷贝到slave1和slave2节点"><a href="#1-4-拷贝到slave1和slave2节点" class="headerlink" title="1.4 拷贝到slave1和slave2节点"></a>1.4 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/spark/<span class="function">conf  <span class="title">slave2</span><span class="params">(slave1)</span>:/opt/spark/</span></span><br></pre></td></tr></table></figure><h2 id="2-启动群集"><a href="#2-启动群集" class="headerlink" title="2. 启动群集"></a>2. 启动群集</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">huser@master</span> <span class="string">bin</span>]<span class="string">$</span> <span class="string">HA-spark-allstart.sh(脚本)</span></span><br><span class="line"><span class="string">-------------------------&lt;--</span> <span class="string">&#x27;或者&#x27;</span> <span class="string">--&gt;-------------------------</span></span><br><span class="line"><span class="comment"># 启动ha-hadoop集群</span></span><br><span class="line">[<span class="string">huser@master</span> <span class="string">bin</span>]<span class="string">$</span> <span class="string">./startdfs.sh(脚本)</span></span><br><span class="line"><span class="comment"># 在master启动spark集群</span></span><br><span class="line">[<span class="string">huser@master</span> <span class="string">sbin</span>]<span class="string">$</span> <span class="string">./start-all.sh</span></span><br><span class="line"><span class="comment"># 在slave1上启动备Master</span></span><br><span class="line">[<span class="string">huser@slave1</span> <span class="string">sbin</span>]<span class="string">$</span> <span class="string">./start-master.sh</span></span><br><span class="line"><span class="comment"># 在master上启动任务历史服务器</span></span><br><span class="line">[<span class="string">huser@master</span> <span class="string">sbin</span>]<span class="string">$</span> <span class="string">./start-history-server.sh</span></span><br></pre></td></tr></table></figure><h2 id="3-查看集群"><a href="#3-查看集群" class="headerlink" title="3. 查看集群"></a>3. 查看集群</h2><h3 id="3-1-jps进程查看"><a href="#3-1-jps进程查看" class="headerlink" title="3.1 jps进程查看"></a>3.1 jps进程查看</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">-----------master jps--------------</span><br><span class="line"><span class="number">125346</span> DataNode</span><br><span class="line"><span class="number">124965</span> QuorumPeerMain</span><br><span class="line"><span class="number">125591</span> JournalNode</span><br><span class="line"><span class="number">125959</span> NodeManager</span><br><span class="line"><span class="number">126360</span> Worker</span><br><span class="line"><span class="number">126267</span> Master</span><br><span class="line"><span class="number">125213</span> NameNode</span><br><span class="line"><span class="number">126477</span> HistoryServer</span><br><span class="line"><span class="number">126541</span> Jps</span><br><span class="line"><span class="number">126172</span> JobHistoryServer</span><br><span class="line"><span class="number">125790</span> DFSZKFailoverController</span><br><span class="line">-----------slave1 jps--------------</span><br><span class="line"><span class="number">95617</span> DataNode</span><br><span class="line"><span class="number">96464</span> Worker</span><br><span class="line"><span class="number">96547</span> Master</span><br><span class="line"><span class="number">95429</span> QuorumPeerMain</span><br><span class="line"><span class="number">95957</span> ResourceManager</span><br><span class="line"><span class="number">95828</span> DFSZKFailoverController</span><br><span class="line"><span class="number">95723</span> JournalNode</span><br><span class="line"><span class="number">96619</span> Jps</span><br><span class="line"><span class="number">96042</span> NodeManager</span><br><span class="line"><span class="number">95532</span> NameNode</span><br><span class="line">-----------slave2 jps--------------</span><br><span class="line"><span class="number">92272</span> DataNode</span><br><span class="line"><span class="number">92483</span> DFSZKFailoverController</span><br><span class="line"><span class="number">93190</span> Worker</span><br><span class="line"><span class="number">92984</span> NodeManager</span><br><span class="line"><span class="number">92091</span> QuorumPeerMain</span><br><span class="line"><span class="number">92187</span> NameNode</span><br><span class="line"><span class="number">93259</span> Jps</span><br><span class="line"><span class="number">92378</span> JournalNode</span><br><span class="line"><span class="number">92860</span> ResourceManager</span><br></pre></td></tr></table></figure><h3 id="3-2-Web-UI查看"><a href="#3-2-Web-UI查看" class="headerlink" title="3.2 Web UI查看"></a>3.2 Web UI查看</h3><p>查看master日志信息<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@master sbin]$ cat /opt/spark/logs/spark-huser-org.apache.spark.deploy.master.Master<span class="number">-1</span>-master.out | grep MasterWebUI</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">22</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">16</span>:<span class="number">37</span>:<span class="number">29</span> INFO MasterWebUI: Bound MasterWebUI to <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>, <span class="keyword">and</span> started at http:<span class="comment">//master:8081</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>通过启动日志可以看到master的MasterWebUI的端口号为8081</p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MwKT.png" alt="HA-spark--Standalone--master--MasterWebUI" title="HA-spark--Standalone--master--MasterWebUI"></p><p>查看slave1日志信息<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 sbin]$ cat /opt/spark/logs/spark-huser-org.apache.spark.deploy.master.Master<span class="number">-1</span>-slave1.out | grep MasterWebUI</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">22</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">16</span>:<span class="number">37</span>:<span class="number">39</span> INFO MasterWebUI: Bound MasterWebUI to <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>, <span class="keyword">and</span> started at http:<span class="comment">//slave1:8082</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>通过启动日志可以看到slave1的MasterWebUI的端口号为8082</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--slave1--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MQiK.png" alt="HA-spark--Standalone--slave1--MasterWebUI" title="HA-spark--Standalone--slave1--MasterWebUI"></p><p>master上的任务历史服务器端口号为18080</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--HistoryServer</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MNF1.png" alt="HA-spark--Standalone--master--HistoryServer" title="HA-spark--Standalone--master--HistoryServer"></p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="https://vip.helloimg.com/images/2023/12/18/o7Mpzb.jpg">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="">          <i class="anzhiyufont anzhiyu-icon-link" style=""></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">HA-Spark集群环境搭建(Standalone模式)</div>            <div class="tag-link-sitename">HA-Spark集群环境搭建(Standalone模式)-视频教程[HA-Spark集群环境搭建(Standalone模式)-视频教程](https://mp.weixin.qq.com/s/9EBu5GD_jHUoLfOL3mntvA)</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="4-计算-PI"><a href="#4-计算-PI" class="headerlink" title="4. 计算 PI"></a>4. 计算 PI</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[huser@master spark]$ bin/spark-submit --master spark://master:7077,slave1:7077,slave2:7077 --executor-memory 1G --total-executor-cores 2 --executor-cores 1 --class org.apache.spark.examples.SparkPi /opt/spark/examples/jars/spark-examples_2.12-3.1.3.jar 10000</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--executor-memory 1G 指定每个executor可用内存为1G</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--total-executor-cores 8 指定所有executor使用的cpu核数为8个</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--executor-cores 2 表示每个executor使用的 cpu 的核数</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Endpoint stopped!</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-7a0bd8da-0f5f-43a2-adeb-6c48c3169cdc</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-ba12bd46-aaa1-4b2a-9a25-111bb963027c</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>报错：<br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BSpark%20%E5%BC%82%E5%B8%B8%E6%80%BB%E7%BB%93%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95_%E7%81%B5%E4%BD%91666%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2%5D(https:/blog.csdn.net/onway_goahead/article/details/107688786?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-5-107688786-blog-107319283.pc_relevant_3mothn_strategy_recovery&spm=1001.2101.3001.4242.4&utm_relevant_index=7)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7M7Bo.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Spark 异常总结及解决办法</div>            <div class="tag-link-sitename">前言总结Spark开发中遇到的异常及解决办法，之前也写过几篇，之所以不再一个异常写一篇博客，是因为现在Spark</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><p>WebUI查看应用执行资源分配情况：</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--PI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MDsD.png" alt="HA-spark--Standalone--master--PI" title="HA-spark--Standalone--master--PI"></p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--slave1--PI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MIvS.png" alt="HA-spark--Standalone--slave1--PI" title="HA-spark--Standalone--slave1--PI"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-shapes modern&quot;&gt;&lt;p&gt;简介:SparkStandalone是&lt;strong&gt;Master-Slaves架构的集群模式&lt;/strong&gt;，和大部分的Master-Slave</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之Spark集群环境搭建(Standalone模式)(三)</title>
    <link href="https://xin0203xin0203.github.io/posts/e1fbbea6.html"/>
    <id>https://xin0203xin0203.github.io/posts/e1fbbea6.html</id>
    <published>2023-12-17T17:15:29.724Z</published>
    <updated>2024-12-18T17:00:03.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-shapes modern"><p>简介:SparkStandalone是<strong>Master-Slaves架构的集群模式</strong>，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</p><ul><li>spark的集群主要有三种运行模式<a href="https://cn.bing.com/search?q=sparkstandalone%E6%A8%A1%E5%BC%8F&amp;qs=n&amp;form=QBRE&amp;sp=-1&amp;pq=sparkstandalone%E6%A8%A1%E5%BC%8F&amp;sc=0-17&amp;sk=&amp;cvid=D98F9B81667C42C1A400D5113697851B&amp;ghsh=0&amp;ghacc=0&amp;ghpl="><strong>standalone</strong></a><strong>、</strong><a href="yarn"><strong>yarn</strong></a><strong>、</strong><a href="https://blog.csdn.net/chikoucha6215/article/details/100855233?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166784048216782417079675%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166784048216782417079675&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-100855233-null-null.142^v63^pc_rank_34_queryrelevant25,201^v3^control_1,213^v1^control&amp;utm_term=mesos&amp;spm=1018.2226.3001.4187"><strong>mesos</strong></a>，其中常被使用的是standalone和yarn</li><li>standalone模式，是spark自己实现的，它是一个资源调度<a href="https://so.csdn.net/so/search?q=%E6%A1%86%E6%9E%B6&amp;spm=1001.2101.3001.7020">框架</a>。</li><li>spark应用程序有一个Driver驱动，Driver可以运行在Client上也可以运行在master上。如果你使用spark-shell去提交job的话它会是运行在master上的，如果你使用spark-submit或者IDEA开发工具方式运行，那么它是运行在Client上的。这样我们知道了，Client的主体作用就是运行Driver。而master除了资源调度的作用还可以运行Driver。</li></ul></div><div class="tip bolt"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note warning simple"><p><strong>[</strong>Spark<strong>](<a href="https://spark.apache.org/downloads.html)压缩包----&gt;spark-3.1.3-bin-hadoop3.2.tgz">https://spark.apache.org/downloads.html)压缩包----&gt;spark-3.1.3-bin-hadoop3.2.tgz</a></strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-3.1.3-bin-hadoop3.2.tgz -C /opt/</span><br><span class="line"><span class="built_in">mv</span> spark-3.1.3-bin-hadoop3.2 spark</span><br></pre></td></tr></table></figure><h2 id="2-配置Spark环境变量"><a href="#2-配置Spark环境变量" class="headerlink" title="2. 配置Spark环境变量"></a>2. 配置Spark环境变量</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># 添加：</span></span><br><span class="line"><span class="comment"># spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/opt/kafka</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/profile  slave2(slave1):/etc/profile</span><br></pre></td></tr></table></figure><h2 id="3-配置文件"><a href="#3-配置文件" class="headerlink" title="3. 配置文件"></a>3. 配置文件</h2><h3 id="3-1-配置spark-env-sh-SPARK-HOME-conf-目录下"><a href="#3-1-配置spark-env-sh-SPARK-HOME-conf-目录下" class="headerlink" title="3.1 配置spark-env.sh,${SPARK_HOME}/conf/ 目录下"></a>3.1 <strong>配置spark-env.sh</strong>,<code>$&#123;SPARK_HOME&#125;/conf/</code> 目录下</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> spark-env.sh.template spark-env.sh</span><br><span class="line"><span class="comment"># 添加:</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_341-amd64</span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/opt/scala</span><br><span class="line">SPARK_MASTER_HOST=master</span><br><span class="line"><span class="comment"># 默认端口就是7077, 可以省略不配</span></span><br><span class="line">SPARK_MASTER_PORT=7077</span><br></pre></td></tr></table></figure><h3 id="3-2-配置workers"><a href="#3-2-配置workers" class="headerlink" title="3.2 配置workers"></a>3.2 <strong>配置workers</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> workers.template workers</span><br><span class="line"><span class="comment"># 添加:</span></span><br><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="3-3-拷贝到slave1和slave2节点"><a href="#3-3-拷贝到slave1和slave2节点" class="headerlink" title="3.3 拷贝到slave1和slave2节点"></a>3.3 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/spark  slave2(slave1):/opt/</span><br></pre></td></tr></table></figure><h2 id="4-启动群集"><a href="#4-启动群集" class="headerlink" title="4. 启动群集"></a>4. 启动群集</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master sbin]$ ./start-all.sh</span><br></pre></td></tr></table></figure><h2 id="5-查看集群"><a href="#5-查看集群" class="headerlink" title="5. 查看集群"></a>5. 查看集群</h2><h3 id="5-1-jps进程查看"><a href="#5-1-jps进程查看" class="headerlink" title="5.1 jps进程查看"></a>5.1 jps进程查看</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">101990 Jps</span><br><span class="line">101944 Worker</span><br><span class="line">101870 Master</span><br></pre></td></tr></table></figure><h3 id="5-2-Web-UI查看"><a href="#5-2-Web-UI查看" class="headerlink" title="5.2 Web UI查看"></a>5.2 Web UI查看</h3><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>spark--Standalone</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MOYc.png" alt="spark--Standalone" title="spark--Standalone"></p><h2 id="6-计算-PI"><a href="#6-计算-PI" class="headerlink" title="6. 计算 PI"></a>6. 计算 PI</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[huser@master spark]$ bin/spark-submit --master spark://master:7077 --executor-memory 1G --total-executor-cores 2 --executor-cores 1 --class org.apache.spark.examples.SparkPi /opt/spark/examples/jars/spark-examples_2.12-3.1.3.jar 1000</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--executor-memory 1G 指定每个executor可用内存为1G</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--total-executor-cores 8 指定所有executor使用的cpu核数为8个</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--executor-cores 2 表示每个executor使用的 cpu 的核数</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Endpoint stopped!</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-7a0bd8da-0f5f-43a2-adeb-6c48c3169cdc</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-ba12bd46-aaa1-4b2a-9a25-111bb963027c</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>WebUI查看应用执行资源分配情况：</p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>spark--Standalone--PI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7Mdeq.png" alt="spark--Standalone--PI" title="spark--Standalone--PI"></p><h2 id="7-配置任务历史服务器"><a href="#7-配置任务历史服务器" class="headerlink" title="7. 配置任务历史服务器"></a>7. 配置任务历史服务器</h2><p>在 Spark-shell 没有退出之前， 我们是可以看到正在执行的任务的日志情况：<font color=orange><a href="http://hadoop01:4040">http://hadoop01:4040</a></font>, 但是退出 Spark-shell 之后， 执行的所有任务记录全部丢失。所以需要配置任务的历史服务器, 方便在任何需要的时候去查看日志。</p><h3 id="7-1-配置spark-defaults-conf-进入-SPARK-HOME-conf目录下"><a href="#7-1-配置spark-defaults-conf-进入-SPARK-HOME-conf目录下" class="headerlink" title="7.1 配置spark-defaults.conf, 进入 ${SPARK_HOME}/conf目录下"></a>7.1 <strong>配置spark-defaults.conf</strong>, 进入 <code>$&#123;SPARK_HOME&#125;/conf</code>目录下</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> spark-defaults.conf.template spark-defaults.conf</span><br><span class="line">vim spark-defaults.conf</span><br><span class="line"><span class="comment"># 添加:</span></span><br><span class="line">spark.master                     spark://master:7077</span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line">spark.eventLog.<span class="built_in">dir</span>               hdfs://master:9000/directory</span><br></pre></td></tr></table></figure><h3 id="7-2-配置spark-env-sh"><a href="#7-2-配置spark-env-sh" class="headerlink" title="7.2 配置spark-env.sh"></a>7.2 <strong>配置spark-env.sh</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HISTORY_OPTS=<span class="string">&quot;-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=30 -Dspark.history.fs.logDirectory=hdfs://master:9000/spark-jobhistory&quot;</span></span><br></pre></td></tr></table></figure><h3 id="7-3-拷贝到slave1和slave2节点"><a href="#7-3-拷贝到slave1和slave2节点" class="headerlink" title="7.3 拷贝到slave1和slave2节点"></a>7.3 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/spark/conf/  slave2(slave1):/opt/spark/</span><br></pre></td></tr></table></figure><h3 id="7-4-启动"><a href="#7-4-启动" class="headerlink" title="7.4 启动"></a>7.4 启动</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./startdfs.<span class="built_in">sh</span>(脚本)  ----   启动集群</span><br><span class="line">[huser@master sbin]$ ./start-all.sh  ----   启动spark服务</span><br><span class="line">[huser@master sbin]$ ./start-history-server.sh  ----   启动spark日志</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">104222</span> HistoryServer</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="7-5-在HDFS上创建spark-jobhistory目录"><a href="#7-5-在HDFS上创建spark-jobhistory目录" class="headerlink" title="7.5 在HDFS上创建spark-jobhistory目录"></a>7.5 在HDFS上创建<code>spark-jobhistory目录</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">mkdir</span> /spark-jobhistory</span><br></pre></td></tr></table></figure><h3 id="7-6-jps进程查看"><a href="#7-6-jps进程查看" class="headerlink" title="7.6 jps进程查看"></a>7.6 jps进程查看</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./allJps.sh.sh(脚本)  ----   查看节点</span><br><span class="line">-----------master jps--------------</span><br><span class="line">109888 QuorumPeerMain</span><br><span class="line">110515 JournalNode</span><br><span class="line">110883 NodeManager</span><br><span class="line">111095 JobHistoryServer</span><br><span class="line">111990 HistoryServer</span><br><span class="line">110136 NameNode</span><br><span class="line">112139 Jps</span><br><span class="line">110714 DFSZKFailoverController</span><br><span class="line">110269 DataNode</span><br><span class="line">111405 Worker</span><br><span class="line">111279 Master</span><br><span class="line">-----------slave1 jps--------------</span><br><span class="line">90992 NameNode</span><br><span class="line">91504 NodeManager</span><br><span class="line">92483 Jps</span><br><span class="line">91077 DataNode</span><br><span class="line">90889 QuorumPeerMain</span><br><span class="line">91288 DFSZKFailoverController</span><br><span class="line">91418 ResourceManager</span><br><span class="line">92077 Worker</span><br><span class="line">91183 JournalNode</span><br><span class="line">-----------slave2 jps--------------</span><br><span class="line">86897 QuorumPeerMain</span><br><span class="line">86993 NameNode</span><br><span class="line">87185 JournalNode</span><br><span class="line">87667 ResourceManager</span><br><span class="line">88581 Jps</span><br><span class="line">87078 DataNode</span><br><span class="line">88153 Worker</span><br><span class="line">87290 DFSZKFailoverController</span><br><span class="line">87791 NodeManager</span><br></pre></td></tr></table></figure><h3 id="7-7-Web-UI查看"><a href="#7-7-Web-UI查看" class="headerlink" title="7.7 Web UI查看"></a>7.7 Web UI查看</h3><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>spark--Standalone--HistoryServer</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7Mv2r.png" alt="spark--Standalone--HistoryServer" title="spark--Standalone--HistoryServer"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-shapes modern&quot;&gt;&lt;p&gt;简介:SparkStandalone是&lt;strong&gt;Master-Slaves架构的集群模式&lt;/strong&gt;，和大部分的Master-Slave</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之Spark-Local模式环境搭建(二)</title>
    <link href="https://xin0203xin0203.github.io/posts/dc6661ea.html"/>
    <id>https://xin0203xin0203.github.io/posts/dc6661ea.html</id>
    <published>2023-12-17T17:15:29.689Z</published>
    <updated>2024-12-18T16:14:01.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-history modern"><p>简介：Spark是一种<font color=red>快速、通用、可扩展的大数据分析引擎</font>，2009年诞生于加州大学伯克利分校AMPLab，2010年开源，2013年6月成为Apache孵化项目，2014年2月成为Apache顶级项目。目前，Spark生态系统已经发展成为一个包含多个子项目的集合，其中包含SparkSQL、SparkStreaming、GraphX、MLlib等子项目，Spark是基于内存计算的大数据并行计算框架。Spark基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了<font color=red>高容错性和高可伸缩性</font>，允许用户将Spark部署在大量廉价硬件之上，形成集群。Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于凤巢、大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。</p><ul><li><strong>与Hadoop的MapReduce相比，Spark基于内存的运算要快100倍以上，基于硬盘的运算也要快10倍以上。Spark实现了高效的DAG(有向无环图)执行引擎，可以通过基于内存来高效处理数据流。</strong></li><li><strong>Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。</strong></li><li><strong>Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。</strong></li><li><strong>Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。</strong></li></ul></div><div class="tip warning"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%B8%80)Scala%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/u25360462/nt1ri1/grya7qs4bau5x7q0?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MliA.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十三、Spark组件搭建之Scala环境搭建(一)</div>            <div class="tag-link-sitename">简介: 是一种多范式的编程语言，其设计的初衷是要集成面向对象编程和函数式编程的各种特性 。Scala 运 行 于Java平台（ Java 虚 拟 机 ）， 并 兼 容 现 有 的 Java 程 序 。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note info simple"><p><a href="https://spark.apache.org/downloads.html"><strong>Spark</strong></a>压缩包——&gt;<strong>spark-3.1.3-bin-hadoop3.2.tgz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark<span class="number">-3.1</span><span class="number">.3</span>-bin-hadoop3<span class="number">.2</span>.tgz -C /opt/</span><br><span class="line">mv spark<span class="number">-3.1</span><span class="number">.3</span>-bin-hadoop3<span class="number">.2</span> spark</span><br></pre></td></tr></table></figure><h2 id="2-配置Spark环境变量"><a href="#2-配置Spark环境变量" class="headerlink" title="2. 配置Spark环境变量"></a>2. 配置Spark环境变量</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># spark</span></span><br><span class="line"><span class="keyword">export</span> SPARK_HOME=/opt/kafka</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/<span class="function">profile  <span class="title">slave2</span><span class="params">(slave1)</span>:/etc/profile</span></span><br></pre></td></tr></table></figure><h2 id="3-配置spark-env-sh-SPARK-HOME-conf-目录下"><a href="#3-配置spark-env-sh-SPARK-HOME-conf-目录下" class="headerlink" title="3. 配置spark-env.sh,${SPARK_HOME}/conf/目录下"></a>3. <strong>配置spark-env.sh</strong>,<code>$&#123;SPARK_HOME&#125;/conf/</code>目录下</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cp spark-env.sh.<span class="keyword">template</span> spark-env.sh</span><br><span class="line"># 添加:</span><br><span class="line"><span class="keyword">export</span> JAVA_HOME=/usr/java/jdk1<span class="number">.8</span><span class="number">.0</span>_341-amd64</span><br><span class="line"><span class="keyword">export</span> SCALA_HOME=/opt/scala</span><br><span class="line">SPARK_LOCAL_IP=master</span><br><span class="line">    </span><br><span class="line"># Options read when launching programs locally with</span><br><span class="line"># ./bin/run-example <span class="keyword">or</span> ./bin/spark-submit</span><br><span class="line"># - HADOOP_CONF_DIR, to point Spark towards Hadoop configuration files</span><br><span class="line"># - SPARK_PUBLIC_DNS, to set the <span class="keyword">public</span> dns name of the driver program</span><br></pre></td></tr></table></figure><h2 id="4-启动测试"><a href="#4-启动测试" class="headerlink" title="4. 启动测试"></a>4. 启动测试</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./spark-shell</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">22</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">59</span> WARN NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... <span class="keyword">using</span> builtin-java classes where applicable</span><br><span class="line">Using Spark<span class="number">&#x27;</span>s <span class="keyword">default</span> log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line">Setting <span class="keyword">default</span> log level to <span class="string">&quot;WARN&quot;</span>.</span><br><span class="line">To adjust logging level use sc.<span class="built_in">setLogLevel</span>(newLevel). For SparkR, <span class="function">use <span class="title">setLogLevel</span><span class="params">(newLevel)</span>.</span></span><br><span class="line"><span class="function">Spark context Web UI available at http://master:<span class="number">4040</span></span></span><br><span class="line"><span class="function">Spark context available as <span class="string">&#x27;sc&#x27;</span> (master =</span> local[*], app id = local<span class="number">-1667838916404</span>).</span><br><span class="line">Spark session available as <span class="string">&#x27;spark&#x27;</span>.</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  <span class="string">&#x27;_/</span></span><br><span class="line"><span class="string">   /___/ .__/\_,_/_/ /_/\_\   version 3.1.3</span></span><br><span class="line"><span class="string">      /_/</span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">Using Scala version 2.12.10 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_341)</span></span><br><span class="line"><span class="string">Type in expressions to have them evaluated.</span></span><br><span class="line"><span class="string">Type :help for more information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; </span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="5-wordcount案例"><a href="#5-wordcount案例" class="headerlink" title="5. wordcount案例"></a>5. wordcount案例</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 准备一个需要统计词频的小文件，部分词频数据：</span><br><span class="line">● 支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；</span><br><span class="line">● 支持数据实时处理；</span><br><span class="line">● 能保证消息的可靠性投递；</span><br><span class="line">● 支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；</span><br><span class="line">● 高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Spark之WordCount案例实操：</span><br><span class="line">scala&gt; val result=sc.<span class="built_in">textFile</span>(<span class="string">&quot;file:///opt/spark/data/cs.txt&quot;</span>).<span class="built_in">flatMap</span>(_.<span class="built_in">split</span>(<span class="string">&quot;\t&quot;</span>)).<span class="built_in">map</span>((_,<span class="number">1</span>)).<span class="built_in">reduceByKey</span>(_ + _).collect</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">[Stage <span class="number">0</span>:&gt;                                                          (<span class="number">0</span> + <span class="number">1</span>) / </span><br><span class="line">result: Array[(String, Int)] = <span class="built_in">Array</span>((● 支持数据实时处理；,<span class="number">1</span>), (● 支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；,<span class="number">1</span>), (● 支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；,<span class="number">1</span>), (● 能保证消息的可靠性投递；,<span class="number">1</span>), (● 高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。,<span class="number">1</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>查看 Spark Web UI 界面，端口为4040：</p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>spark--wordcount</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MT50.png" alt="spark--wordcount" title="spark--wordcount"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-history modern&quot;&gt;&lt;p&gt;简介：Spark是一种&lt;font color=red&gt;快速、通用、可扩展的大数据分析引擎&lt;/font&gt;，2009年诞生于加州大学伯克利分校AMPL</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>五、HBase组件(hive模块等更新)</title>
    <link href="https://xin0203xin0203.github.io/posts/ff0c941c.html"/>
    <id>https://xin0203xin0203.github.io/posts/ff0c941c.html</id>
    <published>2023-12-17T17:15:29.673Z</published>
    <updated>2024-12-17T20:12:52.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-file-word modern"><p>介绍：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的<a href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/6608875?fromModule=lemma_inlink"><strong>分布式存储系统</strong></a>”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。</p></div><div class="tip warning"><p>前提准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%BA%8C%E3%80%81zookeeper%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/u25360462/nt1ri1/wzn655?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7LkQP.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">二、zookeeper组件搭建</div>            <div class="tag-link-sitename">介绍：Zookeeper 是一个开源的分布式协调服务，目前由 Apache 进行维护。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note success simple"><p>需要的安装包：<a href="http://archive.apache.org/dist/hbase/"><strong>HBase</strong></a>镜像——&gt;<strong>hbase-1.4.13-bin.tar.gz</strong></p></div><h1 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h1><h3 id="4-1-1-软件下载并解压"><a href="#4-1-1-软件下载并解压" class="headerlink" title="4.1.1 软件下载并解压"></a>4.1.1 软件下载并解压</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget http://archive.apache.org/dist/hbase/1.4.13/hbase-1.4.13-bin.tar.gz</span><br><span class="line">tar -zxvf hbase-1.4.13-bin.tar.gz</span><br></pre></td></tr></table></figure><h3 id="4-1-2-改名"><a href="#4-1-2-改名" class="headerlink" title="4.1.2 改名"></a>4.1.2 改名</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> hbase-1.4.13/ /opt/hbase</span><br></pre></td></tr></table></figure><h3 id="4-1-3-配置环境变量"><a href="#4-1-3-配置环境变量" class="headerlink" title="4.1.3 配置环境变量"></a>4.1.3 配置环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># HBASE_HOME</span></span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/opt/hbase</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HBASE_HOME</span>/bin</span><br></pre></td></tr></table></figure><h3 id="4-1-4-生效并查看版本"><a href="#4-1-4-生效并查看版本" class="headerlink" title="4.1.4 生效并查看版本"></a>4.1.4 生效并查看版本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line">hbase</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Usage: hbase [&lt;options&gt;] &lt;command&gt; [&lt;args&gt;]</span></span><br><span class="line"><span class="string">Options:</span></span><br><span class="line"><span class="string">  --config DIR     Configuration direction to use. Default: ./conf</span></span><br><span class="line"><span class="string">  --hosts HOSTS    Override the list in &#x27;</span>regionservers<span class="string">&#x27; file</span></span><br><span class="line"><span class="string">  --auth-as-server Authenticate to ZooKeeper using servers configuration</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Commands:</span></span><br><span class="line"><span class="string">Some commands take arguments. Pass no args or -h for usage.</span></span><br><span class="line"><span class="string">  shell           Run the HBase shell</span></span><br><span class="line"><span class="string">  hbck            Run the hbase &#x27;</span>fsck<span class="string">&#x27; tool</span></span><br><span class="line"><span class="string">  snapshot        Tool for managing snapshots</span></span><br><span class="line"><span class="string">  snapshotinfo    Tool for dumping snapshot information</span></span><br><span class="line"><span class="string">  wal             Write-ahead-log analyzer</span></span><br><span class="line"><span class="string">  hfile           Store file analyzer</span></span><br><span class="line"><span class="string">  zkcli           Run the ZooKeeper shell</span></span><br><span class="line"><span class="string">  upgrade         Upgrade hbase</span></span><br><span class="line"><span class="string">  master          Run an HBase HMaster node</span></span><br><span class="line"><span class="string">  regionserver    Run an HBase HRegionServer node</span></span><br><span class="line"><span class="string">  zookeeper       Run a Zookeeper server</span></span><br><span class="line"><span class="string">  rest            Run an HBase REST server</span></span><br><span class="line"><span class="string">  thrift          Run the HBase Thrift server</span></span><br><span class="line"><span class="string">  thrift2         Run the HBase Thrift2 server</span></span><br><span class="line"><span class="string">  clean           Run the HBase clean up script</span></span><br><span class="line"><span class="string">  classpath       Dump hbase CLASSPATH</span></span><br><span class="line"><span class="string">  mapredcp        Dump CLASSPATH entries required by mapreduce</span></span><br><span class="line"><span class="string">  pe              Run PerformanceEvaluation</span></span><br><span class="line"><span class="string">  ltt             Run LoadTestTool</span></span><br><span class="line"><span class="string">  canary          Run the Canary tool</span></span><br><span class="line"><span class="string">  hbtop           Run the HBTop tool</span></span><br><span class="line"><span class="string">  version         Print the version</span></span><br><span class="line"><span class="string">  CLASSNAME       Run the class named CLASSNAME</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="4-1-5-拷贝到slave1和slave2节点"><a href="#4-1-5-拷贝到slave1和slave2节点" class="headerlink" title="4.1.5 拷贝到slave1和slave2节点"></a>4.1.5 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/profile slave2(slave1):/etc/profile</span><br></pre></td></tr></table></figure><h1 id="2-修改配置"><a href="#2-修改配置" class="headerlink" title="2. 修改配置"></a>2. 修改配置</h1><h3 id="4-2-1-添加存储元数据文件-创建在目录-opt-hbase下"><a href="#4-2-1-添加存储元数据文件-创建在目录-opt-hbase下" class="headerlink" title="4.2.1 添加存储元数据文件,创建在目录/opt/hbase下"></a>4.2.1 添加存储元数据文件,创建在<code>目录/opt/hbase下</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> tmp zookeeper_data</span><br></pre></td></tr></table></figure><h3 id="4-2-1-目录下的-opt-hbase-conf-配置hbase-env-sh-把原基础的配置信息全去掉"><a href="#4-2-1-目录下的-opt-hbase-conf-配置hbase-env-sh-把原基础的配置信息全去掉" class="headerlink" title="4.2.1 目录下的/opt/hbase/conf, 配置hbase-env.sh,把原基础的配置信息全去掉"></a>4.2.1 目录下的<code>/opt/hbase/conf</code>, <strong>配置hbase-env.sh</strong>,把原基础的配置信息全去掉</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_341-amd64</span><br><span class="line"><span class="comment">#表示不引用hbase自带的zookeeper，用我们自己安装的</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure><h3 id="4-2-2-配置hbase-site-xml"><a href="#4-2-2-配置hbase-site-xml" class="headerlink" title="4.2.2 配置hbase-site.xml"></a>4.2.2 <strong>配置hbase-site.xml</strong></h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">    &lt;!-- 指定 <span class="title class_">HBase</span> 以分布式模式运行 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">    &lt;!-- 指定 <span class="title class_">HBase</span> 数据存储路径为 <span class="variable constant_">HDFS</span> 上的 hbase 目录,hbase 目录不需要预先创建，程序会自动创</span><br><span class="line">建 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hacluster/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">    &lt;!-- <span class="title class_">HBase</span>临时数据存储目录 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hbase/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">    &lt;!-- 指定 zookeeper 地址和端口 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:2181,slave1:2181,slave2:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">    &lt;!-- zookeeper数据存放位置 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hbase/zookeeper_data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="4-2-3-配置regionservers服务器列表"><a href="#4-2-3-配置regionservers服务器列表" class="headerlink" title="4.2.3 配置regionservers服务器列表"></a>4.2.3 <strong>配置regionservers服务器列表</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="4-2-4-链接hdfs配置"><a href="#4-2-4-链接hdfs配置" class="headerlink" title="4.2.4 链接hdfs配置"></a>4.2.4 <strong>链接hdfs配置</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s <span class="variable">$HADOOP_HOME</span>/etc/hadoop/core-site.xml /opt/hbase/conf/core-site.xml</span><br><span class="line"><span class="built_in">ln</span> -s <span class="variable">$HADOOP_HOME</span>/etc/hadoop/hdfs-site.xml /opt/hbase/conf/hdfs-site.xml</span><br></pre></td></tr></table></figure><h3 id="4-2-5-拷贝到slave1和slave2节点"><a href="#4-2-5-拷贝到slave1和slave2节点" class="headerlink" title="4.2.5 拷贝到slave1和slave2节点"></a>4.2.5 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/hbase/ slave1(slave2):/opt/</span><br></pre></td></tr></table></figure><h3 id="4-2-6-如果出现权限不够，因为拷贝文件的用户是root，要修改huser用户"><a href="#4-2-6-如果出现权限不够，因为拷贝文件的用户是root，要修改huser用户" class="headerlink" title="4.2.6 如果出现权限不够，因为拷贝文件的用户是root，要修改huser用户"></a>4.2.6 如果出现权限不够，因为拷贝文件的用户是root，要修改huser用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 opt]$ sudo <span class="built_in">chown</span> -R huser:huser hbase/</span><br><span class="line">[huser@slave2 opt]$ sudo <span class="built_in">chown</span> -R huser:huser hbase/</span><br></pre></td></tr></table></figure><h1 id="3-启动HBase"><a href="#3-启动HBase" class="headerlink" title="3. 启动HBase"></a>3. 启动HBase</h1><h3 id="4-3-1-执行启动，三台机一起启动"><a href="#4-3-1-执行启动，三台机一起启动" class="headerlink" title="4.3.1 执行启动，三台机一起启动"></a>4.3.1 执行启动，三台机一起启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 必须先开集群</span></span><br><span class="line">start-hbase.sh</span><br><span class="line"><span class="comment"># 关闭HBase</span></span><br><span class="line">stop-hbase.sh</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">节点：HMaster</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>端口号为: 16010 三台机都有</p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>hbase--HRegionServer--master</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7bQgT.png" alt="hbase--HRegionServer--master" title="hbase--HRegionServer--master"></p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>hbase--HRegionServer--slave1</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7bza1.png" alt="hbase--HRegionServer--slave1" title="hbase--HRegionServer--slave1"></p><h1 id="4-Hive与Hbase整合"><a href="#4-Hive与Hbase整合" class="headerlink" title="4. Hive与Hbase整合"></a>4. Hive与Hbase整合</h1><font color=red>有需求，反馈更新</font>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-file-word modern&quot;&gt;&lt;p&gt;介绍：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>四、tez引擎组件</title>
    <link href="https://xin0203xin0203.github.io/posts/6e1f6090.html"/>
    <id>https://xin0203xin0203.github.io/posts/6e1f6090.html</id>
    <published>2023-12-17T17:15:29.647Z</published>
    <updated>2024-12-17T17:40:40.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-dice modern"><p>简介：Tez采用了DAG（<a href="https://so.csdn.net/so/search?q=%E6%9C%89%E5%90%91%E6%97%A0%E7%8E%AF%E5%9B%BE&amp;spm=1001.2101.3001.7020"><strong>有向无环图</strong></a>）来组织MR任务（DAG中一个节点就是一个RDD，边表示对RDD的操作）。它的核心思想是把将Map任务和Reduce任务进一步拆分，Map任务拆分为Input-Processor-Sort-Merge-Output，Reduce任务拆分为Input-Shuffer-Sort-Merge-Process-output，Tez将若干小任务灵活重组，形成一个大的DAG作业。</p></div><div class="tip "><p>前提准备：</p></div><div class="note success simple"><p>需要的安装包：<a href="https://pan.baidu.com/s/1PePN7BXvQGheJxqT5bYYjQ#list/path=%2F"><strong>tez</strong></a>压缩包(提取码：i9yb)——&gt;<strong><em>tez-0.10.1-SNAPSHOT-minimal.tar.gz</em></strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;  <strong><em>tez-0.10.1-SNAPSHOT.tar.gz</em></strong></p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%89%E3%80%81Hive%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA--%3E%E5%86%85%E5%90%ABMySQL%E5%AE%89%E8%A3%85%5D(https:/www.yuque.com/u25360462/nt1ri1/zamxgf?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bvhc.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">三、Hive组件搭建-->内含MySQL安装</div>            <div class="tag-link-sitename">Hive：由Facebook开源用于解决海量结构化日志的数据统计。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1.准备工作"></a>1.准备工作</h2><h3 id="1-1-上传并解压"><a href="#1-1-上传并解压" class="headerlink" title="1.1 上传并解压"></a>1.1 上传并解压</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/tez</span><br><span class="line">tar -zxvf /opt/software/tez-0.10.1-SNAPSHOT-minimal.tar.gz -C /opt/tez</span><br></pre></td></tr></table></figure><h3 id="1-2-上传至HDFS，存放tez依赖包"><a href="#1-2-上传至HDFS，存放tez依赖包" class="headerlink" title="1.2  上传至HDFS，存放tez依赖包"></a>1.2  上传至HDFS，存放tez依赖包</h3><font color=red size=3px weight=bold>注意: 要开集群</font><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">mkdir</span> /tez</span><br><span class="line">hdfs dfs -put /opt/tez-0.10.1-SNAPSHOT.tar.gz /tez</span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>hive--tez引擎--存放tez依赖包</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7b0xq.png" alt="hive--tez引擎--存放tez依赖包" title="hive--tez引擎--存放tez依赖包"></p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BHive%E5%AE%89%E8%A3%85%20Tez%20%E5%BC%95%E6%93%8E_%E6%89%9B%E9%BA%BB%E8%A2%8B%E7%9A%84%E5%B0%91%E5%B9%B4%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2_hive%20tez%5D(https:/blog.csdn.net/lzb348110175/article/details/117817055?app_version=5.10.0&code=app_1562916241&csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22117817055%22,%22source%22:%22qq672596289%22%7D&uLinkId=usr1mkqgl919blen&utm_source=app)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bNWr.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Hive安装 Tez</div>            <div class="tag-link-sitename">Hive安装 Tez 引擎_扛麻袋的少年的博客-CSDN博客_hive tez</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BHive%E6%9B%B4%E6%8D%A2Tez%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/BRz4uiogyMT4xta9N6IygA)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bNWr.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Hive更换Tez计算引擎</div>            <div class="tag-link-sitename">Hive更换Tez计算引擎-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="2-修改配置"><a href="#2-修改配置" class="headerlink" title="2.修改配置"></a>2.修改配置</h2><h3 id="2-1-新建-tez-site-xml"><a href="#2-1-新建-tez-site-xml" class="headerlink" title="2.1 新建 tez-site.xml"></a>2.1 新建 <code>tez-site.xml</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="variable">$HADOOP_HOME</span>/etc/hadoop/tez-site.xml</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.lib.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;fs.defaultFS&#125;/tez/tez-0.10.1-SNAPSHOT.tar.gz<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.use.cluster.hadoop-libs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.am.resource.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.am.resource.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.container.max.java.heap.fraction<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.task.resource.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.task.resource.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="2-2-修改-Hadoop-环境变量"><a href="#2-2-修改-Hadoop-环境变量" class="headerlink" title="2.2 修改 Hadoop 环境变量"></a>2.2 <strong>修改 Hadoop 环境变量</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="variable">$HADOOP_HOME</span>/etc/hadoop/shellprofile.d/tez.sh</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hadoop_add_profile tez</span><br><span class="line"><span class="keyword">function</span> _tez_hadoop_classpath</span><br><span class="line">&#123;</span><br><span class="line"> hadoop_add_classpath <span class="string">&quot;<span class="variable">$HADOOP_HOME</span>/etc/hadoop&quot;</span> after</span><br><span class="line"> hadoop_add_classpath <span class="string">&quot;/opt/tez/*&quot;</span> after</span><br><span class="line"> hadoop_add_classpath <span class="string">&quot;/opt/tez/lib/*&quot;</span> after</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-修改-Hive-的计算引擎"><a href="#2-3-修改-Hive-的计算引擎" class="headerlink" title="2.3 修改 Hive 的计算引擎"></a>2.3 <strong>修改 Hive 的计算引擎</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="variable">$HIVE_HOME</span>/conf/hive-site.xml</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.execution.engine<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">value</span>&gt;</span>tez<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line">&lt;/property&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.tez.container.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="2-4-解决日志-Jar-包冲突"><a href="#2-4-解决日志-Jar-包冲突" class="headerlink" title="2.4 解决日志 Jar 包冲突"></a>2.4 解决日志 Jar 包冲突</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf /opt/tez/slf4j-log4j12-1.7.10.jar</span><br></pre></td></tr></table></figure><h2 id="3-测试"><a href="#3-测试" class="headerlink" title="3.测试"></a>3.测试</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Hive时，要启动集群</span></span><br><span class="line">[<span class="string">huser@master</span> <span class="string">~</span>]<span class="string">$</span> <span class="string">hive</span></span><br><span class="line"><span class="comment"># 创建一张测试表</span></span><br><span class="line"><span class="string">hive</span> <span class="string">(default)&gt;</span> <span class="string">create</span> <span class="string">table</span> <span class="string">ods_user(id</span> <span class="string">int,name</span> <span class="string">string);</span></span><br><span class="line"><span class="comment"># 插入数据</span></span><br><span class="line"><span class="string">hive</span> <span class="string">(default)&gt;</span> <span class="string">insert</span> <span class="string">into</span> <span class="string">ods_user</span> <span class="string">values(1,&quot;root&quot;);</span></span><br><span class="line"><span class="comment"># 验证数据是否插入成功</span></span><br><span class="line"><span class="string">hive</span> <span class="string">(default)&gt;</span> <span class="string">select</span> <span class="string">*</span> <span class="string">from</span> <span class="string">ods_user;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">ods_user.id</span>    <span class="string">ods_user.name</span></span><br><span class="line"><span class="number">1</span>    <span class="string">xiaokang</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.301</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">1</span> <span class="string">row(s)</span></span><br></pre></td></tr></table></figure><h2 id="4-报错解决"><a href="#4-报错解决" class="headerlink" title="4. 报错解决"></a>4. 报错解决</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hive&gt;</span> <span class="string">insert</span> <span class="string">into</span> <span class="string">test</span> <span class="string">values(1);</span></span><br><span class="line"><span class="string">Query</span> <span class="string">ID</span> <span class="string">=</span> <span class="string">huser_20221130013916_16e5ccf9-5b68-48bb-a967-287dabf447fa</span></span><br><span class="line"><span class="string">Total</span> <span class="string">jobs</span> <span class="string">=</span> <span class="number">1</span></span><br><span class="line"><span class="string">Launching</span> <span class="string">Job</span> <span class="number">1</span> <span class="string">out</span> <span class="string">of</span> <span class="number">1</span></span><br><span class="line"><span class="attr">FAILED:</span> <span class="string">Execution</span> <span class="string">Error,</span> <span class="string">return</span> <span class="string">code</span> <span class="number">1</span> <span class="string">from</span> <span class="string">org.apache.hadoop.hive.ql.exec.tez.TezTask</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>尝试添加<code>/opt/hadoop/etc/hadoop目录</code>下的<code>yarn-site.xml文件</code>配置<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">　　    <span class="language-xml"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line">　　    <span class="language-xml"><span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line">&lt;/property&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">　　    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">　　    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-dice modern&quot;&gt;&lt;p&gt;简介：Tez采用了DAG（&lt;a href=&quot;https://so.csdn.net/so/search?q=%E6%9C%89%E5%90%91%E6%</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十一、Flume组件搭建--_日志收集</title>
    <link href="https://xin0203xin0203.github.io/posts/1c48292.html"/>
    <id>https://xin0203xin0203.github.io/posts/1c48292.html</id>
    <published>2023-12-17T17:15:29.627Z</published>
    <updated>2024-12-18T13:22:23.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-circle-half-stroke modern"><p>简介：<font color=red>Apache Flume</font>  是 Cloudera 公司开发，是一个分布式的、高可靠的、高可用的用于海量日志收集、聚合和传输的系统。它可以从不同的数据源收集数据，经过聚合后发送到存储系统中，通常用于日志数据的收集。Flume 分为 NG 和 OG (1.0 之前) 两个版本，NG 在 OG 的基础上进行了完全的重构，是目前使用最为广泛的版本。下面的介绍均以 NG 为基础。</p></div><div class="tip info"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note default simple"><p>需要的安装包：<a href="http://archive.apache.org/dist/flume/"><strong>flume</strong></a>压缩包——&gt;<strong>apache-flume-1.7.0-bin.tar.gz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-flume<span class="number">-1.9</span><span class="number">.0</span>-bin.tar.gz -C /opt/</span><br><span class="line">mv apache-flume<span class="number">-1.9</span><span class="number">.0</span> flume</span><br></pre></td></tr></table></figure><h2 id="2-配置flume环境变量"><a href="#2-配置flume环境变量" class="headerlink" title="2. 配置flume环境变量"></a>2. 配置flume环境变量</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># flume</span></span><br><span class="line"><span class="keyword">export</span> FLUME_HOME=/opt/flume</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$FLUME_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/profile  slave2(slave1):/etc/profile</span><br></pre></td></tr></table></figure><h2 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h2><h3 id="3-1-进入安装目录下的-conf目录，拷贝-Flume-的环境配置模板-flume-env-sh-template"><a href="#3-1-进入安装目录下的-conf目录，拷贝-Flume-的环境配置模板-flume-env-sh-template" class="headerlink" title="3.1 进入安装目录下的 conf目录，拷贝 Flume 的环境配置模板 flume-env.sh.template"></a>3.1 进入安装目录下的 <code>conf目录</code>，拷贝 <strong>Flume</strong> 的环境配置模板 <strong>flume-env.sh.template</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp flume-env.sh.<span class="keyword">template</span> flume-env.sh</span><br></pre></td></tr></table></figure><h3 id="3-2-配置flume-env-sh"><a href="#3-2-配置flume-env-sh" class="headerlink" title="3.2 配置flume-env.sh"></a>3.2 <strong>配置flume-env.sh</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> JAVA_HOME=/usr/java/jdk1<span class="number">.8</span><span class="number">.0</span>_341-amd64</span><br></pre></td></tr></table></figure><h2 id="4-验证"><a href="#4-验证" class="headerlink" title="4. 验证"></a>4. 验证</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">flume-ng version</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Flume 1.9.0</span></span><br><span class="line"><span class="string">Source code repository: https://git-wip-us.apache.org/repos/asf/flume.git</span></span><br><span class="line"><span class="string">Revision: d4fcab4f501d41597bc616921329a4339f73585e</span></span><br><span class="line"><span class="string">Compiled by fszabo on Mon Dec 17 20:45:25 CET 2018</span></span><br><span class="line"><span class="string">From source with checksum 35db629a3bda49d23e9b3690c80737f9</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BFlume%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/FtkDp8qwVxl85DXL9wEQ2Q)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MAYP.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Flume安装及基本使用</div>            <div class="tag-link-sitename">Flume安装及基本使用-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="5-基本使用"><a href="#5-基本使用" class="headerlink" title="5. 基本使用"></a>5. 基本使用</h2><h3 id="5-1-新建配置文件telnet-logger-properties"><a href="#5-1-新建配置文件telnet-logger-properties" class="headerlink" title="5.1 新建配置文件telnet-logger.properties"></a>5.1 新建配置文件<strong>telnet-logger.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources、channels、sinks</span></span><br><span class="line"><span class="string">a1.sources</span> <span class="string">=</span> <span class="string">s1</span></span><br><span class="line"><span class="string">a1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">a1.sinks</span> <span class="string">=</span> <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置source属性</span></span><br><span class="line"><span class="string">a1.sources.s1.type</span> <span class="string">=</span> <span class="string">netcat</span></span><br><span class="line"><span class="string">a1.sources.s1.bind</span> <span class="string">=</span> <span class="string">master</span></span><br><span class="line"><span class="string">a1.sources.s1.port</span> <span class="string">=</span> <span class="number">44444</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line"><span class="string">a1.channels.c1.type</span> <span class="string">=</span> <span class="string">memory</span></span><br><span class="line"><span class="string">a1.channels.c1.capacity</span> <span class="string">=</span> <span class="number">10000</span></span><br><span class="line"><span class="string">a1.channels.c1.transactionCapacity</span> <span class="string">=</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line"><span class="string">a1.sinks.k1.type</span> <span class="string">=</span> <span class="string">logger</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources和channels绑定</span></span><br><span class="line"><span class="string">a1.sources.s1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks和channels绑定</span></span><br><span class="line"><span class="string">a1.sinks.k1.channel</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">NetCat Source ：监听一个指定端口，并接收监听到的数据（接收的数据是字符串形式）。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">NetCat Source 配置项说明:</span></span><br><span class="line"><span class="string">channels    |   绑定的通道</span></span><br><span class="line"><span class="string">    type    |   netcat</span></span><br><span class="line"><span class="string">    bind    |   指定要监听的主机</span></span><br><span class="line"><span class="string">    port    |   指定要监听的端口号</span></span><br><span class="line"><span class="string">    selector.*    |   选择器配置</span></span><br><span class="line"><span class="string">    interceptors.*    |   拦截器列表配置</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://vip.helloimg.com/images/2023/12/18/o7Mi2n.png" alt=""></p><h3 id="5-2-启动"><a href="#5-2-启动" class="headerlink" title="5.2 启动"></a>5.2 启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -n a1 -c /opt/flume/conf/ -f conf/telnet-logger.properties -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">SLF4J: Class path contains multiple SLF4J bindings.</span></span><br><span class="line"><span class="string">SLF4J: Found binding in [jar:file:/opt/flume/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span></span><br><span class="line"><span class="string">SLF4J: Found binding in [jar:file:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span></span><br><span class="line"><span class="string">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span></span><br><span class="line"><span class="string">SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</span></span><br><span class="line"><span class="string">2022-11-05 17:40:48,862 (main) [ERROR - org.apache.flume.node.Application.main(Application.java:374)] A fatal error occurred while running. Exception follows.</span></span><br><span class="line"><span class="string">org.apache.commons.cli.ParseException: The specified configuration file does not exist: /opt/bin/telnet-logger.properties</span></span><br><span class="line"><span class="string">at org.apache.flume.node.Application.main(Application.java:342)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">删掉一个jar包/opt/flume/lib/slf4j-log4j12-1.7.25.jar</span><br></pre></td></tr></table></figure><h3 id="5-3-测试"><a href="#5-3-测试" class="headerlink" title="5.3 测试"></a>5.3 测试</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">第一种：</span></span><br><span class="line"><span class="string">telnet</span> <span class="string">master</span> <span class="number">44444</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="string">证明成功，如果是下面一种，则按下面来:</span></span><br><span class="line">    </span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;bash: telnet: 未找到命令&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#解决方案：使用yum命令安装即可</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">yum</span> <span class="string">-y</span> <span class="string">install</span> <span class="string">telnet</span></span><br><span class="line"><span class="string">第二种：</span></span><br><span class="line"><span class="string">nc</span> <span class="string">master</span> <span class="number">44444</span></span><br><span class="line"><span class="comment"># sudo yum -y install nc</span></span><br></pre></td></tr></table></figure><h2 id="6-官方案例一"><a href="#6-官方案例一" class="headerlink" title="6. 官方案例一"></a>6. 官方案例一</h2><h3 id="6-1-新建配置文件execsource-properties"><a href="#6-1-新建配置文件execsource-properties" class="headerlink" title="6.1  新建配置文件execsource.properties"></a>6.1  新建配置文件<strong>execsource.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources、channels、sinks</span></span><br><span class="line"><span class="string">a1.sources</span> <span class="string">=</span> <span class="string">s1</span></span><br><span class="line"><span class="string">a1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">a1.sinks</span> <span class="string">=</span> <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置source属性 </span></span><br><span class="line"><span class="string">a1.sources.s1.type</span> <span class="string">=</span> <span class="string">exec</span></span><br><span class="line"><span class="string">a1.sources.s1.command</span> <span class="string">=</span> <span class="string">tail</span> <span class="string">-f</span> <span class="string">/opt/flume/data/log.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型 </span></span><br><span class="line"><span class="string">a1.channels.c1.type</span> <span class="string">=</span> <span class="string">memory</span></span><br><span class="line"><span class="string">a1.channels.c1.capacity</span> <span class="string">=</span> <span class="number">10000</span></span><br><span class="line"><span class="string">a1.channels.c1.transactionCapacity</span> <span class="string">=</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line"><span class="string">a1.sinks.k1.type</span> <span class="string">=</span> <span class="string">logger</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources和channels绑定</span></span><br><span class="line"><span class="string">a1.sources.s1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks和channels绑定</span></span><br><span class="line"><span class="string">a1.sinks.k1.channel</span> <span class="string">=</span> <span class="string">c1</span></span><br></pre></td></tr></table></figure><h3 id="6-2-启动"><a href="#6-2-启动" class="headerlink" title="6.2 启动"></a>6.2 启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -n a1 -c /opt/flume/conf/ -f conf/execsource.properties -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><h3 id="6-3-测试"><a href="#6-3-测试" class="headerlink" title="6.3 测试"></a>6.3 测试</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> /opt/flume/data/log.txt</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">sdgfsdfg</span></span><br><span class="line"><span class="string">sdgfsdfg</span></span><br><span class="line"><span class="string">sdgfsdfg</span></span><br><span class="line"><span class="string">sdgfsdfg</span></span><br><span class="line"><span class="string">sdgfsdfgkldfjgkldj</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>使用 Flume 监听文件内容变动，将新添的内容输出到控制台</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MSX6.png" alt="使用 Flume 监听文件内容变动，将新添的内容输出到控制台" title="使用 Flume 监听文件内容变动，将新添的内容输出到控制台"></p><h2 id="7-官方案例二"><a href="#7-官方案例二" class="headerlink" title="7. 官方案例二"></a>7. 官方案例二</h2><h3 id="7-1-新建配置文件xinexecsource-properties"><a href="#7-1-新建配置文件xinexecsource-properties" class="headerlink" title="7.1 新建配置文件xinexecsource.properties"></a>7.1 新建配置文件<strong>xinexecsource.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources、channels、sinks</span></span><br><span class="line"><span class="string">a1.sources</span> <span class="string">=</span> <span class="string">s1</span></span><br><span class="line"><span class="string">a1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">a1.sinks</span> <span class="string">=</span> <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置source属性</span></span><br><span class="line"><span class="string">a1.sources.s1.type</span> <span class="string">=</span> <span class="string">spooldir</span></span><br><span class="line"><span class="string">a1.sources.s1.spoolDir</span> <span class="string">=</span> <span class="string">/opt/flume/data/</span></span><br><span class="line"><span class="string">a1.sources.s1.basenameHeader</span> <span class="string">=</span> <span class="literal">true</span></span><br><span class="line"><span class="string">a1.sources.s1.basenameHeaderKey</span> <span class="string">=</span> <span class="string">fileName</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line"><span class="string">a1.channels.c1.type</span> <span class="string">=</span> <span class="string">memory</span></span><br><span class="line"><span class="string">a1.channels.c1.capacity</span> <span class="string">=</span> <span class="number">10000</span></span><br><span class="line"><span class="string">a1.channels.c1.transactionCapacity</span> <span class="string">=</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line"><span class="string">a1.sinks.k1.type</span> <span class="string">=</span> <span class="string">hdfs</span></span><br><span class="line"><span class="string">a1.sinks.k1.hdfs.path</span> <span class="string">=</span> <span class="string">/flume/%y-%m-%d/%H/</span></span><br><span class="line"><span class="string">a1.sinks.k1.hdfs.filePrefix</span> <span class="string">=</span> <span class="string">%&#123;fileName&#125;</span></span><br><span class="line"><span class="comment">#生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本</span></span><br><span class="line"><span class="string">a1.sinks.k1.hdfs.fileType</span> <span class="string">=</span> <span class="string">DataStream</span></span><br><span class="line"><span class="string">a1.sinks.k1.hdfs.useLocalTimeStamp</span> <span class="string">=</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources和channels绑定</span></span><br><span class="line"><span class="string">a1.sources.s1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks和channels绑定</span></span><br><span class="line"><span class="string">a1.sinks.k1.channel</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Spooling Directory Source 配置项说明:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">channels    |   绑定的通道</span></span><br><span class="line"><span class="string">type    |   spooldir</span></span><br><span class="line"><span class="string">spoolDir    |   读取文件的路径，即“搜集目录”</span></span><br><span class="line"><span class="string">【selector.*    |   选择器配置】</span></span><br><span class="line"><span class="string">【interceptors.*    |   拦截器列表配置】</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="7-2-启动"><a href="#7-2-启动" class="headerlink" title="7.2 启动"></a>7.2 启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -n a1 -c /opt/flume/conf/ -f conf/xinexecsource.properties -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><h3 id="7-3-测试"><a href="#7-3-测试" class="headerlink" title="7.3 测试"></a>7.3 测试</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> 1.txt /opt/flume/data</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-11-07 22:33:57,624 (hdfs-k1-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:393)] Writer callback called.</span></span><br><span class="line"><span class="string">2022-11-07 22:33:57,624 (hdfs-k1-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.doClose(BucketWriter.java:438)] Closing /flume/22-11-07/22//1.txt.1667831605570.tmp</span></span><br><span class="line"><span class="string">2022-11-07 22:33:57,681 (hdfs-k1-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$7.call(BucketWriter.java:681)] Renaming /flume/22-11-07/22/1.txt.1667831605570.tmp to /flume/22-11-07/22/1.txt.1667831605570</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><font color=red size=3px weight=bold>查看上传到 **HDFS** 上的文件内容与本地是否一致：</font><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">cat</span> /flume/22-11-07/22//1.txt.1667831605570.tmp</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">jdaljfaj</span></span><br><span class="line"><span class="string">ajlf;ajfa</span></span><br><span class="line"><span class="string">af;jfa;jfa</span></span><br><span class="line"><span class="string">faj;fja;</span></span><br><span class="line"><span class="string">afjfewjf;q</span></span><br><span class="line"><span class="string">[efjqa;f</span></span><br><span class="line"><span class="string">qafael;f</span></span><br><span class="line"><span class="string">an</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>flume--hdfs</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7M4dM.png" alt="flume--hdfs" title="flume--hdfs"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-circle-half-stroke modern&quot;&gt;&lt;p&gt;简介：&lt;font color=red&gt;Apache Flume&lt;/font&gt;  是 Cloudera 公司开发，是一个分布式</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十二、Kafka组件搭建--_日志收集</title>
    <link href="https://xin0203xin0203.github.io/posts/115d586a.html"/>
    <id>https://xin0203xin0203.github.io/posts/115d586a.html</id>
    <published>2023-12-17T17:15:29.602Z</published>
    <updated>2024-12-18T13:33:33.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-eye-outline modern"><p>简介：Kafka 由LinkedIn(领英)全球职场社交平台公司开发，贡献给Apache成为顶级项目，是一个分布式的流平台。它具有以下特点：</p><ul><li><font color=red>支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；</font></li><li><font color=red>支持数据实时处理；</font></li><li><font color=red>能保证消息的可靠性投递；</font></li><li><font color=red>支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；</font></li><li><font color=red>高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。</font></li></ul></div><div class="tip success"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E5%8D%81%E3%80%81Flume%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA--%3E%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%5D(https:/www.yuque.com/u25360462/nt1ri1/ilmsg4?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MnKR.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十、Flume组件搭建-->日志收集</div>            <div class="tag-link-sitename">简介：<font color=red>Apache Flume</font> 是 Cloudera 公司开发，是一个分布式的、高可靠的、高可用的用于海量日志收集、聚合和传输的系统。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note primary simple"><p>需要的安装包：<a href="https://kafka.apache.org/downloads"><strong>kafka</strong></a>压缩包——&gt;<strong>kafka_2.12-3.0.0.tgz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2<span class="number">.12</span><span class="number">-3.0</span><span class="number">.0</span>.tgz -C /opt/</span><br><span class="line">mv kafka_2<span class="number">.12</span><span class="number">-3.0</span><span class="number">.0</span> kafka</span><br></pre></td></tr></table></figure><h2 id="2-配置kafka环境变量"><a href="#2-配置kafka环境变量" class="headerlink" title="2. 配置kafka环境变量"></a>2. 配置kafka环境变量</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># kafka</span></span><br><span class="line"><span class="keyword">export</span> KAFKA_HOME=/opt/kafka</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/<span class="function">profile  <span class="title">slave2</span><span class="params">(slave1)</span>:/etc/profile</span></span><br></pre></td></tr></table></figure><h2 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h2><h3 id="3-1-在-Kafka-安装目录下创建kafka-logs文件夹（用来存储分区信息的，不要把它与存放错误日志的目录混淆了，日志目录是配置在-log4j-properties-文件-里的）"><a href="#3-1-在-Kafka-安装目录下创建kafka-logs文件夹（用来存储分区信息的，不要把它与存放错误日志的目录混淆了，日志目录是配置在-log4j-properties-文件-里的）" class="headerlink" title="3.1 在 Kafka 安装目录下创建kafka-logs文件夹（用来存储分区信息的，不要把它与存放错误日志的目录混淆了，日志目录是配置在 log4j.properties 文件 里的）"></a>3.1 在 <code>Kafka</code> 安装目录下创建<code>kafka-logs文件夹</code>（用来存储分区信息的，不要把它与存放错误日志的目录混淆了，日志目录是配置在 <code>log4j.properties 文件</code> 里的）</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/kafka/kafka-logs</span><br></pre></td></tr></table></figure><h3 id="3-2-配置server-properties"><a href="#3-2-配置server-properties" class="headerlink" title="3.2 配置server.properties"></a>3.2 <strong>配置server.properties</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># broker的全局唯一标识号，不能重复. 给集群中的每个broker配置一个不同的id</span></span><br><span class="line">broker.id=<span class="number">0</span></span><br><span class="line"># 分区数据的存储位置</span><br><span class="line">log.dirs=/opt/kafka/kafka-logs</span><br><span class="line"># 连接Zookeeper集群地址</span><br><span class="line">zookeeper.connect=master:<span class="number">2181</span>,slave1:<span class="number">2181</span>,slave2:<span class="number">2181</span></span><br></pre></td></tr></table></figure><h3 id="3-3-拷贝到slave1和slave2节点"><a href="#3-3-拷贝到slave1和slave2节点" class="headerlink" title="3.3 拷贝到slave1和slave2节点"></a>3.3 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 分发之后需要修改 broker.<span class="built_in">id</span>( id 值一定不能重复 )的值，同时建议其他节点的环境变量也配置下。</span><br><span class="line">sudo scp -r /opt/kafka/  <span class="built_in">slave2</span>(slave1):/opt/</span><br></pre></td></tr></table></figure><h2 id="4-启动前-先启动zookeeper"><a href="#4-启动前-先启动zookeeper" class="headerlink" title="4. 启动前,先启动zookeeper"></a>4. 启动前,先启动zookeeper</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh /opt/kafka/config/server.properties</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">[<span class="number">2022</span><span class="number">-11</span><span class="number">-07</span> <span class="number">22</span>:<span class="number">47</span>:<span class="number">20</span>,<span class="number">485</span>] INFO [Partition kkjjssdd<span class="number">-0</span> broker=<span class="number">1</span>] Log loaded <span class="keyword">for</span> partition kkjjssdd<span class="number">-0</span> with initial high watermark <span class="number">0</span> (kafka.cluster.Partition)</span><br><span class="line">[<span class="number">2022</span><span class="number">-11</span><span class="number">-07</span> <span class="number">22</span>:<span class="number">47</span>:<span class="number">20</span>,<span class="number">485</span>] INFO [Partition kkjjss<span class="number">-1</span> broker=<span class="number">1</span>] Log loaded <span class="keyword">for</span> partition kkjjss<span class="number">-1</span> with initial high watermark <span class="number">0</span> (kafka.cluster.Partition)</span><br><span class="line">[<span class="number">2022</span><span class="number">-11</span><span class="number">-07</span> <span class="number">22</span>:<span class="number">47</span>:<span class="number">20</span>,<span class="number">492</span>] INFO [BrokerToControllerChannelManager broker=<span class="number">1</span> name=alterIsr]: Recorded <span class="keyword">new</span> controller, from now on will use broker slave1:<span class="number">9092</span> (id: <span class="number">1</span> rack: null) (kafka.server.BrokerToControllerRequestThread)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="5-验证"><a href="#5-验证" class="headerlink" title="5. 验证"></a>5. 验证</h2><p>创建测试主题：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --create --topic kkjjssdd --bootstrap-server master:9092,slave1:9092,slave2:9092 --partitions 2 --replication-factor 1</span><br><span class="line"></span><br><span class="line"><span class="comment">#kafka-topics.sh 任何和 topic 相关的操作都使用这个命令</span></span><br><span class="line"><span class="comment">#--create 表示创建一个 topic</span></span><br><span class="line"><span class="comment">#--zookeeper 指明任意一个 zookeeper 服务器地址</span></span><br><span class="line"><span class="comment">#--replication-factor 表示每个 topic 的副本数. 注意: 副本数必须小于等于 kafka 集群的数量.</span></span><br><span class="line"><span class="comment">#--partitions 这个 topic 的分区的数量</span></span><br><span class="line"><span class="comment">#--topic 这个 topic 的名字.</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Created topic kkjjssdd.</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>创建完成后可以使用以下命令查看创建的主题信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --list --bootstrap-server master:9092,slave1:9092,slave2:9092</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">kkjjssdd</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p><h1 id="Flume整合Kafka"><a href="#Flume整合Kafka" class="headerlink" title="Flume整合Kafka"></a>Flume整合Kafka</h1><h2 id="6-启动zookeeper，和kafka节点"><a href="#6-启动zookeeper，和kafka节点" class="headerlink" title="6. 启动zookeeper，和kafka节点"></a>6. 启动zookeeper，和kafka节点</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br><span class="line">kafka-server-start.sh /opt/kafka/config/server.properties</span><br></pre></td></tr></table></figure><h2 id="7-创建主题"><a href="#7-创建主题" class="headerlink" title="7. 创建主题"></a>7. 创建主题</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建主题</span></span><br><span class="line"><span class="string">kafka-topics.sh</span> <span class="string">--create</span> <span class="string">--zookeeper</span> <span class="string">master:2181</span> <span class="string">--topic</span> <span class="string">flume2kafka</span> <span class="string">--partitions</span> <span class="number">1</span> <span class="string">--replication-factor</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看创建的主题</span></span><br><span class="line"><span class="string">kafka-topics.sh</span> <span class="string">--zookeeper</span> <span class="string">master:2181</span> <span class="string">--list</span></span><br></pre></td></tr></table></figure><h2 id="8-启动kafka消费者"><a href="#8-启动kafka消费者" class="headerlink" title="8. 启动kafka消费者"></a>8. 启动kafka消费者</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server master:9092 --topic flume2kafka</span><br></pre></td></tr></table></figure><h2 id="9-配置flume的文件"><a href="#9-配置flume的文件" class="headerlink" title="9. 配置flume的文件"></a>9. <strong>配置flume的文件</strong></h2><p>新建配置文件 <strong>flume-kafka.properties</strong>，文件内容如下：<br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources、channels、sinks</span></span><br><span class="line"><span class="string">a1.sources</span> <span class="string">=</span> <span class="string">s1</span></span><br><span class="line"><span class="string">a1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">a1.sinks</span> <span class="string">=</span> <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置source属性</span></span><br><span class="line"><span class="string">a1.sources.s1.type</span> <span class="string">=</span> <span class="string">exec</span></span><br><span class="line"><span class="string">a1.sources.s1.command</span> <span class="string">=</span> <span class="string">tail</span> <span class="string">-f</span> <span class="string">/opt/kafka/data/kafka.log</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line"><span class="string">a1.channels.c1.type</span> <span class="string">=</span> <span class="string">memory</span></span><br><span class="line"><span class="string">a1.channels.c1.capacity</span> <span class="string">=</span> <span class="number">10000</span></span><br><span class="line"><span class="string">a1.channels.c1.transactionCapacity</span> <span class="string">=</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line"><span class="comment">#设置Kafka接收器</span></span><br><span class="line"><span class="string">a1.sinks.k1.type</span> <span class="string">=</span> <span class="string">org.apache.flume.sink.kafka.KafkaSink</span></span><br><span class="line"><span class="comment">#设置Kafka地址</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.bootstrap.servers</span> <span class="string">=</span> <span class="string">master:9092</span></span><br><span class="line"><span class="comment">#设置发送到Kafka上的主题</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.topic</span> <span class="string">=</span> <span class="string">flume2kafka</span></span><br><span class="line"><span class="comment">#设置一批中消息的条数</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.flumeBatchSize</span> <span class="string">=</span> <span class="number">6</span></span><br><span class="line"><span class="comment">#0代表不需要等待确认，1代表仅需要leader确认，-1代表所有副本确认</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.producer.acks</span> <span class="string">=</span> <span class="number">1</span></span><br><span class="line"><span class="comment">#设置 linger.ms=1，将达到减少发送的请求数量的效果，但对于在没有负载情况，将增加1ms的延迟。</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.producer.linger.ms</span> <span class="string">=</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources和channels绑定</span></span><br><span class="line"><span class="string">a1.sources.s1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks和channels绑定</span></span><br><span class="line"><span class="string">a1.sinks.k1.channel</span> <span class="string">=</span> <span class="string">c1</span></span><br></pre></td></tr></table></figure></p><h2 id="10-启动Flume"><a href="#10-启动Flume" class="headerlink" title="10. 启动Flume"></a>10. 启动Flume</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> flume-ng agent -n a1 -c /op/flume/conf/ -f /opt/flume/conf/flume-kafka.properties -Dflume.root.logger=INFO,console &amp;&gt;&gt;flume-ng.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h2 id="11-测试"><a href="#11-测试" class="headerlink" title="11. 测试"></a>11. 测试</h2><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>flume-kafka--flume2kafka</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7Mboz.png" alt="flume-kafka--flume2kafka" title="flume-kafka--flume2kafka"><br>向监听的 <code>/home/xiaokang/docker_teach/kafka.log</code> 文件中追加内容，查看 <code>Kafka</code> 消费者的输出：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> alfhlaflkaEJFl &gt;&gt; kafka.log</span><br><span class="line"><span class="built_in">echo</span> aflkajlkf &gt;&gt; kafka.log</span><br><span class="line"><span class="built_in">echo</span> afilajf &gt;&gt; kafka.log</span><br></pre></td></tr></table></figure><br>可以看到 <code>flume2kafka</code> 主题的消费端已经收到了对应的消息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alfhlaflkaEJFl</span><br><span class="line">aflkajlkf</span><br><span class="line">afilajf</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-eye-outline modern&quot;&gt;&lt;p&gt;简介：Kafka 由LinkedIn(领英)全球职场社交平台公司开发，贡献给Apache成为顶级项目，是一个分布式的流平台。它具有以下特点</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十、Azkaban-two-server--工作流调度</title>
    <link href="https://xin0203xin0203.github.io/posts/1a829385.html"/>
    <id>https://xin0203xin0203.github.io/posts/1a829385.html</id>
    <published>2023-12-17T17:15:29.590Z</published>
    <updated>2024-12-18T13:11:02.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-fire modern"><p>简介：two server mode（双进程服务模式 ）：存放元数据的数据库为 MySQL，MySQL 应采用主从模式进行备份和容错。这种模式下 webServer 和 executorServer 在不同进程中运行（ 同一服务器 ）。该模式适合生产环境，更新和升级时对用户的影响较小。</p></div><div class="tip "><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E5%85%AB%E3%80%81Azkaban-solo-server--%3E%E5%B7%A5%E4%BD%9C%E6%B5%81%E8%B0%83%E5%BA%A6%5D(https:/www.yuque.com/u25360462/nt1ri1/fwil15?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MxoE.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">八、Azkaban-solo-server-->工作流调度</div>            <div class="tag-link-sitename">简介：Gradle是一款Google推出的 **基于JVM**、 通用灵活的 项目构建工具， 支持**Maven**，JCenter多种第三方仓库;支持传递性依赖管理、废弃了繁杂的xml文件，转而使用 **简洁的 、 支持多种语言** (例如：java、**groovy**等)的 build脚本文件。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BAzkaban-two-server%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/a8z5gqCrBaWzTYqohvKWfQ)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MESY.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Azkaban-two-server环境搭建</div>            <div class="tag-link-sitename">Azkaban-two-server环境搭建-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-创建目录，并解压和改名"><a href="#1-1-创建目录，并解压和改名" class="headerlink" title="1-1 创建目录，并解压和改名"></a>1-1 创建目录，并解压和改名</h3><p><font color=red size=3px weight=bold>分别解压azkaban目录下的</font><br><strong>1.azkaban-web-server/build/distributions/azkaban-web-server-0.1.0-SNAPSHOT.tar.gz<br>2.azkaban-exec-server/build/distributions/azkaban-exec-server-0.1.0-SNAPSHOT.tar.gz<br>3.azkaban-db/build/distributions/azkaban-db-0.1.0-SNAPSHOT.tar.gz</strong></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">mkdir</span> <span class="string">/opt/azkaban-two</span></span><br><span class="line"><span class="string">tar</span> <span class="string">-zxvf</span> <span class="string">azkaban-web-server-0.1.0-SNAPSHOT.tar.gz</span> <span class="string">-C</span> <span class="string">/opt/azkaben-two</span></span><br><span class="line"><span class="string">tar</span> <span class="string">-zxvf</span> <span class="string">azkaban-exec-server-0.1.0-SNAPSHOT.tar.gz</span> <span class="string">-C</span> <span class="string">/opt/azkaben-two</span></span><br><span class="line"><span class="string">tar</span> <span class="string">-zxvf</span> <span class="string">azkaban-web-server-0.1.0-SNAPSHOT.tar.gz</span> <span class="string">-C</span> <span class="string">/opt/azkaben-two</span></span><br><span class="line"><span class="string">mv</span> <span class="string">azkaban-web-server-0.1.0-SNAPSHOT/</span> <span class="string">web-server</span></span><br><span class="line"><span class="string">mv</span> <span class="string">azkaban-exec-server-0.1.0-SNAPSHOT/</span> <span class="string">executor-server</span></span><br><span class="line"><span class="string">mv</span> <span class="string">azkaban-db-0.1.0-SNAPSHOT/</span> <span class="string">sql-db</span></span><br></pre></td></tr></table></figure><h3 id="1-2-创建MySQL数据库"><a href="#1-2-创建MySQL数据库" class="headerlink" title="1-2 创建MySQL数据库"></a>1-2 创建MySQL数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database azkaban_two;</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;Query OK, 1 row affected (0.01 sec)&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">mysql&gt; use azkaban_two;</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;Database changed&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="built_in">source</span> /opt/azkaban-two/azkaban-db/create-all-sql-0.1.0-SNAPSHOT.sql</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Query OK, 0 rows affected (0.09 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Query OK, 0 rows affected (0.02 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Query OK, 0 rows affected (0.02 sec)</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-3-生成密钥和证书"><a href="#1-3-生成密钥和证书" class="headerlink" title="1-3 生成密钥和证书"></a>1-3 生成密钥和证书</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[huserg@master azkaban-two]$ keytool -keystore /opt/azkaban-two/web-server/keystore -<span class="built_in">alias</span> huser -genkey -keyalg rsa</span><br><span class="line"></span><br><span class="line">keytool是 Java 数据证书的管理工具，使用户能够管理自己的公 /私钥 对及相关证书 。</span><br><span class="line">-keystore 指定密钥库的名称及位置 (产生的各类信息将存在 .keystore文件中)</span><br><span class="line">-genkey (或者 -genkeypair) 生成密钥对</span><br><span class="line">-<span class="built_in">alias</span> 为生成的密钥对指定别名，如果没有默认是 mykey</span><br><span class="line">-keyalg 指定密钥的算法 RSA/DSA，默认是 DSA</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Warning:</span></span><br><span class="line"><span class="string">JKS 密钥库使用专用格式。建议使用 &quot;keytool -importkeystore -srckeystore /opt/azkaban-two/web-server/keystore -destkeystore /opt/azkaban-two/web-server/keystore -deststoretype pkcs12&quot; 迁移到行业标准格式 PKCS12。</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-4-查看密钥库信息"><a href="#1-4-查看密钥库信息" class="headerlink" title="1-4 查看密钥库信息"></a>1-4 查看密钥库信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 web-server]$ keytool -list -keystore keystore</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">输入密钥库口令:  </span></span><br><span class="line"><span class="string">密钥库类型: JKS</span></span><br><span class="line"><span class="string">密钥库提供方: SUN</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">您的密钥库包含 1 个条目</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">huser, 2022-11-3, PrivateKeyEntry, </span></span><br><span class="line"><span class="string">证书指纹 (SHA-256): C7:07:73:D9:81:19:43:6F:C3:8E:5A:E4:0D:0F:08:AA:98:C4:0A:D9:C4:C7:5A:B1:27:E9:1B:80:2C:68:66:5D</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Warning:</span></span><br><span class="line"><span class="string">JKS 密钥库使用专用格式。建议使用 &quot;keytool -importkeystore -srckeystore keystore -destkeystore keystore -deststoretype pkcs12&quot; 迁移到行业标准格式 PKCS12。</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="2-web-服务器配置"><a href="#2-web-服务器配置" class="headerlink" title="2. web 服务器配置"></a>2. web 服务器配置</h2><h3 id="2-1-在web服务器目录下创建多级文件夹plugins-jobtypes："><a href="#2-1-在web服务器目录下创建多级文件夹plugins-jobtypes：" class="headerlink" title="2-1 在web服务器目录下创建多级文件夹plugins/jobtypes："></a>2-1 在web服务器目录下创建多级文件夹<code>plugins/jobtypes</code>：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/azkaban-two/web-server/plugins/jobtypes</span><br></pre></td></tr></table></figure><h3 id="2-2-进入-azkaban-web-服务器安装目录的conf目录下，修改azkaban-properties"><a href="#2-2-进入-azkaban-web-服务器安装目录的conf目录下，修改azkaban-properties" class="headerlink" title="2-2 进入 azkaban web 服务器安装目录的conf目录下，修改azkaban.properties"></a>2-2 进入 <code>azkaban web</code> 服务器安装目录的<code>conf目录</code>下，修改<strong>azkaban.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Azkaban Personalization Settings</span></span><br><span class="line"><span class="string">azkaban.name=huser</span></span><br><span class="line"><span class="string">azkaban.label=huser-Azkaban</span></span><br><span class="line"><span class="string">azkaban.color=#FF3601</span></span><br><span class="line"><span class="string">azkaban.default.servlet.path=/index</span></span><br><span class="line"><span class="string">web.resource.dir=/opt/azkaban-two/web-server/web</span></span><br><span class="line"><span class="string">default.timezone.id=Asia/Shanghai</span></span><br><span class="line"><span class="comment"># Azkaban UserManager class</span></span><br><span class="line"><span class="string">user.manager.class=azkaban.user.XmlUserManager</span></span><br><span class="line"><span class="string">user.manager.xml.file=/opt/azkaban-two/web-server/conf/azkaban-users.xml</span></span><br><span class="line"><span class="comment"># Loader for projects</span></span><br><span class="line"><span class="string">executor.global.properties=/opt/azkaban-two/web-server/conf/global.properties</span></span><br><span class="line"><span class="string">azkaban.project.dir=projects</span></span><br><span class="line"><span class="comment"># Velocity dev mode</span></span><br><span class="line"><span class="string">velocity.dev.mode=false</span></span><br><span class="line"><span class="comment"># Azkaban Jetty server properties.</span></span><br><span class="line"><span class="string">jetty.ssl.port=8443</span></span><br><span class="line"><span class="string">jetty.port=8081</span></span><br><span class="line"><span class="string">jetty.keystore=/opt/azkaban-two/web-server/keystore</span></span><br><span class="line"><span class="string">jetty.password=123456</span></span><br><span class="line"><span class="string">jetty.keypassword=123456</span></span><br><span class="line"><span class="string">jetty.truststore=/opt/azkaban-two/web-server/keystore</span></span><br><span class="line"><span class="string">jetty.trustpassword=huser</span></span><br><span class="line"><span class="string">jetty.maxThreads=25</span></span><br><span class="line"><span class="comment"># Azkaban Executor settings</span></span><br><span class="line"><span class="string">executor.port=11241</span></span><br><span class="line"><span class="comment"># mail settings</span></span><br><span class="line"><span class="string">mail.sender=</span></span><br><span class="line"><span class="string">mail.host=</span></span><br><span class="line"><span class="comment"># User facing web server configurations used to construct the user facing server URLs. They are useful when there is a reverse proxy between Azkaban web servers and users.</span></span><br><span class="line"><span class="comment"># enduser -&gt; myazkabanhost:443 -&gt; proxy -&gt; localhost:8081</span></span><br><span class="line"><span class="comment"># when this parameters set then these parameters are used to generate email links.</span></span><br><span class="line"><span class="comment"># if these parameters are not set then jetty.hostname, and jetty.port(if ssl configured jetty.ssl.port) are used.</span></span><br><span class="line"><span class="comment"># azkaban.webserver.external_hostname=myazkabanhost.com</span></span><br><span class="line"><span class="comment"># azkaban.webserver.external_ssl_port=443</span></span><br><span class="line"><span class="comment"># azkaban.webserver.external_port=8081</span></span><br><span class="line"><span class="string">job.failure.email=</span></span><br><span class="line"><span class="string">job.success.email=</span></span><br><span class="line"><span class="string">lockdown.create.projects=false</span></span><br><span class="line"><span class="string">cache.directory=cache</span></span><br><span class="line"><span class="comment"># JMX stats</span></span><br><span class="line"><span class="string">jetty.connector.stats=true</span></span><br><span class="line"><span class="string">executor.connector.stats=true</span></span><br><span class="line"><span class="comment"># Azkaban plugin settings</span></span><br><span class="line"><span class="string">azkaban.jobtype.plugin.dir=/opt/azkaban-two/web-server/plugins/jobtypes</span></span><br><span class="line"><span class="comment"># Azkaban mysql settings by default. Users should configure their own username and password.</span></span><br><span class="line"><span class="string">database.type=mysql</span></span><br><span class="line"><span class="string">mysql.port=3306</span></span><br><span class="line"><span class="string">mysql.host=192.168.33.147</span></span><br><span class="line"><span class="string">mysql.database=azkaban_two</span></span><br><span class="line"><span class="string">mysql.user=root</span></span><br><span class="line"><span class="string">mysql.password=1</span></span><br><span class="line"><span class="string">mysql.numconnections=100</span></span><br><span class="line"><span class="comment">#Multiple Executor</span></span><br><span class="line"><span class="string">azkaban.use.multiple.executors=true</span></span><br><span class="line"><span class="string">azkaban.executorselector.filters=StaticRemainingFlowSize,CpuStatus</span></span><br><span class="line"><span class="string">azkaban.executorselector.comparator.NumberOfAssignedFlowComparator=1</span></span><br><span class="line"><span class="string">azkaban.executorselector.comparator.Memory=1</span></span><br><span class="line"><span class="string">azkaban.executorselector.comparator.LastDispatched=1</span></span><br><span class="line"><span class="string">azkaban.executorselector.comparator.CpuUsage=1</span></span><br></pre></td></tr></table></figure><h3 id="2-3-log4j-properties修改日志文件路径"><a href="#2-3-log4j-properties修改日志文件路径" class="headerlink" title="2-3 log4j.properties修改日志文件路径"></a>2-3 <strong>log4j.properties</strong>修改日志文件路径</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log4j.appender.server.File=/opt/azkaban-two/web-server/logs/azkaban-webserver.log</span><br></pre></td></tr></table></figure><h3 id="2-4-在azkaban-web-服务器安装目录的conf目录下，-按照如下配置修改-azkaban-users-xml文件，增加自定义管理员用户"><a href="#2-4-在azkaban-web-服务器安装目录的conf目录下，-按照如下配置修改-azkaban-users-xml文件，增加自定义管理员用户" class="headerlink" title="2-4 在azkaban web 服务器安装目录的conf目录下， 按照如下配置修改 azkaban-users.xml文件，增加自定义管理员用户"></a>2-4 在<code>azkaban web</code> 服务器安装目录的<code>conf目录</code>下， 按照如下配置修改 <code>azkaban-users.xml文件</code>，增加自定义管理员用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;azkaban-users&gt;</span><br><span class="line">  &lt;user <span class="built_in">groups</span>=<span class="string">&quot;azkaban&quot;</span> password=<span class="string">&quot;azkaban&quot;</span> roles=<span class="string">&quot;admin&quot;</span> username=<span class="string">&quot;azkaban&quot;</span>/&gt;</span><br><span class="line">  &lt;user <span class="built_in">groups</span>=<span class="string">&quot;azkaban&quot;</span> password=<span class="string">&quot;xiaokang&quot;</span> roles=<span class="string">&quot;admin&quot;</span> username=<span class="string">&quot;xiaokang&quot;</span>/&gt;</span><br><span class="line">  &lt;user password=<span class="string">&quot;metrics&quot;</span> roles=<span class="string">&quot;metrics&quot;</span> username=<span class="string">&quot;metrics&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line">  &lt;role name=<span class="string">&quot;admin&quot;</span> permissions=<span class="string">&quot;ADMIN&quot;</span>/&gt;</span><br><span class="line">  &lt;role name=<span class="string">&quot;metrics&quot;</span> permissions=<span class="string">&quot;METRICS&quot;</span>/&gt;</span><br><span class="line">&lt;/azkaban-users&gt;</span><br></pre></td></tr></table></figure><h2 id="3-Executor-服务器配置"><a href="#3-Executor-服务器配置" class="headerlink" title="3. Executor 服务器配置"></a>3. <strong>Executor</strong> 服务器配置</h2><h3 id="3-1-进入-azkaban-executor服务器安装目录的conf目录下，修改azkaban-properties"><a href="#3-1-进入-azkaban-executor服务器安装目录的conf目录下，修改azkaban-properties" class="headerlink" title="3-1  进入 azkaban executor服务器安装目录的conf目录下，修改azkaban.properties"></a>3-1  进入 <code>azkaban executor</code>服务器安装目录的<code>conf目录</code>下，修改<strong>azkaban.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Azkaban Personalization Settings</span></span><br><span class="line"><span class="string">default.timezone.id=Asia/Shanghai</span></span><br><span class="line"><span class="comment"># Azkaban UserManager class</span></span><br><span class="line"><span class="comment"># Loader for projects</span></span><br><span class="line"><span class="string">executor.global.properties=/opt/azkaban-two/executor-server/conf/global.properties</span></span><br><span class="line"><span class="string">azkaban.project.dir=projects</span></span><br><span class="line"><span class="string">azkaban.webserver.url=https://master:8443</span></span><br><span class="line"><span class="comment"># Azkaban plugin settings</span></span><br><span class="line"><span class="string">azkaban.jobtype.plugin.dir=/opt/azkaban-two/executor-server/plugins/jobtypes</span></span><br><span class="line"><span class="comment"># Azkaban mysql settings by default. Users should configure their own username and password.</span></span><br><span class="line"><span class="string">database.type=mysql</span></span><br><span class="line"><span class="string">mysql.port=3306</span></span><br><span class="line"><span class="string">mysql.host=192.168.33.147</span></span><br><span class="line"><span class="string">mysql.database=azkaban_two</span></span><br><span class="line"><span class="string">mysql.user=root</span></span><br><span class="line"><span class="string">mysql.password=1</span></span><br><span class="line"><span class="string">mysql.numconnections=100</span></span><br><span class="line"><span class="comment"># Azkaban Executor settings</span></span><br><span class="line"><span class="string">executor.maxThreads=50</span></span><br><span class="line"><span class="string">executor.flow.threads=30</span></span><br><span class="line"><span class="string">executor.port=11241</span></span><br></pre></td></tr></table></figure><h3 id="3-2-log4j-properties修改日志文件路径"><a href="#3-2-log4j-properties修改日志文件路径" class="headerlink" title="3-2 log4j.properties修改日志文件路径"></a>3-2 <strong>log4j.properties</strong>修改日志文件路径</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log4j.appender.server.File=/opt/azkaban-two/executor-server/logs/azkaban-execserver.log</span><br></pre></td></tr></table></figure><h2 id="4-启动"><a href="#4-启动" class="headerlink" title="4.启动"></a>4.启动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># executor服务器bin目录下执行启动命令</span></span><br><span class="line">[huser@master bin]$ ./start-exec.sh</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;AzkabanExecutorServer&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动激活executor服务器</span></span><br><span class="line">[huser@master ~]$ curl http://master:11241/executor?action=activate</span><br><span class="line"></span><br><span class="line"><span class="comment"># web服务器bin目录下执行启动命令</span></span><br><span class="line">[huser@master bin]$ ./start-web.sh </span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;AzkabanWebServer&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><font color=red size=3px weight=bold>以下内容跟   <code>基本任务调度</code>  一样</font><br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E5%85%AB%E3%80%81Azkaban-solo-server--%3E%E5%B7%A5%E4%BD%9C%E6%B5%81%E8%B0%83%E5%BA%A6%5D(https:/www.yuque.com/u25360462/nt1ri1/fwil15?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MxoE.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">八、Azkaban-solo-server-->工作流调度</div>            <div class="tag-link-sitename">简介：Gradle是一款Google推出的 **基于JVM**、 通用灵活的 项目构建工具， 支持**Maven**，JCenter多种第三方仓库;支持传递性依赖管理、废弃了繁杂的xml文件，转而使用 **简洁的 、 支持多种语言** (例如：java、**groovy**等)的 build脚本文件。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><p><strong>Azkaban-multiple-executor的操作</strong>只是把Azkaban-two-server的文件发给三台机，在跟Azkaban-two-server的操作任务一样</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-fire modern&quot;&gt;&lt;p&gt;简介：two server mode（双进程服务模式 ）：存放元数据的数据库为 MySQL，MySQL 应采用主从模式进行备份和容错。这种模式下 web</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>七、Sqoop组件搭建--数据迁移工具</title>
    <link href="https://xin0203xin0203.github.io/posts/da145f53.html"/>
    <id>https://xin0203xin0203.github.io/posts/da145f53.html</id>
    <published>2023-12-17T17:15:29.569Z</published>
    <updated>2024-12-18T12:35:20.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-cube modern"><p>简介：Apache Sqoop 是一个常用的数据迁移工具，主要用于在不同存储系统之间实现数据的导入与导出：</p><ul><li>导入数据：从 MySQL、Oracle 等关系型数据库中导入数据到 HDFS、Hive、HBase 等分布式文件存储系统中；</li><li>导出数据：从分布式文件系统中导出数据到关系数据库中。</li></ul><p><strong>Sqoop名字的由来：SQL—-Hadoop=Sq+oop=Sqoop</strong></p></div><div class="tip sync"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note success simple"><p>需要的安装包：<a href="https://archive.apache.org/dist/sqoop/"><strong>Sqoop</strong></a>包—-&gt;<strong>sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-解压并改名"><a href="#1-解压并改名" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf sqoop<span class="number">-1.4</span><span class="number">.6</span>.bin__hadoop<span class="number">-2.0</span><span class="number">.4</span>-alpha.tar.gz -C /opt/</span><br><span class="line">mv sqoop<span class="number">-1.4</span><span class="number">.6</span>.bin__hadoop<span class="number">-2.0</span><span class="number">.4</span>-alpha/ sqoop</span><br></pre></td></tr></table></figure><h2 id="2-配置Sqoop环境变量"><a href="#2-配置Sqoop环境变量" class="headerlink" title="2. 配置Sqoop环境变量"></a>2. 配置Sqoop环境变量</h2><h3 id="2-1-配置Sqoop环境变量"><a href="#2-1-配置Sqoop环境变量" class="headerlink" title="2.1 配置Sqoop环境变量"></a>2.1 配置Sqoop环境变量</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># sqoop</span></span><br><span class="line">export SQOOP_HOME=/opt/sqoop</span><br><span class="line">export PATH=$PATH:$SQOOP_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h2 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h2><h3 id="3-1-配置sqoop-env-sh"><a href="#3-1-配置sqoop-env-sh" class="headerlink" title="3.1 配置sqoop-env.sh"></a>3.1 <strong>配置sqoop-env.sh</strong></h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 拷贝 Sqoop 的环境配置模板</span></span><br><span class="line">cp sqoop-env-template.cmd sqoop-env.sh</span><br><span class="line"></span><br><span class="line">修改内容：</span><br><span class="line">export HADOOP_COMMON_HOME=/opt/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME=/opt/hadoop</span><br><span class="line">export HBASE_HOME=/opt/hbase</span><br><span class="line">export HIVE_HOME=/opt/hive</span><br><span class="line">export ZOOCFGDIR=/opt/zookeeper</span><br><span class="line">export ZOOKEEPER=/opt/zookeeper</span><br></pre></td></tr></table></figure><h3 id="3-2-拷贝数据库驱动"><a href="#3-2-拷贝数据库驱动" class="headerlink" title="3.2 拷贝数据库驱动"></a>3.2 拷贝数据库驱动</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp mysql-connector-java<span class="number">-5.1</span><span class="number">.37</span>.jar /opt/sqoop/lib</span><br></pre></td></tr></table></figure><h3 id="3-3-验证"><a href="#3-3-验证" class="headerlink" title="3.3 验证"></a>3.3 验证</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sqoop version</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Sqoop 1.4.7</span></span><br><span class="line"><span class="string">git commit id 2328971411f57f0cb683dfb79d19d4d19d185dd8</span></span><br><span class="line"><span class="string">Compiled by maugli on Thu Dec 21 15:59:58 STD 2017</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="4-Sqoop基本命令"><a href="#4-Sqoop基本命令" class="headerlink" title="4.Sqoop基本命令"></a>4.Sqoop基本命令</h2><h3 id="4-1-查看所有命令"><a href="#4-1-查看所有命令" class="headerlink" title="4.1 查看所有命令"></a>4.1 查看所有命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop <span class="built_in">help</span></span><br></pre></td></tr></table></figure><h3 id="4-2-查看某条命令的具体使用方法"><a href="#4-2-查看某条命令的具体使用方法" class="headerlink" title="4.2 查看某条命令的具体使用方法"></a>4.2 查看某条命令的具体使用方法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sqoop <span class="built_in">help</span> 命令名</span><br><span class="line"><span class="comment">#例如sqoop help import</span></span><br></pre></td></tr></table></figure><h2 id="5-Sqoop-与-MySQL"><a href="#5-Sqoop-与-MySQL" class="headerlink" title="5. Sqoop 与 MySQL"></a>5. Sqoop 与 MySQL</h2><h3 id="5-1-查询MySQL所有数据库"><a href="#5-1-查询MySQL所有数据库" class="headerlink" title="5.1 查询MySQL所有数据库"></a>5.1 查询MySQL所有数据库</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">sqoop</span> <span class="string">list-databases</span> <span class="string">--connect</span> <span class="string">jdbc:mysql://192.168.33.171:3306</span> <span class="string">--username</span> <span class="string">root</span> <span class="string">--password</span> <span class="number">000000</span></span><br></pre></td></tr></table></figure><h3 id="5-2-查询指定数据库种所有数据表"><a href="#5-2-查询指定数据库种所有数据表" class="headerlink" title="5.2 查询指定数据库种所有数据表"></a>5.2 查询指定数据库种所有数据表</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">sqoop</span> <span class="string">list-tables</span> <span class="string">--connect</span> <span class="string">jdbc:mysql://192.168.33.171:3306/mysql</span> <span class="string">--username</span> <span class="string">root</span> <span class="string">--password</span> <span class="number">000000</span></span><br></pre></td></tr></table></figure><h2 id="6-Sqoop-与-HDFS"><a href="#6-Sqoop-与-HDFS" class="headerlink" title="6. Sqoop 与 HDFS"></a>6. Sqoop 与 HDFS</h2><h3 id="6-1-MySQL数据导入到HDFS"><a href="#6-1-MySQL数据导入到HDFS" class="headerlink" title="6.1 MySQL数据导入到HDFS"></a>6.1 MySQL数据导入到HDFS</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.171:3306/test \</span><br><span class="line">--username root \</span><br><span class="line">--password 000000 \</span><br><span class="line">--table runoob_tbl \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--target-dir /sqoop \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;\t&#x27;</span> \</span><br><span class="line">-m 3</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--table help_keyword \    # 待导入的表</span></span><br><span class="line"><span class="string">--delete-target-dir \    # 目标目录存在则先删除</span></span><br><span class="line"><span class="string">--target-dir /sqoop \    # 导入的目标目录</span></span><br><span class="line"><span class="string">--fields-terminated-by &#x27;</span>\t<span class="string">&#x27; \    # 指定导出数据的分隔符</span></span><br><span class="line"><span class="string">-m 3    # 指定并行执行的 map tasks 数量  </span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="6-2-导入验证"><a href="#6-2-导入验证" class="headerlink" title="6.2 导入验证"></a>6.2 导入验证</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看导入后的目录</span></span><br><span class="line">hdfs dfs -<span class="built_in">ls</span> -R /sqoop</span><br><span class="line"><span class="comment"># 查看导入内容</span></span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> /sqoop/part-m-00000</span><br></pre></td></tr></table></figure><h3 id="6-3-增量导入"><a href="#6-3-增量导入" class="headerlink" title="6.3 增量导入"></a>6.3 增量导入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.147:3306/mysql \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table help_keyword \</span><br><span class="line">--target-dir /sqoop  \</span><br><span class="line">--append \</span><br><span class="line">--incremental  append  \             </span><br><span class="line">--fields-terminated-by <span class="string">&#x27;\t&#x27;</span> \</span><br><span class="line">--check-column  help_keyword_id \</span><br><span class="line">--last-value 463  \ </span><br><span class="line">-m 1</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--fields-terminated-by &#x27;</span>\t<span class="string">&#x27; \    # 指定导出数据的分隔符</span></span><br><span class="line"><span class="string">--check-column  help_keyword_id \    # 指明用于增量导入的参考列</span></span><br><span class="line"><span class="string">--last-value 463  \    # 指定参考列上次导入的最大值 </span></span><br><span class="line"><span class="string">-m 1</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="6-4-HDFS数据导出到MySQL"><a href="#6-4-HDFS数据导出到MySQL" class="headerlink" title="6.4 HDFS数据导出到MySQL"></a>6.4 HDFS数据导出到MySQL</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE help_keyword_from_hdfs LIKE help_keyword;</span><br><span class="line">sqoop <span class="built_in">export</span> \</span><br><span class="line">--connect jdbc:mysql://192.168.33.147:3306/mysql \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table help_keyword_from_hdfs \</span><br><span class="line">--export-dir /sqoop/* \</span><br><span class="line">--input-fields-terminated-by <span class="string">&#x27;\t&#x27;</span> \</span><br><span class="line">-m 3</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--table help_keyword_from_hdfs \     # 导出数据存储在 MySQL 的 help_keyword_from_hdf 的表中</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-cube modern&quot;&gt;&lt;p&gt;简介：Apache Sqoop 是一个常用的数据迁移工具，主要用于在不同存储系统之间实现数据的导入与导出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;导入数据：从 My</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>六、Kylin(麒麟)安装及基本使用--多维分析</title>
    <link href="https://xin0203xin0203.github.io/posts/e170afa6.html"/>
    <id>https://xin0203xin0203.github.io/posts/e170afa6.html</id>
    <published>2023-12-17T17:15:29.541Z</published>
    <updated>2024-12-18T12:18:44.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-book modern"><p>简介:  <a href="https://kylin.apache.org/cn/"><strong>Apache Kylin™</strong></a>是一个开源的、分布式的分析引擎，提供 Hadoop/Spark 之上的 SQL 查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由 eBay 开发并贡献至开源社区。它能在亚秒内查询巨大的表。Apache Kylin也是中国人主导的、唯一的Apache顶级开源项目，在开源社区有世界级的影响力。</p></div><div class="tip bolt"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%BA%8C%E3%80%81zookeeper%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/u25360462/nt1ri1/wzn655?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7LkQP.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">二、zookeeper组件搭建</div>            <div class="tag-link-sitename">介绍：Zookeeper 是一个开源的分布式协调服务，目前由 Apache 进行维护。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%89%E3%80%81Hive%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA--%3E%E5%86%85%E5%90%ABMySQL%E5%AE%89%E8%A3%85%5D(https:/www.yuque.com/u25360462/nt1ri1/zamxgf?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bvhc.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">三、Hive组件搭建-->内含MySQL安装</div>            <div class="tag-link-sitename">Hive：由Facebook开源用于解决海量结构化日志的数据统计。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E5%9B%9B%E3%80%81HBase%E7%BB%84%E4%BB%B6%5D(https:/www.yuque.com/u25360462/nt1ri1/rncd28?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bDDb.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">四、HBase组件</div>            <div class="tag-link-sitename">介绍：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note primary simple"><p>需要的安装包：<a href="http://kylin.apache.org/cn/download/"><strong>Kylin(麒麟)</strong></a>包—-&gt;<strong>apache-kylin-4.0.2-bin.tar.gz</strong></p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BKylin(%E9%BA%92%E9%BA%9F)%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/mfvldzG9VFU6_jZSUJFuSg)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7byG9.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Kylin(麒麟)安装及基本使用</div>            <div class="tag-link-sitename">Apache Kylin™是一个开源的、分布式的分析引擎，提供 Hadoop/Spark 之上的 SQL 查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由 eBay 开发并贡献至开源社区。它能在亚秒内查询巨大的表。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BKylin%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2_%E5%BF%84%E5%87%9D%5E%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2_kylin%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E9%83%A8%E7%BD%B2%5D(https:/blog.csdn.net/weixin_43660536/article/details/119773857)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bjDY.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Kylin集群安装部署</div>            <div class="tag-link-sitename">这里目录标题3、`Kylin`集群安装部署3.1. 下载上传3.1.2 修改 hive 配置文件3.1.3 修改 hbase 配置文件3.1.4 配置 kylin 相关环境变量3.1.5 修改配置文件3.1.6 拷贝kylin到其他节点3.1.7 启动3.1.8 关机拍照3、Kylin集群安装部署安装前提OS: CentOS 7java 1.8zookeeper 3.4.5</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1 准备工作"></a>1 准备工作</h2><h3 id="1-解压并改名"><a href="#1-解压并改名" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-kylin-4.0.2-bin.tar.gz -C /opt/</span><br><span class="line"><span class="built_in">mv</span> apache-kylin-4.0.2-bin kylin</span><br></pre></td></tr></table></figure><h2 id="2-配置Kylin环境变量"><a href="#2-配置Kylin环境变量" class="headerlink" title="2. 配置Kylin环境变量"></a>2. 配置Kylin环境变量</h2><h3 id="1-配置Kylin环境变量"><a href="#1-配置Kylin环境变量" class="headerlink" title="1. 配置Kylin环境变量"></a>1. 配置Kylin环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"></span><br><span class="line">修改内容：</span><br><span class="line"><span class="built_in">export</span> KYLIN_HOME=/opt/kylin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KYLIN_HOME</span>/bin</span><br></pre></td></tr></table></figure><h3 id="2-加载环境变量"><a href="#2-加载环境变量" class="headerlink" title="2. 加载环境变量"></a>2. 加载环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h2 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h2><p>3.1.1 配置<code>conf目录</code>下的<code>kylin.properties</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 改成东八区, 否则会出现时间显示不准的问题</span></span><br><span class="line">kylin.web.timezone=GMT+8</span><br></pre></td></tr></table></figure><br>3.1.2 配置bin目录下的kylin.sh<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [[ -z <span class="variable">$reload_dependency</span> &amp;&amp; `<span class="built_in">ls</span> -1 <span class="variable">$&#123;dir&#125;</span>/cached-* 2&gt;/dev/null | <span class="built_in">wc</span> -l` -eq 5 ]]</span><br><span class="line">   <span class="keyword">then</span></span><br><span class="line">       <span class="built_in">echo</span> <span class="string">&quot;Using cached dependency...&quot;</span></span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/cached-hive-dependency.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/cached-hbase-dependency.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/cached-hadoop-conf-dir.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/cached-kafka-dependency.sh</span><br><span class="line">       <span class="comment">#source $&#123;dir&#125;/cached-spark-dependency.sh</span></span><br><span class="line">   <span class="keyword">else</span></span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/find-hive-dependency.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/find-hbase-dependency.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/find-hadoop-conf-dir.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/find-kafka-dependency.sh</span><br><span class="line">       <span class="comment">#source $&#123;dir&#125;/find-spark-dependency.sh</span></span><br><span class="line">   <span class="keyword">fi</span></span><br></pre></td></tr></table></figure><br>3.1.3 配置HBased的<strong>hbase-site.xml</strong><br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--指定 zookeeper 地址--&gt;</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master,slave1,slave2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure></p><h2 id="4-启动Kylin"><a href="#4-启动Kylin" class="headerlink" title="4. 启动Kylin"></a>4. 启动Kylin</h2><p><strong>4.1.1 启动Kylin之前确保HDFS、YARN、Zookeeper、HBase已经启动</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kylin.sh start</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">A new Kylin instance is started by root. To stop it, run &#x27;</span>kylin.sh stop<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Check the log at /opt/kylin/logs/kylin.log</span></span><br><span class="line"><span class="string">Web UI is at http://master:7070/kylin</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">A new Kylin instance is started by root. To stop it, run &#x27;</span>kylin.sh stop<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Check the log at /opt/kylin/logs/kylin.log</span></span><br><span class="line"><span class="string">Web UI is at http://slave1:7070/kylin</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">A new Kylin instance is started by root. To stop it, run &#x27;</span>kylin.sh stop<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Check the log at /opt/kylin/logs/kylin.log</span></span><br><span class="line"><span class="string">Web UI is at http://slave2:7070/kylin</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">访问 https://slave2:7070/kylin ；默认的用户名和密码为 ADMIN 和 KYLIN</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-book modern&quot;&gt;&lt;p&gt;简介:  &lt;a href=&quot;https://kylin.apache.org/cn/&quot;&gt;&lt;strong&gt;Apache Kylin™&lt;/strong&gt;&lt;/</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>九、Azkaban-solo-server--工作流调度</title>
    <link href="https://xin0203xin0203.github.io/posts/682fb25a.html"/>
    <id>https://xin0203xin0203.github.io/posts/682fb25a.html</id>
    <published>2023-12-17T17:15:29.529Z</published>
    <updated>2024-12-18T12:59:51.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Gradle安装"><a href="#1-Gradle安装" class="headerlink" title="1. Gradle安装"></a>1. <a href="https://blog.csdn.net/qq_42055933/article/details/125923776?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166737555116782395381760%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166737555116782395381760&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-125923776-null-null.142^v62^pc_rank_34_queryrelevant25,201^v3^control_1,213^v1^control&amp;utm_term=Gradle&amp;spm=1018.2226.3001.4187"><strong>Gradle</strong></a>安装</h1><div class="note green anzhiyufont anzhiyu-icon-gear modern"><p>简介：Gradle是一款Google推出的 <strong>基于JVM</strong>、 通用灵活的 项目构建工具， 支持<a href="https://so.csdn.net/so/search?q=Maven&amp;spm=1001.2101.3001.7020"><strong>Maven</strong></a>，JCenter多种第三方仓库;支持传递性依赖管理、废弃了繁杂的xml文件，转而使用 <strong>简洁的 、 支持多种语言</strong> (例如：java、<a href="https://so.csdn.net/so/search?q=groovy&amp;spm=1001.2101.3001.7020"><strong>groovy</strong></a>等)的 build脚本文件 。</p></div><div class="tip bell"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note warning modern"><p>需要的安装包： <strong><a href="https://gradle.org/releases/">Gradle</a>包—-&gt;gradle-4.6-all.zip</strong></p></div><font color=red size=3px weight=bold>注意：有版本依赖，过高的版本会报错</font>## 1-1 准备工作### 1-1-1 下载zip解压组件<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install unzip</span><br></pre></td></tr></table></figure>### 1-1-2 解压并改名<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unzip gradle-4.6-all.zip -r /opt/</span><br><span class="line"><span class="built_in">mv</span> gradle-4.6 gradle</span><br></pre></td></tr></table></figure>## 1-2 配置Gradle环境变量### 1-2-1 配置Gradle环境变量<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="comment"># gradle</span></span><br><span class="line"><span class="built_in">export</span> GRADLE_HOME=/opt/maven</span><br><span class="line"><span class="built_in">export</span> GRADLE_USER_HOME=/opt/gradle</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$GRADLE_HOME</span>/bin</span><br></pre></td></tr></table></figure>### 1-2-2 加载环境变量<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>## 1-3 修改配置### 1-3-1 创建本地目录<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/gradle/gradle_repository</span><br></pre></td></tr></table></figure>### 1-3-2 新创建文件并配置 `init.gradle`**（ init.gradle就相当于maven中的settings.xml）**配置在`/opt/gradle/init.d`<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">allprojects &#123;</span><br><span class="line">    repositories &#123;</span><br><span class="line">        maven &#123; url <span class="string">&#x27;file:///opt/maven/maven_repository&#x27;</span>&#125;</span><br><span class="line">        <span class="built_in">mavenLocal</span>()</span><br><span class="line">        maven &#123; name <span class="string">&quot;Alibaba&quot;</span> ; url <span class="string">&quot;https://maven.aliyun.com/repository/public&quot;</span> &#125;</span><br><span class="line">        maven &#123; name <span class="string">&quot;Bstek&quot;</span> ; url <span class="string">&quot;http://nexus.bsdn.org/content/groups/public/&quot;</span> &#125;</span><br><span class="line">        <span class="built_in">mavenCentral</span>()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    buildscript &#123; </span><br><span class="line">        repositories &#123; </span><br><span class="line">            maven &#123; name <span class="string">&quot;Alibaba&quot;</span> ; url <span class="string">&#x27;https://maven.aliyun.com/repository/public&#x27;</span> &#125;</span><br><span class="line">            maven &#123; name <span class="string">&quot;Bstek&quot;</span> ; url <span class="string">&#x27;http://nexus.bsdn.org/content/groups/public/&#x27;</span> &#125;</span><br><span class="line">            maven &#123; name <span class="string">&quot;M2&quot;</span> ; url <span class="string">&#x27;https://plugins.gradle.org/m2/&#x27;</span> &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>## 1-4 验证### 1-4-1 是否安装成功<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./gradle -v</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">------------------------------------------------------------</span></span><br><span class="line"><span class="string">Gradle 4.6.0</span></span><br><span class="line"><span class="string">------------------------------------------------------------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Build time:   2022-10-17 07:44:02 UTC</span></span><br><span class="line"><span class="string">Revision:     a6198e44749b18b37e26b3b3467db17e034bcff4</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Kotlin:       1.4.20</span></span><br><span class="line"><span class="string">Groovy:       2.5.12</span></span><br><span class="line"><span class="string">Ant:          Apache Ant(TM) version 1.10.9 compiled on September 27 2020</span></span><br><span class="line"><span class="string">JVM:          1.8.0_341 (Oracle Corporation 25.341-b10)</span></span><br><span class="line"><span class="string">OS:           Linux 3.10.0-862.el7.x86_64 amd64</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BAzkaban-solo-server%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/qNGI1iJVvnrjrz8z83B0Qg)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7labz.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Azkaban-solo-server环境搭建</div>            <div class="tag-link-sitename">Azkaban-solo-server环境搭建-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div># 2. [**Azkaban-solo-server**](https://azkaban.readthedocs.io/en/latest/containerization-design.html)安装<div class="note green anzhiyufont anzhiyu-icon-gear modern"><p>简介：solo-server mode（单服务模式）：元数据默认存放在内置的 H2 数据库，该模式中 webServer(管理服务器) 和 executorServer(执行服务器) 运行在同一个进程中，进程名是 AzkabanSingleServer 。该模式适用于小规模工作流的调度，适合用于尝试和了解azkaban的功能。</p></div><div class="note primary simple"><p>需要的安装包： <strong><a href="https://github.com/azkaban/azkaban/releases">azkaban</a>包—-&gt;azkaban-3.57.0.tar.gz</strong></p></div>## 2-1 准备工作### 2-1-1 解压并改名<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf azkaban-3.57.0.tar.gz</span><br><span class="line"><span class="built_in">mv</span> azkaban-3.57.0 azkaban</span><br></pre></td></tr></table></figure>## 2-2 源码编译### 2-2-1 查看Azkaban 依赖 Gradle 版本<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> /opt/azkaban/gradle/wrapper/gradle-wrapper.properties</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># Copyright 2018 LinkedIn Corp.</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not</span></span><br><span class="line"><span class="string"># use this file except in compliance with the License. You may obtain a copy of</span></span><br><span class="line"><span class="string"># the License at</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT</span></span><br><span class="line"><span class="string"># WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the</span></span><br><span class="line"><span class="string"># License for the specific language governing permissions and limitations under</span></span><br><span class="line"><span class="string"># the License.</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">distributionBase=GRADLE_USER_HOME</span></span><br><span class="line"><span class="string">distributionPath=wrapper/dists</span></span><br><span class="line"><span class="string">zipStoreBase=GRADLE_USER_HOME</span></span><br><span class="line"><span class="string">zipStorePath=wrapper/dists</span></span><br><span class="line"><span class="string">distributionUrl=https\://services.gradle.org/distributions/gradle-4.6-all.zip</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>### 2-2-2 拷贝对应gradle版本和修改`gradle-wrapper.properties`中的 **distributionUrl 属性**，指明使用本地的 `gradle`<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> gradle-4.6-all.zip /opt/azkaban/gradle/wrapper/</span><br><span class="line">vim /opt/azkaban/gradle/wrapper/gradle-wrapper.properties</span><br><span class="line">修改为：</span><br><span class="line">distributionUrl=gradle-4.6-all.zip</span><br></pre></td></tr></table></figure>### 2-2-3 在安装目录下执行编译命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@master azkaban]$ ./gradlew distTar</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">BUILD SUCCESSFUL in 25s</span></span><br><span class="line"><span class="string">54 actionable tasks: 5 executed, 49 up-to-date</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>### 2-2-4 报错解决<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Parallel execution with configuration on demand is an incubating feature.</span><br><span class="line"></span><br><span class="line">FAILURE: Build failed with an exception.</span><br><span class="line"></span><br><span class="line">* Where:</span><br><span class="line">Build file <span class="string">&#x27;/opt/azkaban/build.gradle&#x27;</span> line: 41</span><br><span class="line"></span><br><span class="line">* What went wrong:</span><br><span class="line">A problem occurred evaluating root project <span class="string">&#x27;azkaban&#x27;</span>.</span><br><span class="line">&gt; Failed to apply plugin [<span class="built_in">id</span> <span class="string">&#x27;com.cinnober.gradle.semver-git&#x27;</span>]</span><br><span class="line">   &gt; Cannot run program <span class="string">&quot;git&quot;</span> (<span class="keyword">in</span> directory <span class="string">&quot;/opt/azkaban&quot;</span>): error=2, 没有那个文件或目录</span><br><span class="line"></span><br><span class="line">* Try:</span><br><span class="line">Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more <span class="built_in">log</span> output. Run with --scan to get full insights.</span><br><span class="line"></span><br><span class="line">* Get more <span class="built_in">help</span> at https://help.gradle.org</span><br><span class="line"></span><br><span class="line">BUILD FAILED <span class="keyword">in</span> 1s</span><br><span class="line"></span><br><span class="line">解决方案：下载组件，因为linux没有下载git的渠道</span><br><span class="line">sudo yum -y install git</span><br><span class="line">sudo yum -y install gcc-c++</span><br></pre></td></tr></table></figure>## 2-3 Solo Server 模式部署### 2-3-1 解压编译后的`Solo Server`模式安装包,并改名<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/azkaban/azkaban-solo-server/build/distributions/</span><br><span class="line">tar -zxvf azkaban-solo-server-0.1.0-SNAPSHOT.tar.gz -C /opt/</span><br><span class="line"><span class="built_in">mv</span> azkaban-solo-server-0.1.0-SNAPSHOT/ azkaban-solo-serve</span><br></pre></td></tr></table></figure>### 2-3-2 修改时区，进入`conf目录`，修改**azkaban.properties**<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim azkaban.properties</span><br><span class="line">修改为：</span><br><span class="line">default.timezone.id=Asia/Shanghai</span><br></pre></td></tr></table></figure>### 2-3-3 启动，执行启动命令，需要注意的是一定要在根目录下执行，不能进入 `bin目录`下执行，不然会抛出 `Cannot find 'database.properties'` 异常。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master azkaban-solo-server]$ bin/start-solo.sh </span><br></pre></td></tr></table></figure>### 2-3-4 验证#### 第一种：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">114226</span> AzkabanSingleServer</span><br><span class="line"><span class="number">114238</span> Jps</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"># 如果节点占用端口，如：</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">114226</span> AzkabanSingleServer</span><br><span class="line"><span class="number">113927</span> GradleDaemon</span><br><span class="line"><span class="number">110906</span> DataXExecutorApplication</span><br><span class="line"><span class="number">114238</span> Jps</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">就直接卡掉</span><br><span class="line">kill <span class="number">-9</span> <span class="number">113927</span> <span class="number">110906</span></span><br></pre></td></tr></table></figure>#### 第二种：验证方式二：访问 8081 端口，查看 Web UI 界面，默认的登录名密码都是 `azkaban`，如果需要修改或新增用户，可以在 `conf/azkaban-users.xml` 文件中进行配置：<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;azkaban-users&gt;</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">user</span> <span class="attr">groups</span>=<span class="string">&quot;azkaban&quot;</span> <span class="attr">password</span>=<span class="string">&quot;azkaban&quot;</span> <span class="attr">roles</span>=<span class="string">&quot;admin&quot;</span> <span class="attr">username</span>=<span class="string">&quot;azkaban&quot;</span>/&gt;</span></span></span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">user</span> <span class="attr">password</span>=<span class="string">&quot;metrics&quot;</span> <span class="attr">roles</span>=<span class="string">&quot;metrics&quot;</span> <span class="attr">username</span>=<span class="string">&quot;metrics&quot;</span>/&gt;</span></span></span><br><span class="line"></span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">role</span> <span class="attr">name</span>=<span class="string">&quot;admin&quot;</span> <span class="attr">permissions</span>=<span class="string">&quot;ADMIN&quot;</span>/&gt;</span></span></span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">role</span> <span class="attr">name</span>=<span class="string">&quot;metrics&quot;</span> <span class="attr">permissions</span>=<span class="string">&quot;METRICS&quot;</span>/&gt;</span></span></span><br><span class="line">&lt;/azkaban-users&gt;</span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>Azkaban-solo-server</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MPdC.png" alt="Azkaban-solo-server" title="Azkaban-solo-server"></p><h2 id="2-3-基本任务调度"><a href="#2-3-基本任务调度" class="headerlink" title="2-3 基本任务调度"></a>2-3 基本任务调度</h2><h3 id="2-3-1-新建项目"><a href="#2-3-1-新建项目" class="headerlink" title="2-3-1 新建项目"></a>2-3-1 新建项目</h3><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>Azkaban 主界面创建一个新项目</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MXMu.png" alt="Azkaban 主界面创建一个新项目" title="Azkaban 主界面创建一个新项目"></p><h3 id="2-3-2-任务配置"><a href="#2-3-2-任务配置" class="headerlink" title="2-3-2 任务配置"></a>2-3-2 任务配置</h3><p>新建任务配置文件 huser.job，内容如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#command.job</span></span><br><span class="line"><span class="built_in">type</span>=<span class="built_in">command</span></span><br><span class="line"><span class="built_in">command</span>=<span class="built_in">echo</span> <span class="string">&#x27;Hello Azkaban,Flow-1.0!xk1181259634!$$$$!  Azkaban &#x27;</span></span><br></pre></td></tr></table></figure><br> 通过 Web UI 界面上传：<br> <font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>Azkaban-solo-server—打包上传</font></p><p><img src="https://vip.helloimg.com/images/2023/12/18/o7M3Xt.png" alt="Azkaban-solo-server--打包上传" title="Azkaban-solo-server--打包上传"></p><h3 id="2-3-4-执行任务，-点击页面上的-Execute-Flow-执行任务："><a href="#2-3-4-执行任务，-点击页面上的-Execute-Flow-执行任务：" class="headerlink" title="2-3-4 执行任务， 点击页面上的 Execute Flow 执行任务："></a>2-3-4 执行任务， 点击页面上的 Execute Flow 执行任务：</h3> <font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>Azkaban-solo-server--执行任务</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MaVQ.png" alt="Azkaban-solo-server--执行任务" title="Azkaban-solo-server--执行任务"></p><h3 id="2-3-5-执行结果，点击-Log-可以查看到任务的执行日志"><a href="#2-3-5-执行结果，点击-Log-可以查看到任务的执行日志" class="headerlink" title="2-3-5 执行结果，点击 Log 可以查看到任务的执行日志"></a>2-3-5 执行结果，点击 Log 可以查看到任务的执行日志</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-Gradle安装&quot;&gt;&lt;a href=&quot;#1-Gradle安装&quot; class=&quot;headerlink&quot; title=&quot;1. Gradle安装&quot;&gt;&lt;/a&gt;1. &lt;a href=&quot;https://blog.csdn.net/qq_42055933/article/d</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>三、Hive组件搭建--内含MySQL安装</title>
    <link href="https://xin0203xin0203.github.io/posts/e3a54e89.html"/>
    <id>https://xin0203xin0203.github.io/posts/e3a54e89.html</id>
    <published>2023-12-15T07:30:17.236Z</published>
    <updated>2024-12-17T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<div class="tip error"><p>前提准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%BA%8C%E3%80%81zookeeper%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/u25360462/nt1ri1/wzn655?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7LkQP.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">二、zookeeper组件搭建</div>            <div class="tag-link-sitename">介绍：Zookeeper 是一个开源的分布式协调服务，目前由 Apache 进行维护。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="tip ban"><p>需要的安装包：</p></div><p>1.<a href="https://dev.mysql.com/downloads/file/?id=514685"><strong>MySQL</strong></a>压缩包—-&gt;mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar<br>2.<a href="https://dlcdn.apache.org/hive/"><strong>Hive</strong></a>压缩包—-&gt;apache-hive-2.3.4-bin.tar.gz<br>3.<a href="https://dev.mysql.com/downloads/connector/j/"><strong>MySQL的jar</strong></a>包—-&gt;mysql-connector-java-5.1.37.jar<br>4.<a href="https://www.apache.org/dyn/closer.lua/tez/0.9.2/"><strong>tez引擎</strong></a>包—-&gt;apache-tez-0.9.2-bin.tar.gz</p><h1 id="一、CentOS7-x安装MYSQL8-0-19"><a href="#一、CentOS7-x安装MYSQL8-0-19" class="headerlink" title="一、CentOS7.x安装MYSQL8.0.19"></a>一、CentOS7.x安装MYSQL8.0.19</h1><font color=red size=3px>跟Hive组件一起连用，如果不需要，可以跳过</font><details class="folding-tag" yellow><summary> MySQL 8.0新特性： </summary>              <div class='content'>              <ul><li>1、默认字符集由latin1变为utf8mb4</li><li>2、MyISAM系统表全部换成InnoDB表</li><li>3、自增主键AUTO_INCREMENT的值支持持久化</li><li>4、InnoDB表的DDL支持事务完整性</li><li>5、支持在线修改全局参数并持久化</li><li>6、新增降序索引</li><li>7、对于group by字段不再隐式排序</li><li>8、大幅改进了对JSON的支持</li><li>9、支持redo和undo日志加密</li><li>10、InnoDB select for update跳过锁等待</li><li>11、在SQL语法中增加SET_VAR语法</li><li>12、使用INVISIBLE关键字在创建表或进行表变更中设置索引是否可见</li><li>13、支持直方图</li><li>14、新增innodb_dedicated_server参数</li><li>15、日志分类更详细</li><li>16、undo空间自动回收</li><li>17、新增资源组功能，用于调控线程优先级及绑定CPU</li><li>18、增加角色管理</li></ul>              </div>            </details><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B009-%E5%B0%9A%E7%A1%85%E8%B0%B7-Hive-%E9%85%8D%E7%BD%AEHive%E5%85%83%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E4%B8%BAMySQL&%E5%86%8D%E6%AC%A1%E5%90%AF%E5%8A%A8%E6%B5%8B%E8%AF%95_%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9_bilibili%5D(https:/www.bilibili.com/video/BV1EZ4y1G7iL/?p=9&spm_id_from=pageDriver&vd_source=da2acaac8a1d2357dae9e3de7ea3357e)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bdwh.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">尚硅谷-Hive-配置Hive元数据存储为MySQL</div>            <div class="tag-link-sitename">009-尚硅谷-Hive-配置Hive元数据存储为MySQL&再次启动测试_哔哩哔哩_bilibili</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div>## 1. 安装文件### 1.1 关闭[**firewalld**](https://so.csdn.net/so/search?q=firewalld&urw=)和[**selinux**](https://so.csdn.net/so/search?q=selinux&urw=)<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="string">&#x27;查看防火墙&#x27;</span>&gt; systemctl status firewalld</span><br><span class="line">&lt;<span class="string">&#x27;关闭防火墙&#x27;</span>&gt; sudo systemctl stop firewalld</span><br><span class="line">&lt;<span class="string">&#x27;关闭selinux&#x27;</span>&gt; sudo vim /etc/selinux/config</span><br><span class="line">修改为:</span><br><span class="line">      SELINUX=disabled</span><br><span class="line">      SELINUXTYPE=targeted</span><br><span class="line">&lt;<span class="string">&#x27;查看selinux&#x27;</span>&gt; sestatus</span><br></pre></td></tr></table></figure>### 1.2 删除CentOS 7.x自带的[**MariaDB**](https://so.csdn.net/so/search?q=MariaDB&urw=)<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="string">&#x27;查看mariadb&#x27;</span>&gt; rpm -qa | grep -i mariadb</span><br><span class="line">mariadb-libs-5.5.56-2.el7.x86_64</span><br><span class="line">&lt;<span class="string">&#x27;删掉mariadb&#x27;</span>&gt; sudo rpm -e --nodeps mariadb-libs-5.5.56-2.el7.x86_64</span><br></pre></td></tr></table></figure>### <font color=red>(可跳过)</font>1.3 删除原有的MySQL<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="string">&#x27;查看MySQL&#x27;</span>&gt; rpm -qa | grep -i mysql</span><br><span class="line">&lt;<span class="string">&#x27;卸载MySQL&#x27;</span>&gt; sudo yum -y remove <span class="string">&#x27;文件&#x27;</span></span><br><span class="line">&lt;<span class="string">&#x27;查找MySQL相关目录&#x27;</span>&gt; sudo find / -name mysql</span><br><span class="line">&lt;<span class="string">&#x27;删除MySQL相关目录&#x27;</span>&gt; sudo <span class="built_in">rm</span> -rf <span class="string">&#x27;文件&#x27;</span></span><br></pre></td></tr></table></figure>### 1.4 下载并安装[**MySQL8.0**](https://blog.csdn.net/young_0609/article/details/109015666)<font color=red>这里直接使用`mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar`就行了不用wget下载</font><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wegt 不能执行,就直接下载wegt组件 ---&gt;  sudo yum -y install wget</span></span><br><span class="line"><span class="string">wget</span> <span class="string">https://cdn.mysql.com//Downloads/MySQL-Cluster-8.0/mysql-cluster-community-8.0.31-1.el9.x86_64.rpm-bundle.tar</span></span><br><span class="line"><span class="string">tar</span> <span class="string">-xf</span> <span class="string">mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</span> <span class="string">-C</span> <span class="string">/opt/</span></span><br></pre></td></tr></table></figure><h3 id="1-5-压缩MySQL运行包"><a href="#1-5-压缩MySQL运行包" class="headerlink" title="1.5 压缩MySQL运行包"></a>1.5 压缩MySQL运行包</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">sudo</span> <span class="string">rpm</span> <span class="string">-ivh</span> <span class="string">mysql-community-common-5.7.28-1.el7.x86_64.rpm</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">rpm</span> <span class="string">-ivh</span> <span class="string">mysql-community-libs-5.7.28-1.el7.x86_64.rpm</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">rpm</span> <span class="string">-ivh</span> <span class="string">mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">rpm</span> <span class="string">-ivh</span> <span class="string">mysql-community-client-5.7.28-1.el7.x86_64.rpm</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">rpm</span> <span class="string">-ivh</span> <span class="string">mysql-community-server-5.7.28-1.el7.x86_64.rpm</span></span><br></pre></td></tr></table></figure><h3 id="1-6-如果mysql-community-server-5-7-28-1-el7-x86-64-rpm安装报错，就下载MySQL-server依赖包"><a href="#1-6-如果mysql-community-server-5-7-28-1-el7-x86-64-rpm安装报错，就下载MySQL-server依赖包" class="headerlink" title="1.6 如果mysql-community-server-5.7.28-1.el7.x86_64.rpm安装报错，就下载MySQL-server依赖包"></a>1.6 如果<code>mysql-community-server-5.7.28-1.el7.x86_64.rpm</code>安装报错，就下载MySQL-server依赖包</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">yum</span> <span class="string">-y</span> <span class="string">install</span> <span class="string">libaio</span></span><br></pre></td></tr></table></figure><h2 id="2-配置MySQL文件并启动"><a href="#2-配置MySQL文件并启动" class="headerlink" title="2. 配置MySQL文件并启动"></a>2. 配置MySQL文件并启动</h2><h3 id="2-1-查看datadir的值"><a href="#2-1-查看datadir的值" class="headerlink" title="2.1 查看datadir的值"></a>2.1 查看datadir的值</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> /etc/my.cnf</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string"># For advice on how to change settings please see</span></span><br><span class="line"><span class="string"># http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[mysqld]</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># Remove leading # and set to the amount of RAM for the most important data</span></span><br><span class="line"><span class="string"># cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.</span></span><br><span class="line"><span class="string"># innodb_buffer_pool_size = 128M</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># Remove leading # to turn on a very important data integrity option: logging</span></span><br><span class="line"><span class="string"># changes to the binary log between backups.</span></span><br><span class="line"><span class="string"># log_bin</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># Remove leading # to set options mainly useful for reporting servers.</span></span><br><span class="line"><span class="string"># The server defaults are faster for transactions and fast SELECTs.</span></span><br><span class="line"><span class="string"># Adjust sizes as needed, experiment to find the optimal values.</span></span><br><span class="line"><span class="string"># join_buffer_size = 128M</span></span><br><span class="line"><span class="string"># sort_buffer_size = 2M</span></span><br><span class="line"><span class="string"># read_rnd_buffer_size = 2M</span></span><br><span class="line"><span class="string">datadir=/var/lib/mysql</span></span><br><span class="line"><span class="string">socket=/var/lib/mysql/mysql.sock</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Disabling symbolic-links is recommended to prevent assorted security risks</span></span><br><span class="line"><span class="string">symbolic-links=0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">log-error=/var/log/mysqld.log</span></span><br><span class="line"><span class="string">pid-file=/var/run/mysqld/mysqld.pid</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="2-2-删除-var-lib-mysql目录下的所有内容："><a href="#2-2-删除-var-lib-mysql目录下的所有内容：" class="headerlink" title="2.2 删除/var/lib/mysql目录下的所有内容："></a>2.2 删除<code>/var/lib/mysql目录</code>下的所有内容：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">rm</span> -rf ./*// 注意执行命令,删错了重来(传说中的：删库跑路)</span><br><span class="line"><span class="comment">#查看内容:</span></span><br><span class="line">sudo <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><h3 id="2-3-初始化数据库"><a href="#2-3-初始化数据库" class="headerlink" title="2.3 初始化数据库"></a>2.3 <a href="https://blog.csdn.net/liuwkk/article/details/110627234"><strong>初始化</strong></a>数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mysqld --initialize --user=mysql</span><br></pre></td></tr></table></figure><h3 id="2-4-查看临时生成的root用户的密码"><a href="#2-4-查看临时生成的root用户的密码" class="headerlink" title="2.4 查看临时生成的root用户的密码"></a>2.4 查看临时生成的root用户的密码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">cat</span> /var/log/mysqld.log</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-11-13T14:19:22.104258Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).</span></span><br><span class="line"><span class="string">2022-11-13T14:19:22.525465Z 0 [Warning] InnoDB: New log files created, LSN=45790</span></span><br><span class="line"><span class="string">2022-11-13T14:19:22.703239Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.</span></span><br><span class="line"><span class="string">2022-11-13T14:19:22.822416Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 2b9e4e23-635e-11ed-a517-000c29b25ef7.</span></span><br><span class="line"><span class="string">2022-11-13T14:19:22.826219Z 0 [Warning] Gtid table is not ready to be used. Table &#x27;</span>mysql.gtid_executed<span class="string">&#x27; cannot be opened.</span></span><br><span class="line"><span class="string">2022-11-13T14:19:23.146937Z 0 [Warning] CA certificate ca.pem is self signed.</span></span><br><span class="line"><span class="string">2022-11-13T14:19:23.425713Z 1 [Note] A temporary password is generated for root@localhost: ?yr6d34alX5q</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 密码:  ?yr6d34alX5q</span></span><br></pre></td></tr></table></figure><h3 id="2-5-启动MySQL及查看启动状态"><a href="#2-5-启动MySQL及查看启动状态" class="headerlink" title="2.5 启动MySQL及查看启动状态"></a>2.5 启动MySQL及查看启动状态</h3><font color=red size=3px>不是管理者需要sudo</font><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">service mysqld start</span><br><span class="line">service mysqld status</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Redirecting to /bin/systemctl status mysqld.service</span></span><br><span class="line"><span class="string">● mysqld.service - MySQL Server</span></span><br><span class="line"><span class="string">   Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)</span></span><br><span class="line"><span class="string">   Active: active (running) since 日 2022-11-13 22:24:37 CST; 18s ago</span></span><br><span class="line"><span class="string">     Docs: man:mysqld(8)</span></span><br><span class="line"><span class="string">           http://dev.mysql.com/doc/refman/en/using-systemd.html</span></span><br><span class="line"><span class="string">  Process: 42313 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS)</span></span><br><span class="line"><span class="string">  Process: 42296 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS)</span></span><br><span class="line"><span class="string"> Main PID: 42316 (mysqld)</span></span><br><span class="line"><span class="string">   CGroup: /system.slice/mysqld.service</span></span><br><span class="line"><span class="string">           └─42316 /usr/sbin/mysqld --daemonize --pid-file=/var/run...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">11月 13 22:24:36 master systemd[1]: Starting MySQL Server...</span></span><br><span class="line"><span class="string">11月 13 22:24:37 master systemd[1]: Started MySQL Server.</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#  running 证明已开启</span></span><br><span class="line"><span class="comment">#  dead 证明已关闭</span></span><br></pre></td></tr></table></figure><h3 id="2-6-登录-lt-—-gt-登出"><a href="#2-6-登录-lt-—-gt-登出" class="headerlink" title="2.6  登录 &lt;! —- !&gt; 登出"></a>2.6  <strong>登录</strong> &lt;! —- !&gt; <strong>登出</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br><span class="line">Enter password:<span class="string">&#x27;?yr6d34alX5q(临时密码)&#x27;</span></span><br><span class="line"><span class="comment"># Welcome to the MySQL monitor.  Commands end with ; or \g.</span></span><br><span class="line"><span class="comment"># Your MySQL connection id is 16</span></span><br><span class="line"><span class="comment"># Server version: 8.0.20 MySQL Community Server - GPL</span></span><br><span class="line"><span class="comment"># Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.</span></span><br><span class="line"><span class="comment"># Oracle is a registered trademark of Oracle Corporation and/or its</span></span><br><span class="line"><span class="comment"># affiliates. Other names may be trademarks of their respective</span></span><br><span class="line"><span class="comment"># owners.</span></span><br><span class="line"><span class="comment"># Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span></span><br><span class="line"><span class="comment"># mysql&gt; </span></span><br></pre></td></tr></table></figure><h2 id="3-MySQL配置向导"><a href="#3-MySQL配置向导" class="headerlink" title="3. MySQL配置向导"></a>3. MySQL配置向导</h2><h3 id="3-1-修改root用户密码"><a href="#3-1-修改root用户密码" class="headerlink" title="3.1 修改root用户密码"></a>3.1 修改root用户密码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改MySQL的root密码,使及密码生效</span></span><br><span class="line">mysql&gt; <span class="built_in">set</span> password = password(<span class="string">&quot;新密码&quot;</span>);</span><br></pre></td></tr></table></figure><h3 id="3-2-进去mysql库中-修改mysqlku下的user表中的root用户允许任意ip连接-并及时生效"><a href="#3-2-进去mysql库中-修改mysqlku下的user表中的root用户允许任意ip连接-并及时生效" class="headerlink" title="3.2 进去mysql库中, 修改mysqlku下的user表中的root用户允许任意ip连接, 并及时生效"></a>3.2 进去mysql库中, 修改mysqlku下的user表中的root用户允许任意ip连接, 并及时生效</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">msyql&gt; show databases;---&gt; 查看数据库</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">+--------------------+</span></span><br><span class="line"><span class="string">| Database           |</span></span><br><span class="line"><span class="string">+--------------------+</span></span><br><span class="line"><span class="string">| information_schema |</span></span><br><span class="line"><span class="string">| mysql              |</span></span><br><span class="line"><span class="string">| performance_schema |</span></span><br><span class="line"><span class="string">| sys                |</span></span><br><span class="line"><span class="string">+--------------------+</span></span><br><span class="line"><span class="string">4 rows in set (0.01 sec)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">mysql&gt; show tables;---&gt; 查看数据表</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">+---------------------------+</span></span><br><span class="line"><span class="string">| Tables_in_mysql           |</span></span><br><span class="line"><span class="string">+---------------------------+</span></span><br><span class="line"><span class="string">| columns_priv              |</span></span><br><span class="line"><span class="string">| db                        |</span></span><br><span class="line"><span class="string">| engine_cost               |</span></span><br><span class="line"><span class="string">| event                     |</span></span><br><span class="line"><span class="string">| func                      |</span></span><br><span class="line"><span class="string">| general_log               |</span></span><br><span class="line"><span class="string">| gtid_executed             |</span></span><br><span class="line"><span class="string">| help_category             |</span></span><br><span class="line"><span class="string">| help_keyword              |</span></span><br><span class="line"><span class="string">| help_relation             |</span></span><br><span class="line"><span class="string">| help_topic                |</span></span><br><span class="line"><span class="string">| innodb_index_stats        |</span></span><br><span class="line"><span class="string">| innodb_table_stats        |</span></span><br><span class="line"><span class="string">| ndb_binlog_index          |</span></span><br><span class="line"><span class="string">| plugin                    |</span></span><br><span class="line"><span class="string">| proc                      |</span></span><br><span class="line"><span class="string">| procs_priv                |</span></span><br><span class="line"><span class="string">| proxies_priv              |</span></span><br><span class="line"><span class="string">| server_cost               |</span></span><br><span class="line"><span class="string">| servers                   |</span></span><br><span class="line"><span class="string">| slave_master_info         |</span></span><br><span class="line"><span class="string">| slave_relay_log_info      |</span></span><br><span class="line"><span class="string">| slave_worker_info         |</span></span><br><span class="line"><span class="string">| slow_log                  |</span></span><br><span class="line"><span class="string">| tables_priv               |</span></span><br><span class="line"><span class="string">| time_zone                 |</span></span><br><span class="line"><span class="string">| time_zone_leap_second     |</span></span><br><span class="line"><span class="string">| time_zone_name            |</span></span><br><span class="line"><span class="string">| time_zone_transition      |</span></span><br><span class="line"><span class="string">| time_zone_transition_type |</span></span><br><span class="line"><span class="string">| user                      |</span></span><br><span class="line"><span class="string">+---------------------------+</span></span><br><span class="line"><span class="string">31 rows in set (0.00 sec)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 先进到mysql里，use mysql;</span></span><br><span class="line">mysql&gt; <span class="keyword">select</span> Host,User from user;---&gt; 查user表中的root用户</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">+-----------+---------------+</span></span><br><span class="line"><span class="string">| Host      | User          |</span></span><br><span class="line"><span class="string">+-----------+---------------+</span></span><br><span class="line"><span class="string">| localhost | mysql.session |</span></span><br><span class="line"><span class="string">| localhost | mysql.sys     |</span></span><br><span class="line"><span class="string">| localhost | root          |</span></span><br><span class="line"><span class="string">+-----------+---------------+</span></span><br><span class="line"><span class="string">3 rows in set (0.00 sec)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">mysql&gt; update mysql.user <span class="built_in">set</span> host=<span class="string">&quot;%&quot;</span> <span class="built_in">where</span> user=<span class="string">&quot;root&quot;</span>; ---&gt; 修改权限</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Query OK, 1 row affected (0.01 sec)</span></span><br><span class="line"><span class="string">Rows matched: 1  Changed: 1  Warnings: 0</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">mysql&gt; <span class="keyword">select</span> Host,User from user;---&gt; 查user表中的root用户</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">+-----------+---------------+</span></span><br><span class="line"><span class="string">| Host      | User          |</span></span><br><span class="line"><span class="string">+-----------+---------------+</span></span><br><span class="line"><span class="string">| %         | root          |</span></span><br><span class="line"><span class="string">| localhost | mysql.session |</span></span><br><span class="line"><span class="string">| localhost | mysql.sys     |</span></span><br><span class="line"><span class="string">+-----------+---------------+</span></span><br><span class="line"><span class="string">3 rows in set (0.00 sec)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">mysql&gt; flush privileges;---&gt; 及时生效</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Query OK, 0 rows affected (0.00 sec)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="4-测试连接"><a href="#4-测试连接" class="headerlink" title="4. 测试连接"></a>4. 测试连接</h2><h3 id="4-1-mysql连接测试"><a href="#4-1-mysql连接测试" class="headerlink" title="4.1 mysql连接测试"></a>4.1 mysql连接测试</h3><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>hive--mysql--连接测试</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7bWD5.png" alt="hive--mysql--连接测试" title="hive--mysql--连接测试"></p><h3 id="4-2-连接成功"><a href="#4-2-连接成功" class="headerlink" title="4.2 连接成功"></a>4.2 连接成功</h3><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>hive--mysql--连接成功</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7bTHA.png" alt="hive--mysql--连接成功" title="hive--mysql--连接成功"></p><h1 id="二、-Hive组件搭建"><a href="#二、-Hive组件搭建" class="headerlink" title="二、 Hive组件搭建"></a>二、 <a href="https://blog.csdn.net/zmzdmx/article/details/108776666?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166719648416782427496026%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166719648416782427496026&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-108776666-null-null.142^v62^pc_rank_34_queryrelevant25,201^v3^control_1,213^v1^control&amp;utm_term=hive&amp;spm=1018.2226.3001.4187"><strong>Hive</strong></a>组件搭建</h1><div class="tip bell"><p>Hive：由Facebook开源用于解决海量结构化日志的数据统计。<br>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</p></div><div class="note default simple"><p><a href="https://www.yuque.com/attachments/yuque/0/2022/txt/33576317/1670333072537-0121e833-6fe6-4dfd-a9aa-bb50d0deb3b5.txt"><strong>Hive数据源</strong></a></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1 准备工作"></a>1 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1  解压并改名"></a>1.1  解压并改名</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-hive-2.3.4-bin.tar.gz -C /opt/</span><br><span class="line"><span class="built_in">mv</span> apache-hive-2.3.4-bin hive</span><br></pre></td></tr></table></figure><h2 id="2-配置Hive环境变量"><a href="#2-配置Hive环境变量" class="headerlink" title="2. 配置Hive环境变量"></a>2. 配置Hive环境变量</h2><h3 id="2-1-配置Hive环境变量"><a href="#2-1-配置Hive环境变量" class="headerlink" title="2.1 配置Hive环境变量"></a>2.1 配置Hive环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"></span><br><span class="line">修改内容：</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/opt/hive</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br><span class="line">如果报错，试着修改以下内容：</span><br><span class="line"><span class="built_in">export</span> HBASE_HOME =/opt/hive</span><br><span class="line"><span class="built_in">export</span> PATH = <span class="variable">$PATH</span>:<span class="variable">$HBASE_HOME</span>/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-解决日志jar包冲突"><a href="#2-3-解决日志jar包冲突" class="headerlink" title="2.3 解决日志jar包冲突"></a>2.3 解决日志jar包冲突</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.6.2.jar <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.6.2.bak</span><br></pre></td></tr></table></figure><h3 id="2-4-初始化元数据库"><a href="#2-4-初始化元数据库" class="headerlink" title="2.4 初始化元数据库"></a>2.4 初始化元数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 hive] bin/schematool -dbType derby -initSchema</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V</span></span><br><span class="line"><span class="string">at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:536)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.mapred.JobConf.setJarByClass(JobConf.java:554)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.mapred.JobConf.&lt;init&gt;(JobConf.java:448)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:4045)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.hive.conf.HiveConf.&lt;init&gt;(HiveConf.java:4008)</span></span><br><span class="line"><span class="string">at org.apache.hive.beeline.HiveSchemaTool.&lt;init&gt;(HiveSchemaTool.java:82)</span></span><br><span class="line"><span class="string">at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1117)</span></span><br><span class="line"><span class="string">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span></span><br><span class="line"><span class="string">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span></span><br><span class="line"><span class="string">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span></span><br><span class="line"><span class="string">at java.lang.reflect.Method.invoke(Method.java:498)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.util.RunJar.run(RunJar.java:323)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.util.RunJar.main(RunJar.java:236)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="若报错则尝试-2-5-初始化如果报错，就把hadoop的guava包替换到hive的guava包"><a href="#若报错则尝试-2-5-初始化如果报错，就把hadoop的guava包替换到hive的guava包" class="headerlink" title="(若报错则尝试)2.5 初始化如果报错，就把hadoop的guava包替换到hive的guava包"></a><font color=red>(若报错则尝试)</font>2.5 初始化如果报错，就把hadoop的<strong>guava包</strong>替换到hive的<strong>guava包</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf <span class="variable">$HIVE_HOME</span>/lib/guava-14.0.1.jar</span><br><span class="line"><span class="built_in">cp</span> <span class="variable">$HADOOP_HOME</span>/share/hadoop/common/lib/guava-27.0-jre.jar <span class="variable">$HIVE_HOME</span>/lib/</span><br></pre></td></tr></table></figure><h3 id="2-6-再次初始化元数据库-没有报错，可跳过"><a href="#2-6-再次初始化元数据库-没有报错，可跳过" class="headerlink" title="2.6 再次初始化元数据库(没有报错，可跳过)"></a>2.6 再次初始化元数据库<font color=red>(没有报错，可跳过)<font></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[huser@master hive] bin/schematool -dbType derby -initSchema</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Metastore connection URL: jdbc:derby:;databaseName=metastore_db;create=true</span></span><br><span class="line"><span class="string">Metastore Connection Driver : org.apache.derby.jdbc.EmbeddedDriver</span></span><br><span class="line"><span class="string">Metastore connection User: APP</span></span><br><span class="line"><span class="string">Starting metastore schema initialization to 2.3.0</span></span><br><span class="line"><span class="string">Initialization script hive-schema-2.3.0.derby.sql</span></span><br><span class="line"><span class="string">Initialization script completed</span></span><br><span class="line"><span class="string">schemaTool completed</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="2-7-验证时，先开集群"><a href="#2-7-验证时，先开集群" class="headerlink" title="2.7 验证时，先开集群"></a>2.7 验证时，先开<font color=red>集群</font></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 /] hive</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Logging initialized using configuration in jar:file:/opt/hive/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true</span></span><br><span class="line"><span class="string">Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><br><span class="line"><span class="string">hive&gt;</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="3-Hive存储命令行"><a href="#3-Hive存储命令行" class="headerlink" title="3. Hive存储命令行"></a>3. Hive存储命令行</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">测试：</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">show</span> <span class="string">databases;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">default</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.464</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">1</span> <span class="string">row(s)</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">create</span> <span class="string">database</span> <span class="string">test1;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.111</span> <span class="string">seconds</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">show</span> <span class="string">databases;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">default</span></span><br><span class="line"><span class="string">test1</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.026</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">2</span> <span class="string">row(s)</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">use</span> <span class="string">test1</span> <span class="string">;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.028</span> <span class="string">seconds</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">show</span> <span class="string">tables;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.029</span> <span class="string">seconds</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">create</span> <span class="string">table</span> <span class="string">students(</span></span><br><span class="line"><span class="string">id</span> <span class="string">bigint</span> <span class="string">comment</span> <span class="string">&#x27;学生id&#x27;</span><span class="string">,</span></span><br><span class="line"><span class="string">name</span> <span class="string">string</span> <span class="string">comment</span> <span class="string">&#x27;学生姓名&#x27;</span><span class="string">,</span></span><br><span class="line"><span class="string">age</span> <span class="string">int</span> <span class="string">comment</span> <span class="string">&#x27;学生年龄&#x27;</span><span class="string">,</span></span><br><span class="line"><span class="string">gender</span> <span class="string">string</span> <span class="string">comment</span> <span class="string">&#x27;学生性别&#x27;</span><span class="string">,</span></span><br><span class="line"><span class="string">clazz</span> <span class="string">string</span> <span class="string">comment</span> <span class="string">&#x27;学生班级&#x27;</span></span><br><span class="line"><span class="string">)comment</span> <span class="string">&#x27;学生信息表&#x27;</span></span><br><span class="line"><span class="string">row</span> <span class="string">format</span> <span class="string">delimited</span> <span class="string">fields</span> <span class="string">terminated</span> <span class="string">by</span> <span class="string">&#x27;,&#x27;</span><span class="string">;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.424</span> <span class="string">seconds</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">show</span> <span class="string">tables;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">students</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.025</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">1</span> <span class="string">row(s)</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">desc</span> <span class="string">students;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">id</span>                  <span class="string">bigint</span>              <span class="string">??id</span>                </span><br><span class="line"><span class="string">name</span>                <span class="string">string</span>              <span class="string">????</span>                </span><br><span class="line"><span class="string">age</span>                 <span class="string">int</span>                 <span class="string">????</span>                </span><br><span class="line"><span class="string">gender</span>              <span class="string">string</span>              <span class="string">????</span>                </span><br><span class="line"><span class="string">clazz</span>               <span class="string">string</span>              <span class="string">????</span>                </span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.077</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">5</span> <span class="string">row(s)</span></span><br><span class="line"></span><br><span class="line"><span class="string">exit;（退出命令）</span></span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>hive--hdfs--测试</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7bOC0.png" alt="hive--hdfs--测试" title="hive--hdfs--测试"></p><h2 id="4-解决报错"><a href="#4-解决报错" class="headerlink" title="4. 解决报错"></a>4. 解决报错</h2><h3 id="4-1-启动HIVE失败（jar包冲突）"><a href="#4-1-启动HIVE失败（jar包冲突）" class="headerlink" title="4.1 启动HIVE失败（jar包冲突）"></a>4.1 启动HIVE失败（jar包冲突）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">SLF4J: Found binding in [jar:file:/home/hdp/hive/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span></span><br><span class="line"><span class="string">SLF4J: Found binding in [jar:file:/home/hdp/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span></span><br><span class="line"><span class="string">SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span></span><br><span class="line"><span class="string">HiveSchemaTool:Parsing failed.  Reason: Missing required option: [-help print this message, -alterCatalog Alter a catalog, requires --catalogLocation and/or --catalogDescription parameter as well, -initSchemaTo Schema initialization to a version, -upgradeSchemaFrom Schema upgrade from a version, -moveDatabase Move a database between catalogs.  Argument is the database name. Requires --fromCatalog and --toCatalog parameters as well, -moveTable Move a table to a different database.  Argument is the table name. Requires --fromCatalog, --toCatalog, --fromDatabase, and --toDatabase  parameters as well., -initSchema Schema initialization, -createCatalog Create a catalog, requires --catalogLocation parameter as well, -upgradeSchema Schema upgrade, -info Show config and schema details, -validate Validate the database]</span></span><br><span class="line"><span class="string">usage: schemaTool…………………………………………</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">解决方案：</span><br><span class="line"><span class="comment"># cd /opt/hive/lib</span></span><br><span class="line"><span class="comment"># ls log4j-*</span></span><br><span class="line"><span class="built_in">rm</span> -rf log4j-slf4j-impl-2.17.1.jar</span><br></pre></td></tr></table></figure><h3 id="4-2-格式化失败"><a href="#4-2-格式化失败" class="headerlink" title="4.2 格式化失败"></a>4.2 格式化失败</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">java.lang.IncompatibleClassChangeError: Found class jline.Terminal, but interface was expected</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">解决方案：</span><br><span class="line"><span class="comment"># 把高等级的guava.jar文件添加：进入hive/lib</span></span><br><span class="line"><span class="built_in">cp</span> /opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar /opt/hive/lib</span><br></pre></td></tr></table></figure><h3 id="4-3-元数据出错"><a href="#4-3-元数据出错" class="headerlink" title="4.3 元数据出错"></a>4.3 元数据出错</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">FAILED: HiveException java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 元数据出错</span></span><br><span class="line">解决方案：</span><br><span class="line">./hive --service metastore &amp;</span><br><span class="line">然后重新启动  hive</span><br><span class="line"><span class="comment"># hive-site.xml出错</span></span><br></pre></td></tr></table></figure><h3 id="4-4-metastore-启动出错解决"><a href="#4-4-metastore-启动出错解决" class="headerlink" title="4.4 metastore 启动出错解决"></a>4.4 metastore 启动出错解决</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">MetaException(message:Version information not found in metastore.)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:84)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8661)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:8656)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:8926)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.hive.metastore.HiveMetaStore.main(HiveMetaStore.java:8843)</span></span><br><span class="line"><span class="string">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span></span><br><span class="line"><span class="string">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span></span><br><span class="line"><span class="string">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span></span><br><span class="line"><span class="string">at java.lang.reflect.Method.invoke(Method.java:498)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.util.RunJar.run(RunJar.java:221)</span></span><br><span class="line"><span class="string">at org.apache.hadoop.util.RunJar.main(RunJar.java:136)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># hive metastore进程 已经有启动过了，应该讲相关的进程kill 掉。</span></span><br><span class="line">ps -ef |grep  hive </span><br><span class="line"><span class="comment"># huser     11025   3408  0 12:57 pts/1    00:00:00 grep --color=auto hive</span></span><br><span class="line"><span class="comment"># 将hive 相关进程kill 掉。然后重新启动：</span></span><br><span class="line">./hive --service metastore</span><br><span class="line"><span class="comment"># 同理如果 运行 </span></span><br><span class="line">./hive  --service hiveserver2 </span><br><span class="line"><span class="comment"># 出现 0.0.0.0/0.0.0.0:10000端口的错误，也可能是已经存在了相关的进程，将其杀掉重新启动就能解决</span></span><br><span class="line">没有出错，则</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-10-31 12:41:16: Starting HiveServer2</span></span><br><span class="line"><span class="string">Hive Session ID = 5e7ae187-9f27-4a22-8a81-c05dcf390598</span></span><br><span class="line"><span class="string">Hive Session ID = 570423cb-4125-4c95-9f83-5c256e9583fe</span></span><br><span class="line"><span class="string">Hive Session ID = ff65d2e0-6ead-4850-9d0c-38270c3e35a2</span></span><br><span class="line"><span class="string">Hive Session ID = 5cd156e1-3b30-4ce6-8c64-b00ef3ae7457</span></span><br><span class="line"><span class="string">..............</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 另外就是hive-site.xml的报错</span></span><br><span class="line">添加：</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;datanucleus.metadata.validate&lt;/name&gt;</span><br><span class="line">&lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;</span><br><span class="line">&lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;&lt;property&gt;</span><br><span class="line">&lt;name&gt;datanucleus.schema.autoCreateAll&lt;/name&gt;</span><br><span class="line">&lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;datanucleus.schema.autoCreateAll&lt;/name&gt;</span><br><span class="line">&lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"><span class="comment"># 最后提醒：在xml配置文件中，在标签之间不要有空格！！！因为读取xml文件时是按标签读取的</span></span><br></pre></td></tr></table></figure><h1 id="三-Hive元数据配置到MySQL"><a href="#三-Hive元数据配置到MySQL" class="headerlink" title="三. Hive元数据配置到MySQL"></a>三. Hive元数据配置到MySQL</h1><h2 id="1-拷贝数据库驱动"><a href="#1-拷贝数据库驱动" class="headerlink" title="1. 拷贝数据库驱动"></a>1. 拷贝数据库驱动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自行下载拷贝并上传</span></span><br><span class="line"><span class="built_in">cp</span> mysql-connector-java-5.1.48.jar /opt/hive/lib/</span><br></pre></td></tr></table></figure><h2 id="2-配置Metastore到MySQL，目录-opt-hive-conf"><a href="#2-配置Metastore到MySQL，目录-opt-hive-conf" class="headerlink" title="2. 配置Metastore到MySQL，目录/opt/hive/conf"></a>2. 配置<strong>Metastore</strong>到MySQL，<code>目录/opt/hive/conf</code></h2><h3 id="2-1-创建并配置hive-site-xml"><a href="#2-1-创建并配置hive-site-xml" class="headerlink" title="2.1 创建并配置hive-site.xml"></a>2.1 <strong>创建并配置hive-site.xml</strong></h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="comment">&lt;!-- jdbc连接的URL --&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://slave1:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="comment">&lt;!-- jdbc连接的Driver--&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"><span class="comment">&lt;!-- jdbc连接的username--&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  <span class="comment">&lt;!-- jdbc连接的password --&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="comment">&lt;!-- Hive默认在HDFS的工作目录 --&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  <span class="comment">&lt;!-- Hive 元数据存储版本的验证 --&gt;</span> </span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  <span class="comment">&lt;!--元数据存储授权--&gt;</span> </span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.schema.autoCreateAll<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="可跳过-2-2-配置日志文件位置-amp-打印当前库名mysql表头信息"><a href="#可跳过-2-2-配置日志文件位置-amp-打印当前库名mysql表头信息" class="headerlink" title="(可跳过)2.2 配置日志文件位置&amp;打印当前库名mysql表头信息"></a><font color=red>(可跳过)</font>2.2 配置日志文件位置&amp;打印当前库名mysql表头信息</h3><h4 id="2-2-1-防止直接修改出错，先将需要配置的文件复制一份再修改"><a href="#2-2-1-防止直接修改出错，先将需要配置的文件复制一份再修改" class="headerlink" title="2.2.1  #防止直接修改出错，先将需要配置的文件复制一份再修改"></a>2.2.1  #防止直接修改出错，先将需要配置的文件复制一份再修改</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /opt/hive/conf</span></span><br><span class="line"><span class="built_in">cp</span> hive-env.sh.template hive-env.sh</span><br><span class="line"><span class="built_in">cp</span> hive-log4j.properties.template hive-log4j.properties</span><br><span class="line"><span class="built_in">cp</span> hive-default.xml.template hive-default.xml</span><br></pre></td></tr></table></figure><h4 id="2-2-2-配置hive-env-sh"><a href="#2-2-2-配置hive-env-sh" class="headerlink" title="2.2.2 配置hive-env.sh"></a>2.2.2 <strong>配置hive-env.sh</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim hive-env.sh</span><br><span class="line">添加：</span><br><span class="line">HADOOP_HOME=/opt/hadoop</span><br><span class="line"><span class="built_in">export</span> HIVE_CONF_DIR=/opt/hive/conf</span><br><span class="line"><span class="built_in">export</span> HIVE_AUX_JARS_PATH=/opt/hive/lib</span><br></pre></td></tr></table></figure><h4 id="2-2-3-配置hive-log4j-properties"><a href="#2-2-3-配置hive-log4j-properties" class="headerlink" title="2.2.3 配置hive-log4j.properties"></a>2.2.3 <strong>配置hive-log4j.properties</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim hive-log4j.properties</span><br><span class="line">添加：</span><br><span class="line">hive.log.dir=/opt/hive/log</span><br></pre></td></tr></table></figure><h4 id="2-2-4-创建并配置hive-site-xml"><a href="#2-2-4-创建并配置hive-site-xml" class="headerlink" title="2.2.4 创建并配置hive-site.xml"></a>2.2.4 <strong>创建并配置hive-site.xml</strong></h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="comment">&lt;!-- jdbc连接的URL --&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://slave1:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="comment">&lt;!-- jdbc连接的Driver--&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"><span class="comment">&lt;!-- jdbc连接的username--&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  <span class="comment">&lt;!-- jdbc连接的password --&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="comment">&lt;!-- Hive默认在HDFS的工作目录 --&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="comment">&lt;!--</span></span></span><br><span class="line"><span class="comment"><span class="language-xml">  &lt;!-- Hive 元数据存储版本的验证 --&gt;</span> </span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  <span class="comment">&lt;!--元数据存储授权--&gt;</span> </span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.schema.autoCreateAll<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">--&gt;</span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h4 id="2-2-5-启动Hive"><a href="#2-2-5-启动Hive" class="headerlink" title="2.2.5 启动Hive"></a>2.2.5 启动Hive</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 hive] bin/hive</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Logging initialized using configuration in jar:file:/opt/hive/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true</span></span><br><span class="line"><span class="string">Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><br><span class="line"><span class="string">hive(default)&gt;</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="可跳过-2-3-配置信息位置-amp-优先级"><a href="#可跳过-2-3-配置信息位置-amp-优先级" class="headerlink" title="(可跳过)2.3 配置信息位置&amp;优先级"></a><font color=red>(可跳过)</font>2.3 配置信息位置&amp;优先级</h3><h4 id="2-3-1-查看当前所有的配置信息"><a href="#2-3-1-查看当前所有的配置信息" class="headerlink" title="2.3.1 查看当前所有的配置信息"></a>2.3.1 查看当前所有的配置信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="built_in">set</span>;</span><br></pre></td></tr></table></figure><h4 id="2-3-2-命令行参数方式"><a href="#2-3-2-命令行参数方式" class="headerlink" title="2.3.2 命令行参数方式"></a>2.3.2 命令行参数方式</h4><p>注意: 仅对本次hive启动有效<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 hive]$ bin/hive -hiveconf hive.cli.print.current.db=<span class="literal">false</span>;</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Logging initialized using configuration in jar:file:/opt/hive/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true</span></span><br><span class="line"><span class="string">Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><br><span class="line"><span class="string">hive&gt;</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">hive&gt; <span class="built_in">set</span> hive.cli.print.current.db=<span class="literal">true</span>;</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">hive(default)&gt;</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 查看参数设置</span></span><br><span class="line">hive(default)&gt; <span class="built_in">set</span> mapred.reduce.tasks;</span><br><span class="line"><span class="comment"># 在HQL中使用SET关键字设定参数</span></span><br><span class="line">hive(default)&gt; <span class="built_in">set</span> mapred.reduce.tasks=10;</span><br></pre></td></tr></table></figure></p><h3 id="2-4-登录MySQL"><a href="#2-4-登录MySQL" class="headerlink" title="2.4 登录MySQL"></a>2.4 登录MySQL</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p000000</span><br></pre></td></tr></table></figure><h3 id="2-5-新建Hive元数据库"><a href="#2-5-新建Hive元数据库" class="headerlink" title="2.5 新建Hive元数据库"></a>2.5 新建Hive元数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database metastore; </span><br><span class="line">mysql&gt; quit;</span><br></pre></td></tr></table></figure><h3 id="2-6-初始化Hive元数据库"><a href="#2-6-初始化Hive元数据库" class="headerlink" title="2.6 初始化Hive元数据库"></a>2.6 初始化Hive元数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">schematool -initSchema -dbType mysql -verbose</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">No rows affected (0.001 seconds)</span></span><br><span class="line"><span class="string">0: jdbc:mysql://slave1:3306/metastore&gt; !closeall</span></span><br><span class="line"><span class="string">Closing: 0: jdbc:mysql://slave1:3306/metastore?useSSL=false</span></span><br><span class="line"><span class="string">beeline&gt; </span></span><br><span class="line"><span class="string">beeline&gt; Initialization script completed</span></span><br><span class="line"><span class="string">schemaTool completed</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="3-再次启动hive"><a href="#3-再次启动hive" class="headerlink" title="3. 再次启动hive"></a>3. 再次启动hive</h2><h3 id="3-1-启动Hive"><a href="#3-1-启动Hive" class="headerlink" title="3.1 启动Hive"></a>3.1 启动Hive</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 hive]$ bin/hive</span><br></pre></td></tr></table></figure><h3 id="3-2-使用Hive"><a href="#3-2-使用Hive" class="headerlink" title="3.2 使用Hive"></a>3.2 使用Hive</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hive&gt;</span> <span class="string">show</span> <span class="string">databases;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">default</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.032</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">1</span> <span class="string">row(s)</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">create</span> <span class="string">table</span> <span class="string">ts(id</span> <span class="string">string);</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">1.062</span> <span class="string">seconds</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">select</span> <span class="string">*</span> <span class="string">from</span> <span class="string">ts;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.349</span> <span class="string">seconds</span></span><br><span class="line"><span class="comment"># 这里没有数据</span></span><br><span class="line"><span class="comment"># 所以创建文件数据并上传hdfs</span></span><br><span class="line">[<span class="string">huser@slave1</span> <span class="string">hive</span>]<span class="string">$</span> <span class="string">vim</span> <span class="string">id.txt</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">10086</span></span><br><span class="line"><span class="string">10083</span></span><br><span class="line"><span class="string">12183273</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">[<span class="string">huser@slave1</span> <span class="string">hive</span>]<span class="string">$</span> <span class="string">hadoop</span> <span class="string">fs</span> <span class="string">-put</span> <span class="string">id.txt</span> <span class="string">/user/hive/warehouse/ts</span></span><br><span class="line"><span class="number">2022-11-26 15:00:51</span><span class="string">,884</span> <span class="attr">INFO sasl.SaslDataTransferClient: SASL encryption trust check:</span> <span class="string">localHostTrusted</span> <span class="string">=</span> <span class="literal">false</span><span class="string">,</span> <span class="string">remoteHostTrusted</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">select</span> <span class="string">*</span> <span class="string">from</span> <span class="string">ts;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="number">10086</span></span><br><span class="line"><span class="number">10083</span></span><br><span class="line"><span class="number">12183273</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.621</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">3</span> <span class="string">row(s)</span></span><br></pre></td></tr></table></figure><h2 id="4-使用元数据服务的方式访问Hive"><a href="#4-使用元数据服务的方式访问Hive" class="headerlink" title="4. 使用元数据服务的方式访问Hive"></a>4. 使用元数据服务的方式访问Hive</h2><h3 id="4-1-连接存储元数据地址，需要修改hive-site-xml"><a href="#4-1-连接存储元数据地址，需要修改hive-site-xml" class="headerlink" title="4.1 连接存储元数据地址，需要修改hive-site.xml"></a>4.1 连接存储元数据地址，需要<strong>修改hive-site.xml</strong></h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定存储元数据要连接的地址 --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://slave1:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="4-2-启动Hive"><a href="#4-2-启动Hive" class="headerlink" title="4.2 启动Hive"></a>4.2 启动Hive</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 hive]$ bin/hive --service metastore</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-11-26 15:33:16: Starting Hive Metastore Server</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 注意：启动后窗口不能再操作，需打开一个新的shell窗口做别的操作</span></span><br><span class="line">[huser@slave1 hive]$ bin/hive</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Logging initialized using configuration in jar:file:/opt/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true</span></span><br><span class="line"><span class="string">Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><br><span class="line"><span class="string">Hive Session ID = 59776f1a-d2d0-48ca-afb7-2de366803efb</span></span><br><span class="line"><span class="string">hive&gt;</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="4-3-测试"><a href="#4-3-测试" class="headerlink" title="4.3 测试"></a>4.3 测试</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hive&gt;</span> <span class="string">show</span> <span class="string">databases;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">default</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.871</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">1</span> <span class="string">row(s)</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">show</span> <span class="string">tables;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">ts</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.126</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">1</span> <span class="string">row(s)</span></span><br><span class="line"><span class="string">hive&gt;</span> <span class="string">select</span> <span class="string">*</span> <span class="string">from</span> <span class="string">ts;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="number">10086</span></span><br><span class="line"><span class="number">10083</span></span><br><span class="line"><span class="number">12183273</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">4.242</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">3</span> <span class="string">row(s)</span></span><br></pre></td></tr></table></figure><h2 id="5-使用JDBC方式访问Hive"><a href="#5-使用JDBC方式访问Hive" class="headerlink" title="5. 使用JDBC方式访问Hive"></a>5. 使用JDBC方式访问Hive</h2><h3 id="5-1-在hive-site-xml文件中添加如下配置信息"><a href="#5-1-在hive-site-xml文件中添加如下配置信息" class="headerlink" title="5.1 在hive-site.xml文件中添加如下配置信息"></a>5.1 在<code>hive-site.xml文件</code>中添加如下配置信息</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定hiveserver2连接的host --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>slave1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">&lt;!-- 指定hiveserver2连接的端口号 --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="5-2-启动metastore"><a href="#5-2-启动metastore" class="headerlink" title="5.2 启动metastore"></a>5.2 <strong>启动metastore</strong></h3><p>注意：启动后窗口不能再操作，需打开一个新的shell窗口做别的操作<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 hive]$ bin/hive --service metastore</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-11-26 15:33:16: Starting Hive Metastore Server</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p><h3 id="5-2-启动hiveserver2"><a href="#5-2-启动hiveserver2" class="headerlink" title="5.2 启动hiveserver2"></a>5.2 <strong>启动hiveserver2</strong></h3><p>注意：启动后窗口不能再操作，需打开一个新的shell窗口做别的操作<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 hive]$ bin/hive --service hiveserver2</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">which: no hbase in (/opt/hbase/bin:/opt/hive/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/usr/java/jdk1.8.0_341-amd64/bin:/opt/hadoop/bin:/opt/hadoop/sbin:/opt/zookeeper/bin:/opt/sqoop/bin:/opt/bin:/opt/maven/bin:/opt/maven/bin:/opt/flume/bin:/opt/kafka/bin:/opt/kafka/bin:/opt/kafka/bin:/bin:/home/huser/.local/bin:/home/huser/bin)</span></span><br><span class="line"><span class="string">2022-11-26 17:29:52: Starting HiveServer2</span></span><br><span class="line"><span class="string">Hive Session ID = 04c9025c-ba79-42de-8f2a-96de660072c8</span></span><br><span class="line"><span class="string">Hive Session ID = 6936bbd6-c52e-4523-bfea-016a7b62f0fc</span></span><br><span class="line"><span class="string">Hive Session ID = b16222cb-6a9e-4866-b08c-9f11de650f6a</span></span><br><span class="line"><span class="string">Hive Session ID = a36d5961-078f-4a70-9649-8113e32dc1d1</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p><h3 id="5-3-启动beeline客户端"><a href="#5-3-启动beeline客户端" class="headerlink" title="5.3 启动beeline客户端"></a>5.3 <strong>启动beeline客户端</strong></h3><p>注意：1.启动后窗口不能再操作，需打开一个新的shell窗口做别的操作</p><ol><li>等hiveserver2服务完全开启, 否则直接报拒绝连接<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 hive]$ bin/beeline -u jdbc:hive2://slave1:10000 -n huser</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;Connecting to jdbc:hive2://slave1:10000</span></span><br><span class="line"><span class="string">Connected to: Apache Hive (version 3.1.2)</span></span><br><span class="line"><span class="string">Driver: Hive JDBC (version 3.1.2)</span></span><br><span class="line"><span class="string">Transaction isolation: TRANSACTION_REPEATABLE_READ</span></span><br><span class="line"><span class="string">Beeline version 3.1.2 by Apache Hive</span></span><br><span class="line"><span class="string">0: jdbc:hive2://slave1:10000&gt;</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="5-4-测试"><a href="#5-4-测试" class="headerlink" title="5.4 测试"></a>5.4 测试</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">0:</span> <span class="string">jdbc:hive2://slave1:10000&gt;</span> <span class="string">show</span> <span class="string">databases;</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Compiling</span> <span class="string">command(queryId=huser_20221126171309_51ccbfac-4e21-44e5-a036-9716d3631756):</span> <span class="string">show</span> <span class="string">databases</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Concurrency</span> <span class="string">mode</span> <span class="string">is</span> <span class="string">disabled,</span> <span class="string">not</span> <span class="string">creating</span> <span class="string">a</span> <span class="string">lock</span> <span class="string">manager</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Semantic</span> <span class="string">Analysis</span> <span class="string">Completed</span> <span class="string">(retrial</span> <span class="string">=</span> <span class="literal">false</span><span class="string">)</span></span><br><span class="line"><span class="attr">INFO  : Returning Hive schema:</span> <span class="string">Schema(fieldSchemas:[FieldSchema(name:database_name,</span> <span class="string">type:string,</span> <span class="string">comment:from</span> <span class="string">deserializer)],</span> <span class="string">properties:null)</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Completed</span> <span class="string">compiling</span> <span class="string">command(queryId=huser_20221126171309_51ccbfac-4e21-44e5-a036-9716d3631756);</span> <span class="attr">Time taken:</span> <span class="number">0.383</span> <span class="string">seconds</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Concurrency</span> <span class="string">mode</span> <span class="string">is</span> <span class="string">disabled,</span> <span class="string">not</span> <span class="string">creating</span> <span class="string">a</span> <span class="string">lock</span> <span class="string">manager</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Executing</span> <span class="string">command(queryId=huser_20221126171309_51ccbfac-4e21-44e5-a036-9716d3631756):</span> <span class="string">show</span> <span class="string">databases</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Starting</span> <span class="string">task</span> [<span class="string">Stage-0:DDL</span>] <span class="string">in</span> <span class="string">serial</span> <span class="string">mode</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Completed</span> <span class="string">executing</span> <span class="string">command(queryId=huser_20221126171309_51ccbfac-4e21-44e5-a036-9716d3631756);</span> <span class="attr">Time taken:</span> <span class="number">0.093</span> <span class="string">seconds</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">OK</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Concurrency</span> <span class="string">mode</span> <span class="string">is</span> <span class="string">disabled,</span> <span class="string">not</span> <span class="string">creating</span> <span class="string">a</span> <span class="string">lock</span> <span class="string">manager</span></span><br><span class="line"><span class="string">+----------------+</span></span><br><span class="line"><span class="string">|</span> <span class="string">database_name</span>  <span class="string">|</span></span><br><span class="line"><span class="string">+----------------+</span></span><br><span class="line"><span class="string">|</span> <span class="string">default</span>        <span class="string">|</span></span><br><span class="line"><span class="string">+----------------+</span></span><br><span class="line"><span class="number">1</span> <span class="string">row</span> <span class="string">selected</span> <span class="string">(0.914</span> <span class="string">seconds)</span></span><br><span class="line"><span class="attr">0:</span> <span class="string">jdbc:hive2://slave1:10000&gt;</span> <span class="string">show</span> <span class="string">tables;</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Compiling</span> <span class="string">command(queryId=huser_20221126171531_76ed2baf-f3af-4809-8b83-e34bf6b223d1):</span> <span class="string">show</span> <span class="string">tables</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Concurrency</span> <span class="string">mode</span> <span class="string">is</span> <span class="string">disabled,</span> <span class="string">not</span> <span class="string">creating</span> <span class="string">a</span> <span class="string">lock</span> <span class="string">manager</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Semantic</span> <span class="string">Analysis</span> <span class="string">Completed</span> <span class="string">(retrial</span> <span class="string">=</span> <span class="literal">false</span><span class="string">)</span></span><br><span class="line"><span class="attr">INFO  : Returning Hive schema:</span> <span class="string">Schema(fieldSchemas:[FieldSchema(name:tab_name,</span> <span class="string">type:string,</span> <span class="string">comment:from</span> <span class="string">deserializer)],</span> <span class="string">properties:null)</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Completed</span> <span class="string">compiling</span> <span class="string">command(queryId=huser_20221126171531_76ed2baf-f3af-4809-8b83-e34bf6b223d1);</span> <span class="attr">Time taken:</span> <span class="number">0.172</span> <span class="string">seconds</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Concurrency</span> <span class="string">mode</span> <span class="string">is</span> <span class="string">disabled,</span> <span class="string">not</span> <span class="string">creating</span> <span class="string">a</span> <span class="string">lock</span> <span class="string">manager</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Executing</span> <span class="string">command(queryId=huser_20221126171531_76ed2baf-f3af-4809-8b83-e34bf6b223d1):</span> <span class="string">show</span> <span class="string">tables</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Starting</span> <span class="string">task</span> [<span class="string">Stage-0:DDL</span>] <span class="string">in</span> <span class="string">serial</span> <span class="string">mode</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Completed</span> <span class="string">executing</span> <span class="string">command(queryId=huser_20221126171531_76ed2baf-f3af-4809-8b83-e34bf6b223d1);</span> <span class="attr">Time taken:</span> <span class="number">0.053</span> <span class="string">seconds</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">OK</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Concurrency</span> <span class="string">mode</span> <span class="string">is</span> <span class="string">disabled,</span> <span class="string">not</span> <span class="string">creating</span> <span class="string">a</span> <span class="string">lock</span> <span class="string">manager</span></span><br><span class="line"><span class="string">+-----------+</span></span><br><span class="line"><span class="string">|</span> <span class="string">tab_name</span>  <span class="string">|</span></span><br><span class="line"><span class="string">+-----------+</span></span><br><span class="line"><span class="string">|</span> <span class="string">ts</span>        <span class="string">|</span></span><br><span class="line"><span class="string">+-----------+</span></span><br><span class="line"><span class="number">1</span> <span class="string">row</span> <span class="string">selected</span> <span class="string">(0.322</span> <span class="string">seconds)</span></span><br><span class="line"><span class="attr">0:</span> <span class="string">jdbc:hive2://slave1:10000&gt;</span> <span class="string">select</span> <span class="string">*</span> <span class="string">from</span> <span class="string">ts;</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Compiling</span> <span class="string">command(queryId=huser_20221126171609_87fc3173-f1a7-42cb-969c-302e73df63b3):</span> <span class="string">select</span> <span class="string">*</span> <span class="string">from</span> <span class="string">ts</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Concurrency</span> <span class="string">mode</span> <span class="string">is</span> <span class="string">disabled,</span> <span class="string">not</span> <span class="string">creating</span> <span class="string">a</span> <span class="string">lock</span> <span class="string">manager</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Semantic</span> <span class="string">Analysis</span> <span class="string">Completed</span> <span class="string">(retrial</span> <span class="string">=</span> <span class="literal">false</span><span class="string">)</span></span><br><span class="line"><span class="attr">INFO  : Returning Hive schema:</span> <span class="string">Schema(fieldSchemas:[FieldSchema(name:ts.id,</span> <span class="string">type:string,</span> <span class="string">comment:null)],</span> <span class="string">properties:null)</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Completed</span> <span class="string">compiling</span> <span class="string">command(queryId=huser_20221126171609_87fc3173-f1a7-42cb-969c-302e73df63b3);</span> <span class="attr">Time taken:</span> <span class="number">3.368</span> <span class="string">seconds</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Concurrency</span> <span class="string">mode</span> <span class="string">is</span> <span class="string">disabled,</span> <span class="string">not</span> <span class="string">creating</span> <span class="string">a</span> <span class="string">lock</span> <span class="string">manager</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Executing</span> <span class="string">command(queryId=huser_20221126171609_87fc3173-f1a7-42cb-969c-302e73df63b3):</span> <span class="string">select</span> <span class="string">*</span> <span class="string">from</span> <span class="string">ts</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Completed</span> <span class="string">executing</span> <span class="string">command(queryId=huser_20221126171609_87fc3173-f1a7-42cb-969c-302e73df63b3);</span> <span class="attr">Time taken:</span> <span class="number">0.032</span> <span class="string">seconds</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">OK</span></span><br><span class="line"><span class="attr">INFO  :</span> <span class="string">Concurrency</span> <span class="string">mode</span> <span class="string">is</span> <span class="string">disabled,</span> <span class="string">not</span> <span class="string">creating</span> <span class="string">a</span> <span class="string">lock</span> <span class="string">manager</span></span><br><span class="line"><span class="string">+-----------+</span></span><br><span class="line"><span class="string">|</span>   <span class="string">ts.id</span>   <span class="string">|</span></span><br><span class="line"><span class="string">+-----------+</span></span><br><span class="line"><span class="string">|</span> <span class="number">10086</span>     <span class="string">|</span></span><br><span class="line"><span class="string">|</span> <span class="number">10083</span>     <span class="string">|</span></span><br><span class="line"><span class="string">|</span> <span class="number">12183273</span>  <span class="string">|</span></span><br><span class="line"><span class="string">+-----------+</span></span><br><span class="line"><span class="number">3</span> <span class="string">rows</span> <span class="string">selected</span> <span class="string">(4.477</span> <span class="string">seconds)</span></span><br></pre></td></tr></table></figure><h3 id="5-5-拒接连接报错"><a href="#5-5-拒接连接报错" class="headerlink" title="5.5 拒接连接报错"></a>5.5 拒接连接报错</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Connecting to jdbc:hive2://slave1:10000</span></span><br><span class="line"><span class="string">22/11/26 17:29:24 [main]: WARN jdbc.HiveConnection: Failed to connect to slave1:10000</span></span><br><span class="line"><span class="string">Could not open connection to the HS2 server. Please check the server URI and if the URI is correct, then ask the administrator to check the server status.</span></span><br><span class="line"><span class="string">Error: Could not open client transport with JDBC Uri: jdbc:hive2://slave1:10000: java.net.ConnectException: 拒绝连接 (Connection refused) (state=08S01,code=0)</span></span><br><span class="line"><span class="string">Beeline version 3.1.2 by Apache Hive</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 解决</span></span><br><span class="line">1. 等hiveserver2服务完全开启</span><br><span class="line">2. 修改hadoop目录下的hdfs-site.xml和core-site.xml的文件</span><br></pre></td></tr></table></figure><h3 id="5-6-解决方案"><a href="#5-6-解决方案" class="headerlink" title="5.6 解决方案:"></a>5.6 解决方案:</h3><strong>注意：以下配置文件里出现的“huser”请换成您自己的用户名！！！</strong><h4 id="5-6-1-在hdfs-site-xml文件中添加如下内容（路径：-HADOOP-HOME-etc-hadoop）"><a href="#5-6-1-在hdfs-site-xml文件中添加如下内容（路径：-HADOOP-HOME-etc-hadoop）" class="headerlink" title="5.6.1 在hdfs-site.xml文件中添加如下内容（路径：$HADOOP_HOME/etc/hadoop）"></a>5.6.1 在<code>hdfs-site.xml文件</code>中添加如下内容<code>（路径：$HADOOP_HOME/etc/hadoop）</code></h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h4 id="5-6-2-在core-site-xml文件中添加如下内容："><a href="#5-6-2-在core-site-xml文件中添加如下内容：" class="headerlink" title="5.6.2 在core-site.xml文件中添加如下内容："></a>5.6.2 在<code>core-site.xml文件</code>中添加如下内容：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.huser.hosts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;slave1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.huser.groups&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;10000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><strong> 提示：配置的时候一定要注意细节哦，不然容易启动报错哦！！！其次记得分发改了的文件，并且重新启动相应的集群哦！！！</strong></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;tip error&quot;&gt;&lt;p&gt;前提准备：&lt;/p&gt;
&lt;/div&gt;
&lt;div calss=&#39;anzhiyu-tag-link&#39;&gt;&lt;a class=&quot;tag-Link&quot; target=&quot;_blank&quot; href=&quot;/%5B%E4%B8%80%E3%80%81%E9</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
</feed>
