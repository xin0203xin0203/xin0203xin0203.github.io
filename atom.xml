<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>知安</title>
  
  <subtitle>要么庸俗，要么孤独</subtitle>
  <link href="https://xin0203xin0203.github.io/atom.xml" rel="self"/>
  
  <link href="https://xin0203xin0203.github.io/"/>
  <updated>2024-12-25T21:14:01.000Z</updated>
  <id>https://xin0203xin0203.github.io/</id>
  
  <author>
    <name>知安</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习IRIS（鸢尾花数据分析）</title>
    <link href="https://xin0203xin0203.github.io/posts/188aa76e.html"/>
    <id>https://xin0203xin0203.github.io/posts/188aa76e.html</id>
    <published>2023-12-25T16:25:13.375Z</published>
    <updated>2024-12-25T21:14:01.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="鸢尾花数据分析"><a href="#鸢尾花数据分析" class="headerlink" title="鸢尾花数据分析"></a>鸢尾花数据分析</h2><details class="folding-tag" cyan open><summary> 学习大纲 </summary>              <div class='content'>              <ul><li><strong>展示数据处理过程</strong><ul><li>数据加载</li><li>数据探查</li><li>问题类型</li><li>算法选择</li><li>结果预测</li></ul></li><li><strong>熟悉并初步使用sklearn模块</strong><ul><li>模块导入</li><li>模块函数的调用</li><li>分类算法选择</li><li>split方法</li><li>fit方法</li><li>predict方法</li><li>给出预测结果</li><li>准确度检验</li></ul></li><li><strong>忽略的地方</strong><ul><li>直方图、小提琴图的具体含义</li><li>视频中提及的预测算法（SVM、LR、KNN、DT等）详细解释</li></ul></li></ul>              </div>            </details><div class="btns rounded grid5">            <a class="button no-text-decoration" href='https://pan.baidu.com/s/1r5iTls_LP-Yp-IPKhdpPZA?pwd=r1kf' title='下载源码(r1kf)'><i class='anzhiyufont anzhiyu-icon-bolt'></i>下载源码(r1kf)</a><a class="button no-text-decoration" href='https://www.yuque.com/attachments/yuque/0/2023/py/33576317/1703523713564-a5e5d938-4512-4fc4-927f-e5d3fafa516e.py' title='查看文档'><i class='anzhiyufont anzhiyu-icon-book'></i>查看文档</a><a class="button no-text-decoration" href='https://www.yuque.com/attachments/yuque/0/2023/csv/33576317/1703523673357-760a19e0-3525-4883-96a8-ad793be7e1b2.csv' title='下载数据源'><i class='anzhiyufont anzhiyu-icon-square-poll-vertical'></i>下载数据源</a><a class="button no-text-decoration" href='https://www.bilibili.com/video/BV1Pi4y1j743/?spm_id_from=333.1007.tianma.1-1-1.click' title='观看视频'><i class='anzhiyufont anzhiyu-icon-bilibili'></i>观看视频</a>          </div><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.<span class="property">pyplot</span> <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">np.<span class="title function_">sum</span>([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>6</p></div><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 文件路径 = <span class="attr">E</span>:\jupter_book\<span class="variable constant_">IRIS</span>/<span class="title class_">Iris</span>.<span class="property">csv</span></span><br><span class="line">iris = pd.<span class="title function_">read_csv</span>(<span class="string">&#x27;E:\jupter_book\IRIS/Iris.csv&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html"><span class='p blue'>pandas.DataFrame.head</span></a><br>查看前n行数据，默认n=5</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iris.<span class="title function_">head</span>()</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7y8Sc.png"/></div></div></div><p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html"><span class='p blue'>pandas.DataFrame.info</span></a><br>打印数据的简短摘要：索引值、列名、非空值统计、数据类型和内存使用情况<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iris.<span class="title function_">info</span>()</span><br></pre></td></tr></table></figure><br><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7y6Zh.png"/></div></div></div></p><p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"><span class='p blue'>pandas.DataFrame.drop</span></a><br>删除不必要的行or列。通过传入行or列名，axis=0（默认）删除行，axis=1删除列；inplace=False（默认）不在原数据修改返回新的df，inplace=True在原数据上修改<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iris.<span class="title function_">drop</span>(<span class="string">&#x27;Id&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="title class_">True</span>)</span><br></pre></td></tr></table></figure></p><h3 id="Iris数据探查"><a href="#Iris数据探查" class="headerlink" title="Iris数据探查"></a>Iris数据探查</h3><ul><li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"><span class='p blue'>pandas.DataFrame.plot.scatter</span></a></li><li>下面ax参数用来指定在那个画板上画图。ax=fig表示还是用第一个fig画板继续画图</li><li>python matplotlib.pyplot.gca() 函数的作用</li><li><a href="https://matplotlib.org/3.3.2/api/_as_gen/matplotlib.pyplot.gcf.html"><span class='p blue'>matplotlib.pyplot.gcf</span></a> — get current figure</li><li><a href="https://zhuanlan.zhihu.com/p/108570910"><span class='p blue'>Matplotlib画图中fig</span></a></li><li><a href="https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.figure.Figure.html"><span class='p blue'>matplotlib.figure.Figure</span></a> — fig的所有操作<br><br></li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fig = iris[iris.<span class="property">Species</span>==<span class="string">&#x27;Iris-setosa&#x27;</span>].<span class="title function_">plot</span>(kind=<span class="string">&#x27;scatter&#x27;</span>,x=<span class="string">&#x27;SepalLengthCm&#x27;</span>,y=<span class="string">&#x27;SepalWidthCm&#x27;</span>,color=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;Setosa&#x27;</span>)</span><br><span class="line">iris[iris.<span class="property">Species</span>==<span class="string">&#x27;Iris-versicolor&#x27;</span>].<span class="title function_">plot</span>(kind=<span class="string">&#x27;scatter&#x27;</span>,x=<span class="string">&#x27;SepalLengthCm&#x27;</span>,y=<span class="string">&#x27;SepalWidthCm&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>,ax=fig)</span><br><span class="line">iris[iris.<span class="property">Species</span>==<span class="string">&#x27;Iris-virginica&#x27;</span>].<span class="title function_">plot</span>(kind=<span class="string">&#x27;scatter&#x27;</span>,x=<span class="string">&#x27;SepalLengthCm&#x27;</span>,y=<span class="string">&#x27;SepalWidthCm&#x27;</span>,color=<span class="string">&#x27;green&#x27;</span>, label=<span class="string">&#x27;virginica&#x27;</span>, ax=fig)</span><br><span class="line">fig.<span class="title function_">set_xlabel</span>(<span class="string">&quot;Sepal Length&quot;</span>)</span><br><span class="line">fig.<span class="title function_">set_ylabel</span>(<span class="string">&quot;Sepal Width&quot;</span>)</span><br><span class="line">fig.<span class="title function_">set_title</span>(<span class="string">&quot;Sepal Length VS Width&quot;</span>)</span><br><span class="line">fig=plt.<span class="title function_">gcf</span>()</span><br><span class="line">fig.<span class="title function_">set_size_inches</span>(<span class="number">10</span>,<span class="number">6</span>)</span><br><span class="line">plt.<span class="title function_">show</span>()</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7yUyr.png"/></div></div></div><p>上面的图片给出了花萼长度和宽度的关系。下面来看一下花瓣的长度和宽度的关系。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fig = iris[iris.<span class="property">Species</span>==<span class="string">&#x27;Iris-setosa&#x27;</span>].<span class="property">plot</span>.<span class="title function_">scatter</span>(x=<span class="string">&#x27;PetalLengthCm&#x27;</span>,y=<span class="string">&#x27;PetalWidthCm&#x27;</span>,color=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;Setosa&#x27;</span>)</span><br><span class="line">iris[iris.<span class="property">Species</span>==<span class="string">&#x27;Iris-versicolor&#x27;</span>].<span class="property">plot</span>.<span class="title function_">scatter</span>(x=<span class="string">&#x27;PetalLengthCm&#x27;</span>,y=<span class="string">&#x27;PetalWidthCm&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>,ax=fig)</span><br><span class="line">iris[iris.<span class="property">Species</span>==<span class="string">&#x27;Iris-virginica&#x27;</span>].<span class="property">plot</span>.<span class="title function_">scatter</span>(x=<span class="string">&#x27;PetalLengthCm&#x27;</span>,y=<span class="string">&#x27;PetalWidthCm&#x27;</span>,color=<span class="string">&#x27;green&#x27;</span>, label=<span class="string">&#x27;virginica&#x27;</span>, ax=fig)</span><br><span class="line">fig.<span class="title function_">set_xlabel</span>(<span class="string">&quot;Petal Length&quot;</span>)</span><br><span class="line">fig.<span class="title function_">set_ylabel</span>(<span class="string">&quot;Petal Width&quot;</span>)</span><br><span class="line">fig.<span class="title function_">set_title</span>(<span class="string">&quot; Petal Length VS Width&quot;</span>)</span><br><span class="line">fig=plt.<span class="title function_">gcf</span>()</span><br><span class="line">fig.<span class="title function_">set_size_inches</span>(<span class="number">10</span>,<span class="number">6</span>)</span><br><span class="line">plt.<span class="title function_">show</span>()</span><br></pre></td></tr></table></figure><br><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7yKpq.png"/></div></div></div><br>正如上图所示，花瓣的特征比花萼更能区分鸢尾花不同的种类。这就暗示着花瓣比花萼能做出更好的预测。我们随后检验这个想法。</p><h3 id="现在我们看看Iris长度和宽度的分布"><a href="#现在我们看看Iris长度和宽度的分布" class="headerlink" title="现在我们看看Iris长度和宽度的分布"></a>现在我们看看Iris长度和宽度的分布</h3><p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html#pandas-dataframe-hist"><span class='p blue'>pandas.DataFrame.hist</span></a> 画出DataFrame中每一个列的直方图，默认10个bin<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iris.<span class="title function_">hist</span>(edgecolor=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">1.2</span>)</span><br><span class="line">fig=plt.<span class="title function_">gcf</span>()</span><br><span class="line">fig.<span class="title function_">set_size_inches</span>(<span class="number">12</span>,<span class="number">6</span>)</span><br><span class="line">plt.<span class="title function_">show</span>()</span><br></pre></td></tr></table></figure><br><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7yVVK.png"/></div></div></div></p><h3 id="现在我们看看长度与宽度跟种类的关系"><a href="#现在我们看看长度与宽度跟种类的关系" class="headerlink" title="现在我们看看长度与宽度跟种类的关系"></a>现在我们看看长度与宽度跟种类的关系</h3><ul><li><a href="https://seaborn.pydata.org/generated/seaborn.violinplot.html"><span class='p blue'>seaborn.violinplot</span></a> — 绘制小提琴图</li><li>小提琴图 是 箱型图 和 核密度图的结合</li><li>小提琴图展示了数据随种类的长度和密度。越窄的部分说明数据密度较低，越宽的部分说明数据密度高。</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.<span class="title function_">figure</span>(figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line">plt.<span class="title function_">subplot</span>(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">sns.<span class="title function_">violinplot</span>(x=<span class="string">&#x27;Species&#x27;</span>,y=<span class="string">&#x27;PetalLengthCm&#x27;</span>,data=iris)</span><br><span class="line">plt.<span class="title function_">subplot</span>(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">sns.<span class="title function_">violinplot</span>(x=<span class="string">&#x27;Species&#x27;</span>,y=<span class="string">&#x27;PetalWidthCm&#x27;</span>,data=iris)</span><br><span class="line">plt.<span class="title function_">subplot</span>(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">sns.<span class="title function_">violinplot</span>(x=<span class="string">&#x27;Species&#x27;</span>,y=<span class="string">&#x27;SepalLengthCm&#x27;</span>,data=iris)</span><br><span class="line">plt.<span class="title function_">subplot</span>(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">sns.<span class="title function_">violinplot</span>(x=<span class="string">&#x27;Species&#x27;</span>,y=<span class="string">&#x27;SepalWidthCm&#x27;</span>,data=iris)</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7yrd1.png"/></div></div></div><h3 id="鉴于这个问题是分类问题，所以使用分类算法来建立模型"><a href="#鉴于这个问题是分类问题，所以使用分类算法来建立模型" class="headerlink" title="鉴于这个问题是分类问题，所以使用分类算法来建立模型"></a>鉴于这个问题是分类问题，所以使用分类算法来建立模型</h3><ul><li>分类：样本属于一个or更多个类别，从已经分类号的数据中预测未分类的数据</li><li>回归：如果期望的输出结果是一个or多个连续值，那么就称为回归。例如，根据鱼的体重和年龄预测其长度。<br>在开始之前，我们需要了解一下ML相关符号。</li><li>属性：实例的属性用于确定其分类。在这个问题中，花萼or花瓣的长度和宽度就是属性，也称之为特征。</li><li>目标变量：在机器学习中是预期的输出值。在这个问题中，3种分类就是目标变量。</li><li><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model"><span class='p blue'>sklearn.linear_model</span></a> — 逻辑回归算法</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"><span class='p blue'>sklearn.model_selection.train_test_split</span></a> — 将数据集随机分成训练集和测试集</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"><span class='p blue'>sklearn.neighbors.KNeighborsClassifier</span></a> — K邻近算法</li><li><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm"><span class='p blue'>sklearn.svm</span></a> — 支持向量机算法</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score"><span class='p blue'>sklearn.metrics.accuracy_score</span></a> — 检查模型的准确性</li><li><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm"><span class='p blue'>sklearn.tree.DecisionTreeClassifier</span></a> — 决策树算法</li></ul><h2 id="熟悉并初步使用sklearn模块"><a href="#熟悉并初步使用sklearn模块" class="headerlink" title="熟悉并初步使用sklearn模块"></a>熟悉并初步使用sklearn模块</h2><h3 id="模块导入"><a href="#模块导入" class="headerlink" title="模块导入"></a>模块导入</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.<span class="property">linear_model</span> <span class="keyword">import</span> <span class="title class_">LogisticRegression</span></span><br><span class="line"><span class="keyword">from</span> sklearn.<span class="property">model_selection</span> <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.<span class="property">neighbors</span> <span class="keyword">import</span> <span class="title class_">KNeighborsClassifier</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.<span class="property">tree</span> <span class="keyword">import</span> <span class="title class_">DecisionTreeClassifier</span></span><br></pre></td></tr></table></figure><p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html"><span class='p blue'>pandas.DataFrame.shape</span></a> — 返回DataFrame数据形状</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iris.<span class="property">shape</span></span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>(150, 5)</p></div><p>现在，当我们训练任何算法时，特征的数量及其相关性都起着重要的作用。如果存在特征并且许多特征高度相关，那么训练具有所有特征的算法将降低准确性。因此要谨慎选取特征。虽然这个数据集特征较少，我们仍要查看其相关性。</p><ul><li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html"><span class='p blue'>pandas.DataFrame.corr</span></a> — 计算相关系数</li><li><a href="https://seaborn.pydata.org/generated/seaborn.heatmap.html"><span class='p blue'>seaborn.heatmap</span></a> — 热力图</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.<span class="title function_">figure</span>(figsize=(<span class="number">7</span>,<span class="number">4</span>)) </span><br><span class="line">sns.<span class="title function_">heatmap</span>(iris.<span class="title function_">corr</span>(),annot=<span class="title class_">True</span>,cmap=<span class="string">&#x27;cubehelix_r&#x27;</span>)</span><br><span class="line">plt.<span class="title function_">show</span>()</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7ykmT.png"/></div></div></div><h3 id="观察"><a href="#观察" class="headerlink" title="观察"></a>观察</h3><p>花萼的长度和宽度具有非相关特征，花瓣的长度和宽度具有高相关性。<br>首先，我们使用所有的特征来训练算法并检验其正确性。<br>然后，我们将使用1个花瓣特征和1个萼片特征来检查算法的准确性，因为我们仅使用了2个不相关的特征。因此，我们可以在数据集中找到方差，这可能有助于提高准确性。我们稍后会检查。</p><h3 id="训练算法步骤"><a href="#训练算法步骤" class="headerlink" title="训练算法步骤"></a>训练算法步骤</h3><ul><li>将数据集划分为训练集和测试集。一般训练集的数据占比要高，这样有助于提高算法模型精度。</li><li>基于问题选择你认为可靠的算法（分类or回归）。</li><li>将训练集输入到算法里面进行算法训练。使用 .fit() 方法实现。</li><li>将测试集输入到已训练好的算法中，给出对应的预测值。使用 .predict() 方法。</li><li>比较预测值与真实值，给出算法准确度。<h3 id="数据集划分为训练集和测试集"><a href="#数据集划分为训练集和测试集" class="headerlink" title="数据集划分为训练集和测试集"></a>数据集划分为训练集和测试集</h3></li><li><p>test_size = 0.3 测试集数据占比为30%</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train, test = <span class="title function_">train_test_split</span>(iris, test_size = <span class="number">0.3</span>)</span><br><span class="line"><span class="title function_">print</span>(train.<span class="property">shape</span>)</span><br><span class="line"><span class="title function_">print</span>(test.<span class="property">shape</span>)</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>(105, 5)<br>(45, 5)</p></div></li><li><p>获取训练集X的特征：[‘SepalLengthCm’,’SepalWidthCm’,’PetalLengthCm’,’PetalWidthCm’]</p></li><li>训练集Y的实际分类</li><li>测试集X的特征</li><li>测试集Y实际分类</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_X = train[[<span class="string">&#x27;SepalLengthCm&#x27;</span>,<span class="string">&#x27;SepalWidthCm&#x27;</span>,<span class="string">&#x27;PetalLengthCm&#x27;</span>,<span class="string">&#x27;PetalWidthCm&#x27;</span>]]</span><br><span class="line">train_y=train.<span class="property">Species</span></span><br><span class="line">test_X= test[[<span class="string">&#x27;SepalLengthCm&#x27;</span>,<span class="string">&#x27;SepalWidthCm&#x27;</span>,<span class="string">&#x27;PetalLengthCm&#x27;</span>,<span class="string">&#x27;PetalWidthCm&#x27;</span>]]</span><br><span class="line">test_y =test.<span class="property">Species</span> </span><br></pre></td></tr></table></figure><p>检查训练集和测试集<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_X.<span class="title function_">head</span>(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><br><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7yj8D.png"/></div></div></div></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_X.<span class="title function_">head</span>(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7yh2o.png"/></div></div></div><p>训练集中分类的输出值（原始列表中标注的分类）</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_y.<span class="title function_">head</span>()</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/o7yfXb.png"/></div></div></div><h3 id="支持向量机（SVM）"><a href="#支持向量机（SVM）" class="headerlink" title="支持向量机（SVM）"></a>支持向量机（SVM）</h3><ul><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"><span class='p blue'>sklearn.svm.SVC</span></a> — SVC算法</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.fit"><span class='p blue'>sklearn.svm.SVC.fit</span></a> — 对于训练集使用fit方法训练算法</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict"><span class='p blue'>sklearn.svm.SVC.predict</span></a> — 传入测试集，使用predict方法给出预测值</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"><span class='p blue'>sklearn.metrics.accuracy_score</span></a> — 预测值与实际值对比，给出算法准确度</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = svm.<span class="title function_">SVC</span>()</span><br><span class="line">model.<span class="title function_">fit</span>(train_X,train_y)</span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_X)</span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the SVM is:&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y))</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>The accuracy of the SVM is: 0.9777777777777777</p></div><p>SVM给出了较好准确度。基于上面的步骤，检验不同算法结果。</p><h3 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = <span class="title class_">LogisticRegression</span>()</span><br><span class="line">model.<span class="title function_">fit</span>(train_X,train_y)</span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_X)</span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the Logistic Regression is&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y))</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>The accuracy of the Logistic Regression is 0.9777777777777777</p></div><h3 id="决策树（Decision-Tree）"><a href="#决策树（Decision-Tree）" class="headerlink" title="决策树（Decision Tree）"></a>决策树（Decision Tree）</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model=<span class="title class_">DecisionTreeClassifier</span>()</span><br><span class="line">model.<span class="title function_">fit</span>(train_X,train_y)</span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_X)</span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the Decision Tree is&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y))</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>The accuracy of the Decision Tree is 0.9333333333333333</p></div><h3 id="K邻近算法（K-Nearest-Neighbours）"><a href="#K邻近算法（K-Nearest-Neighbours）" class="headerlink" title="K邻近算法（K-Nearest Neighbours）"></a>K邻近算法（K-Nearest Neighbours）</h3><p>n_neighbors=3：检查邻近3个点判断属于那个分类</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model=<span class="title class_">KNeighborsClassifier</span>(n_neighbors=<span class="number">3</span>)</span><br><span class="line">model.<span class="title function_">fit</span>(train_X,train_y)</span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_X)</span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the KNN is&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y))</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>The accuracy of the KNN is 0.9777777777777777</p></div><h3 id="当n-neighbors值不同时，检查KNN算法的准确度变化"><a href="#当n-neighbors值不同时，检查KNN算法的准确度变化" class="headerlink" title="当n_neighbors值不同时，检查KNN算法的准确度变化"></a>当n_neighbors值不同时，检查KNN算法的准确度变化</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">a_index=<span class="title function_">list</span>(<span class="title function_">range</span>(<span class="number">1</span>,<span class="number">11</span>))</span><br><span class="line">#a=pd.<span class="title class_">Series</span>()</span><br><span class="line">a=pd.<span class="title class_">Series</span>(dtype=<span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line">x=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="title function_">list</span>(<span class="title function_">range</span>(<span class="number">1</span>,<span class="number">11</span>)):</span><br><span class="line">    model=<span class="title class_">KNeighborsClassifier</span>(n_neighbors=i) </span><br><span class="line">    model.<span class="title function_">fit</span>(train_X,train_y)</span><br><span class="line">    prediction=model.<span class="title function_">predict</span>(test_X)</span><br><span class="line">    a=a.<span class="title function_">append</span>(pd.<span class="title class_">Series</span>(metrics.<span class="title function_">accuracy_score</span>(prediction,test_y)))</span><br><span class="line">plt.<span class="title function_">plot</span>(a_index, a)</span><br><span class="line">plt.<span class="title function_">xticks</span>(x)</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/oD55iC.png"/></div></div></div><h3 id="在上面的模型中，我们使用了数据集所有的特征。现在分别使用花萼、花瓣特征"><a href="#在上面的模型中，我们使用了数据集所有的特征。现在分别使用花萼、花瓣特征" class="headerlink" title="在上面的模型中，我们使用了数据集所有的特征。现在分别使用花萼、花瓣特征"></a>在上面的模型中，我们使用了数据集所有的特征。现在分别使用花萼、花瓣特征</h3><ul><li>花萼：长度和宽度相关性很低</li><li>花瓣：长度和宽度相关性很高</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">petal=iris[[<span class="string">&#x27;PetalLengthCm&#x27;</span>,<span class="string">&#x27;PetalWidthCm&#x27;</span>,<span class="string">&#x27;Species&#x27;</span>]]</span><br><span class="line">sepal=iris[[<span class="string">&#x27;SepalLengthCm&#x27;</span>,<span class="string">&#x27;SepalWidthCm&#x27;</span>,<span class="string">&#x27;Species&#x27;</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_p,test_p=<span class="title function_">train_test_split</span>(petal,test_size=<span class="number">0.3</span>,random_state=<span class="number">0</span>)  #petals</span><br><span class="line">train_x_p=train_p[[<span class="string">&#x27;PetalWidthCm&#x27;</span>,<span class="string">&#x27;PetalLengthCm&#x27;</span>]]</span><br><span class="line">train_y_p=train_p.<span class="property">Species</span></span><br><span class="line">test_x_p=test_p[[<span class="string">&#x27;PetalWidthCm&#x27;</span>,<span class="string">&#x27;PetalLengthCm&#x27;</span>]]</span><br><span class="line">test_y_p=test_p.<span class="property">Species</span></span><br><span class="line"></span><br><span class="line">train_s,test_s=<span class="title function_">train_test_split</span>(sepal,test_size=<span class="number">0.3</span>,random_state=<span class="number">0</span>)  #<span class="title class_">Sepal</span></span><br><span class="line">train_x_s=train_s[[<span class="string">&#x27;SepalWidthCm&#x27;</span>,<span class="string">&#x27;SepalLengthCm&#x27;</span>]]</span><br><span class="line">train_y_s=train_s.<span class="property">Species</span></span><br><span class="line">test_x_s=test_s[[<span class="string">&#x27;SepalWidthCm&#x27;</span>,<span class="string">&#x27;SepalLengthCm&#x27;</span>]]</span><br><span class="line">test_y_s=test_s.<span class="property">Species</span></span><br></pre></td></tr></table></figure><h3 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model=svm.<span class="title function_">SVC</span>()</span><br><span class="line">model.<span class="title function_">fit</span>(train_x_p,train_y_p) </span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_x_p) </span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the SVM using Petals is:&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y_p))</span><br><span class="line"></span><br><span class="line">model=svm.<span class="title function_">SVC</span>()</span><br><span class="line">model.<span class="title function_">fit</span>(train_x_s,train_y_s) </span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_x_s) </span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the SVM using Sepal is:&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y_s))</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>The accuracy of the SVM using Petals is: 0.9777777777777777<br>The accuracy of the SVM using Sepal is: 0.8</p></div><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = <span class="title class_">LogisticRegression</span>()</span><br><span class="line">model.<span class="title function_">fit</span>(train_x_p,train_y_p) </span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_x_p) </span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the Logistic Regression using Petals is:&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y_p))</span><br><span class="line"></span><br><span class="line">model.<span class="title function_">fit</span>(train_x_s,train_y_s) </span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_x_s) </span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the Logistic Regression using Sepals is:&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y_s))</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>The accuracy of the Logistic Regression using Petals is: 0.9777777777777777<br>The accuracy of the Logistic Regression using Sepals is: 0.8222222222222222</p></div><h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model=<span class="title class_">DecisionTreeClassifier</span>()</span><br><span class="line">model.<span class="title function_">fit</span>(train_x_p,train_y_p) </span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_x_p) </span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the Decision Tree using Petals is:&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y_p))</span><br><span class="line"></span><br><span class="line">model.<span class="title function_">fit</span>(train_x_s,train_y_s) </span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_x_s) </span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the Decision Tree using Sepals is:&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y_s))</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>The accuracy of the Decision Tree using Petals is: 0.9555555555555556<br>The accuracy of the Decision Tree using Sepals is: 0.6444444444444445</p></div><h3 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model=<span class="title class_">KNeighborsClassifier</span>(n_neighbors=<span class="number">3</span>) </span><br><span class="line">model.<span class="title function_">fit</span>(train_x_p,train_y_p) </span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_x_p) </span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the KNN using Petals is:&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y_p))</span><br><span class="line"></span><br><span class="line">model.<span class="title function_">fit</span>(train_x_s,train_y_s) </span><br><span class="line">prediction=model.<span class="title function_">predict</span>(test_x_s) </span><br><span class="line"><span class="title function_">print</span>(<span class="string">&#x27;The accuracy of the KNN using Sepals is:&#x27;</span>,metrics.<span class="title function_">accuracy_score</span>(prediction,test_y_s))</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><p>The accuracy of the KNN using Petals is: 0.9777777777777777<br>The accuracy of the KNN using Sepals is: 0.7333333333333333</p></div><p>总结：<br>使用花瓣数据比使用花萼数据给出更高的准确度<br>正如前面热力图展示的，花瓣特征的相关性比花萼特征的相关性更强</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ccc = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">ddd = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">16</span>,<span class="number">25</span>]</span><br><span class="line">plt.<span class="title function_">scatter</span>(ccc,ccc,color=<span class="string">&#x27;red&#x27;</span>)</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/oD5G5t.png"/></div></div></div><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">eee = [x**<span class="number">2</span>-x <span class="keyword">for</span> x <span class="keyword">in</span> ccc]</span><br><span class="line">plt.<span class="title function_">scatter</span>(ccc,eee)</span><br></pre></td></tr></table></figure><div class="note green anzhiyufont anzhiyu-icon-forward simple"><div class="img-wrap"><div class="img-bg"><img class="img" src="https://vip.helloimg.com/images/2023/12/26/oD5BpQ.png"/></div></div></div>]]></content>
    
    
    <summary type="html">期末试题</summary>
    
    
    
    <category term="机器学习" scheme="https://xin0203xin0203.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://xin0203xin0203.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Python" scheme="https://xin0203xin0203.github.io/tags/Python/"/>
    
    <category term="Jupyter" scheme="https://xin0203xin0203.github.io/tags/Jupyter/"/>
    
  </entry>
  
  <entry>
    <title>十四、Flink组件搭建之Scala环境搭建（一）</title>
    <link href="https://xin0203xin0203.github.io/posts/e7ef9c46.html"/>
    <id>https://xin0203xin0203.github.io/posts/e7ef9c46.html</id>
    <published>2023-12-18T15:31:57.214Z</published>
    <updated>2024-12-25T01:34:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-shuffle modern"><p>介绍：<br>Scala 是一门多范式（multi-paradigm）的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。<br>Scala 运行在 Java 虚拟机上，并兼容现有的 Java 程序。<br>Scala 源代码被编译成 Java 字节码，所以它可以运行于 JVM 之上，并可以调用现有的 Java 类库。</p></div><div class="tip bolt"><p>参考文件：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BScala%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s?__biz=MzI4MDQzMzYyMg==&mid=2247485228&idx=1&sn=a1924a0895d668ec77e9621cf1effa5e&chksm=ebb9c195dcce4883e064380ee281c69c78c96b49bdcc075ee3fbd5c9930b83fd221bf5c50ccb&scene=21#wechat_redirect)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7fngS.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Scala环境搭建</div>            <div class="tag-link-sitename">Scala环境搭建-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h1 id="一、Window-下搭建开发环境"><a href="#一、Window-下搭建开发环境" class="headerlink" title="一、Window 下搭建开发环境"></a>一、Window 下搭建开发环境</h1><h2 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h2><p>准保JDK8安装成功，并成功配置环境变量：<code>JAVA_HOME</code>, <code>Path</code><br><img src="https://vip.helloimg.com/images/2023/12/25/o7flHQ.png" alt="640.png"></p><h2 id="2-下载"><a href="#2-下载" class="headerlink" title="2. 下载"></a>2. 下载</h2><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B**Scala%202.13.6**%5D(https:/scala-lang.org/download/2.13.6.html)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7fAhb.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Scala 2.13.6</div>            <div class="tag-link-sitename">The Scala Programming Language</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><p><img src="https://vip.helloimg.com/images/2023/12/25/o7fbaC.png" alt="a4f72964-ea59-49a0-900a-aacbc6874f89.png"></p><h2 id="3-解压"><a href="#3-解压" class="headerlink" title="3. 解压"></a>3. 解压</h2><p>解压到自己文件目录里，然后记住<font color=red>文件路径</font></p><h2 id="4-配置环境变量"><a href="#4-配置环境变量" class="headerlink" title="4. 配置环境变量"></a>4. 配置环境变量</h2><p>配置Scala 环境变量：<code>SCALA_HOME</code> 和 <code>Path</code><br><img src="https://vip.helloimg.com/images/2023/12/25/o7fW4v.png" alt="1.PNG"></p><p><img src="https://vip.helloimg.com/images/2023/12/25/o7f90E.png" alt="2.PNG"></p><h2 id="5-验证安装是否成功"><a href="#5-验证安装是否成功" class="headerlink" title="5. 验证安装是否成功"></a>5. 验证安装是否成功</h2><p>按下键盘的<font color=orange weight=bold>Win+R</font>后，输入<font color=orange weight=bold>cmd回车</font>，输入Scala，如果能进入 <code>Scala</code> 交互环境，则代表安装成功：<br><img src="https://vip.helloimg.com/images/2023/12/25/o7fTCu.png" alt="3.PNG"></p><h1 id="二、Linux-下搭建开发环境"><a href="#二、Linux-下搭建开发环境" class="headerlink" title="二、Linux 下搭建开发环境"></a>二、Linux 下搭建开发环境</h1><h2 id="1-JDK环境准备"><a href="#1-JDK环境准备" class="headerlink" title="1. JDK环境准备"></a>1. JDK环境准备</h2><div class="tip bolt"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="2-下载解压并改名"><a href="#2-下载解压并改名" class="headerlink" title="2. 下载解压并改名"></a>2. 下载解压并改名</h2><p><strong><a href="https://scala-lang.org/download/2.13.6.html">Scala</a>压缩包——&gt;scala-2.13.6.tgz</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf scala-<span class="number">2.13</span><span class="number">.6</span>.tgz </span><br><span class="line">mv scala-<span class="number">2.13</span><span class="number">.6</span>.tgz scala</span><br></pre></td></tr></table></figure></p><h2 id="3-配置环境变量"><a href="#3-配置环境变量" class="headerlink" title="3. 配置环境变量"></a>3. 配置环境变量</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"># 添加以下内容</span><br><span class="line">export SCALA_HOME=/opt/scala</span><br><span class="line">export PATH=$PATH:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure><h2 id="4-更新环境变量"><a href="#4-更新环境变量" class="headerlink" title="4. 更新环境变量"></a>4. 更新环境变量</h2><p>使得配置的环境变量立即生效：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><h2 id="5-验证安装是否成功-1"><a href="#5-验证安装是否成功-1" class="headerlink" title="5. 验证安装是否成功"></a>5. 验证安装是否成功</h2><p>输入<code>scala</code>，如果能进入 Scala 交互环境，则代表安装成功<br><img src="https://vip.helloimg.com/images/2023/12/25/o7fMDt.png" alt="捕获.PNG"></p><h1 id="三、Scala-的Hello-world-案例"><a href="#三、Scala-的Hello-world-案例" class="headerlink" title="三、Scala 的Hello world 案例"></a>三、Scala 的Hello world 案例</h1><h2 id="1-创建一个Maven工程"><a href="#1-创建一个Maven工程" class="headerlink" title="1. 创建一个Maven工程"></a>1. 创建一个Maven工程</h2><p>参考文件：<br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B1.%20%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97%5D(https:/www.yuque.com/yuqueyonghub89qji/whl8ua/yf1fllg7ivf7yv8h?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7fOhY.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">1. 安装指南</div>            <div class="tag-link-sitename">环境要求Java8及以上 Maven 3.3及以上：https://www.yuque.com/yuqueyonghub89qji/whl8ua/yf1fllg7ivf7yv8h</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><h2 id="2-引入依赖"><a href="#2-引入依赖" class="headerlink" title="2. 引入依赖"></a>2. 引入依赖</h2><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">flink.version</span>&gt;</span>1.13.0<span class="tag">&lt;/<span class="name">flink.version</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">target.java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target.java.version</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">scala.binary.version</span>&gt;</span>2.12<span class="tag">&lt;/<span class="name">scala.binary.version</span>&gt;</span></span></span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-scala_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-scala_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span></span><br></pre></td></tr></table></figure><p>等待下载。。。</p><h2 id="3-创建项目的源文件目录"><a href="#3-创建项目的源文件目录" class="headerlink" title="3. 创建项目的源文件目录"></a>3. 创建项目的源文件目录</h2><p>在 <code>main</code> 下创建一个文件夹作为 <code>scala</code> 源文件的根目录, 比如目录名: <code>scala</code>, 然后标记为源文件根目录<br><img src="https://vip.helloimg.com/images/2023/12/25/o7fNaM.png" alt="2.PNG"></p><h2 id="4-下载scala组件工具"><a href="#4-下载scala组件工具" class="headerlink" title="4. 下载scala组件工具"></a>4. 下载scala组件工具</h2><p><img src="https://vip.helloimg.com/images/2023/12/25/o7fv9X.png" alt="1.PNG"></p><h2 id="5-引入scala组件工具"><a href="#5-引入scala组件工具" class="headerlink" title="5. 引入scala组件工具"></a>5. 引入scala组件工具</h2><p><img src="https://vip.helloimg.com/images/2023/12/25/o7fQbP.png" alt="1a4e41ef43002d13b72f0549a388e90.png"></p><p><img src="https://vip.helloimg.com/images/2023/12/25/o7fwgg.png" alt="3.PNG"></p><h2 id="4-创建Scala-的类"><a href="#4-创建Scala-的类" class="headerlink" title="4. 创建Scala 的类"></a>4. 创建Scala 的类</h2><p><img src="https://vip.helloimg.com/images/2023/12/25/o7fdx9.png" alt="捕获.PNG"></p><h2 id="5-编写程序"><a href="#5-编写程序" class="headerlink" title="5. 编写程序"></a>5. 编写程序</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">object HelloWorld &#123;</span><br><span class="line">  def <span class="title function_">main</span><span class="params">(args:Array[String])</span>:Unit = &#123;</span><br><span class="line">    println(<span class="string">&quot;Hello Scala&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="6-运行"><a href="#6-运行" class="headerlink" title="6. 运行"></a>6. 运行</h2><p><img src="https://vip.helloimg.com/images/2023/12/25/o7fpD6.png" alt="捕获.PNG"></p><h1 id="拓展统计单词计算"><a href="#拓展统计单词计算" class="headerlink" title="拓展统计单词计算"></a>拓展统计单词计算</h1><p><img src="https://vip.helloimg.com/images/2023/12/25/o7f7Gn.png" alt="捕获.PNG"></p><h2 id="1-准备数据"><a href="#1-准备数据" class="headerlink" title="1. 准备数据"></a>1. 准备数据</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hello python</span><br><span class="line">hello scala</span><br><span class="line">hello java</span><br><span class="line">hello hadoop</span><br><span class="line">hello word</span><br><span class="line">hello spark</span><br></pre></td></tr></table></figure><h2 id="2-编写程序"><a href="#2-编写程序" class="headerlink" title="2. 编写程序"></a>2. 编写程序</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.com</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.scala.&#123;ExecutionEnvironment, createTypeInformation&#125;</span><br><span class="line"></span><br><span class="line">object BatchWordCount &#123;</span><br><span class="line">  def <span class="title function_">main</span><span class="params">(args: Array[String])</span>: Unit = &#123;</span><br><span class="line">    <span class="comment">// 1. 创建一个执行环境</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">env</span> <span class="operator">=</span> ExecutionEnvironment.getExecutionEnvironment</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 2. 读取文本文件数据</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">lineDataSet</span> <span class="operator">=</span> env.readTextFile(<span class="string">&quot;input/test.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 对数据集中进行转换处理</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">wordAndOne</span> <span class="operator">=</span> lineDataSet.flatMap(_.split(<span class="string">&quot; &quot;</span>)).map(word=&gt;(word, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 按照单词进行分组</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">wordAndOneGroup</span> <span class="operator">=</span> wordAndOne.groupBy(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5. 对分组数据进行sum聚合统计</span></span><br><span class="line">    <span class="type">val</span> <span class="variable">sum</span> <span class="operator">=</span> wordAndOneGroup.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 6. 打印</span></span><br><span class="line">    sum.print()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="报错提醒"><a href="#报错提醒" class="headerlink" title="报错提醒"></a>报错提醒</h2><h3 id="报错原因：由于scala的版本不对"><a href="#报错原因：由于scala的版本不对" class="headerlink" title="报错原因：由于scala的版本不对"></a><strong>报错原因：</strong>由于scala的版本不对</h3><p><code>Error:scalac: Error: scala.collection.mutable.Set$.apply(Lscala/collection/Seq；)</code><br>解决方案：<br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BError:scalac:%20Error:%20scala.collection.mutable.Set$.apply(Lscala/collection/Seq%EF%BC%9B)_%E7%BC%96%E4%B8%8D%E5%87%BA%E4%BB%A3%E7%A0%81%E7%9A%84%E5%A5%B3%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2_lscala/collection/seq%5D(https:/blog.csdn.net/Miraitowa_Neo/article/details/123232229)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7yFIh.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Error:scalac: Error: scala.collection.mutable.Set$.apply</div>            <div class="tag-link-sitename">Error:scalac: Error: scala.collection.mutable.Set$.apply(Lscala/collection/Seq；</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><h3 id="报错原因：java与scala的版本冲突导致"><a href="#报错原因：java与scala的版本冲突导致" class="headerlink" title="报错原因：java与scala的版本冲突导致"></a><strong>报错原因：java与<a href="https://so.csdn.net/so/search?q=scala&amp;spm=1001.2101.3001.7020">scala</a>的版本冲突导致</strong></h3><p>解决方案：<br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BError:scalac:%20error%20while%20loading%20package">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(Scala signature package has wrong version_miaohui8023的博客-CSDN博客](https://blog.csdn.net/miaohui8023/article/details/105327734))">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Error:scalac: error while loading package</div>            <div class="tag-link-sitename">Error:scalac: error while loading package，Scala signature package has wrong version_miaohui8023</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><h2 id="3-运行结果"><a href="#3-运行结果" class="headerlink" title="3. 运行结果"></a>3. 运行结果</h2><p><img src="https://vip.helloimg.com/images/2023/12/25/o7y1Lq.png" alt="捕获.PNG"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-shuffle modern&quot;&gt;&lt;p&gt;介绍：&lt;br&gt;Scala 是一门多范式（multi-paradigm）的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。&lt;br&gt;Sc</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十四、Flink组件搭建之HA-Flink集群环境搭建(Yarn模式)(五)</title>
    <link href="https://xin0203xin0203.github.io/posts/e593d1c2.html"/>
    <id>https://xin0203xin0203.github.io/posts/e593d1c2.html</id>
    <published>2023-12-18T15:31:57.200Z</published>
    <updated>2024-12-25T20:34:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="tip success"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%EF%BC%88%E4%B8%80%EF%BC%89Scala%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/ifi3zw34ztgm4bqt?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7fngS.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">（一）Scala环境搭建</div>            <div class="tag-link-sitename">Scala 是一门多范式（multi-paradigm）的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。 Scala 运行在 Java 虚拟机上，并兼容现有的 Java 程序。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%BA%8C)%20Flink%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Local%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/fbyk58l02whdr677?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7y3Nr.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">(二) Flink集群环境搭建(Local模式)</div>            <div class="tag-link-sitename">Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%B8%89)%20Flink%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Standalone%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/dxmlft2waa775lkm?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7yt6S.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">(三) Flink集群环境搭建(Standalone模式)</div>            <div class="tag-link-sitename"> </div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E5%9B%9B)%20HA-Flink%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Standalone%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/lne7tfikcbvkww26?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7ySQt.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">(四) HA-Flink集群环境搭建(Standalone模式)</div>            <div class="tag-link-sitename"> </div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="tip sync"><p>需要的安装包：<strong><a href="https://archive.apache.org/dist/flink/">flink</a>压缩包——&gt;flink-1.13.0-bin-scala_2.12.tgz</strong></p></div><h1 id="HA-Yarn模式"><a href="#HA-Yarn模式" class="headerlink" title="HA-Yarn模式"></a>HA-Yarn模式</h1><h3 id="1-1-修改集群配置"><a href="#1-1-修改集群配置" class="headerlink" title="1.1 修改集群配置"></a>1.1 修改集群配置</h3><h4 id="1-1-1-vim-HADOOP-HOME-etc-hadoop-yarn-site-xml"><a href="#1-1-1-vim-HADOOP-HOME-etc-hadoop-yarn-site-xml" class="headerlink" title="1.1.1 vim $HADOOP_HOME/etc/hadoop/yarn-site.xml"></a>1.1.1 <strong>vim $HADOOP_HOME/etc/hadoop/yarn-site.xml</strong></h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--关闭yarn的内存检查--&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.am.max-attempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h4 id="1-1-2-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件"><a href="#1-1-2-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件" class="headerlink" title="1.1.2 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件"></a>1.1.2 进入 <code>$&#123;FLINK_HOME&#125;/conf</code> 目录下，修改<strong>flink-conf.yaml文件</strong></h4><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置Flink的主节点</span></span><br><span class="line"><span class="attr">jobmanager.rpc.address:</span> <span class="string">master</span></span><br><span class="line"><span class="comment"># 配置使用zookeeper来开启高可用模式</span></span><br><span class="line"><span class="attr">high-availability:</span> <span class="string">zookeeper</span></span><br><span class="line"><span class="comment"># 配置zookeeper的地址，采用zookeeper集群时，可以使用逗号来分隔多个节点地址</span></span><br><span class="line"><span class="attr">high-availability.zookeeper.quorum:</span> <span class="string">master:2181,slave1:2181,slave2:2181</span></span><br><span class="line"><span class="comment"># 在zookeeper上存储flink集群元信息的路径</span></span><br><span class="line"><span class="attr">high-availability.zookeeper.path.root:</span> <span class="string">/ha-flink</span></span><br><span class="line"><span class="comment"># 持久化存储JobManager元数据的地址，zookeeper上存储的只是指向该元数据的指针信息</span></span><br><span class="line"><span class="attr">high-availability.storageDir:</span> <span class="string">hdfs://hacluster:8020/flink/recovery</span></span><br><span class="line"><span class="comment">#（hacluster与HAHadoop中的core-site.xml里的hadoop集群在zookeeper上注册的节点名一致）</span></span><br><span class="line"><span class="comment"># 将已完成的作业上传到此目录中，让任务历史服务器进行监控</span></span><br><span class="line"><span class="attr">jobmanager.archive.fs.dir:</span> <span class="string">hdfs://hacluster:8020/flink-jobhistory</span></span><br><span class="line"><span class="attr">historyserver.web.address:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">historyserver.web.port:</span> <span class="number">18082</span></span><br><span class="line"><span class="comment"># 任务历史服务器监控目录中已存档的作业</span></span><br><span class="line"><span class="attr">historyserver.archive.fs.dir:</span> <span class="string">hdfs://hacluster:8020/flink-jobhistory</span></span><br><span class="line"><span class="attr">historyserver.web.refresh-interval:</span> <span class="number">10000</span></span><br><span class="line"><span class="comment">#比StandAlone模式多了</span></span><br><span class="line"><span class="attr">yarn.application-attempts:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure><p>除了上面的配置之外，Flink 还可以使用以下可选参数来优化集群性能：</p><ul><li><strong>jobmanager.heap.size</strong>：JobManager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.heap.size</strong>：Taskmanager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.numberOfTaskSlots</strong>：Taskmanager 上 slots 的数量，通常设置为 CPU 核心的数量，或其一半。</li><li><strong>parallelism.default</strong>：任务默认的并行度。</li><li><strong>io.tmp.dirs</strong>：存储临时文件的路径，如果没有配置，则默认采用服务器的临时目录，如 LInux 的 /tmp 目录。<h4 id="1-1-3-修改-masters-文件，指定JobManager节点"><a href="#1-1-3-修改-masters-文件，指定JobManager节点" class="headerlink" title="1.1.3 修改 masters 文件，指定JobManager节点"></a>1.1.3 修改 <code>masters</code> 文件，指定JobManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">master:<span class="number">8081</span></span><br><span class="line">slave1:<span class="number">8081</span></span><br></pre></td></tr></table></figure><h4 id="1-1-4-修改-slaves（workers）-文件，添加TaskManager节点"><a href="#1-1-4-修改-slaves（workers）-文件，添加TaskManager节点" class="headerlink" title="1.1.4 修改 slaves（workers） 文件，添加TaskManager节点"></a>1.1.4 修改 <code>slaves（workers）</code> 文件，添加TaskManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-2-导入Flink依赖flink-shaded-hadoop包到Flink-lib中去（各个节点Flink的lib）"><a href="#1-2-导入Flink依赖flink-shaded-hadoop包到Flink-lib中去（各个节点Flink的lib）" class="headerlink" title="1.2 导入Flink依赖flink-shaded-hadoop包到Flink/lib中去（各个节点Flink的lib）"></a>1.2 导入Flink依赖<strong>flink-shaded-hadoop</strong>包到Flink/lib中去（各个节点Flink的lib）</h3><strong>将文件下载本地，再将文件的后缀篡改为jar，在上传群集文件当中（.txt—&gt;.jar）</strong><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="https://www.yuque.com/attachments/yuque/0/2023/txt/33576317/1676461700287-df65f88c-00ec-4a79-9a33-83f71af0a1d4.txt">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="">          <i class="anzhiyufont anzhiyu-icon-link" style=""></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">flink-shaded-hadoop-2-uber-2.8.3-10.0.txt</div>            <div class="tag-link-sitename"> </div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h3 id="1-3-分发Flink给其他节点"><a href="#1-3-分发Flink给其他节点" class="headerlink" title="1.3 分发Flink给其他节点"></a>1.3 分发Flink给其他节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r $FLINK_HOME/ slave1:/opt/</span><br><span class="line">scp -r $FLINK_HOME/ slave2:/opt/</span><br></pre></td></tr></table></figure><h3 id="1-4-在HDFS上创建HIstory目录"><a href="#1-4-在HDFS上创建HIstory目录" class="headerlink" title="1.4 在HDFS上创建HIstory目录"></a>1.4 在<strong>HDFS</strong>上<strong>创建</strong>HIstory目录</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /flink</span><br><span class="line">hdfs dfs -mkdir /flink/recovery</span><br><span class="line">hdfs dfs -mkdir /flink-jobhistory</span><br><span class="line">hdfs dfs -chmod <span class="number">777</span> /flink-jobhistory</span><br></pre></td></tr></table></figure><h3 id="1-5-启动"><a href="#1-5-启动" class="headerlink" title="1.5 启动"></a>1.5 启动</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 启动HAHadoop集群</span><br><span class="line">[huser@master ~]$ ./opt/bin/start-dfs.sh--&gt;  <span class="string">&#x27;脚本启动&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-6-启动Flink集群和任务历史服务器"><a href="#1-6-启动Flink集群和任务历史服务器" class="headerlink" title="1.6 启动Flink集群和任务历史服务器"></a>1.6 启动Flink集群和任务历史服务器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[huser@master ~]$ start-cluster.sh</span><br><span class="line">[huser@master ~]$ historyserver.sh start</span><br><span class="line"><span class="meta">#jps</span></span><br><span class="line">#主节点多出:</span><br><span class="line"><span class="number">3835</span> StandaloneSessionClusterEntrypoint</span><br><span class="line"><span class="number">4148</span> TaskManagerRunner</span><br><span class="line">#其他节点多出：</span><br><span class="line"><span class="number">3437</span> TaskManagerRunner</span><br></pre></td></tr></table></figure><h3 id="1-7-查看web端"><a href="#1-7-查看web端" class="headerlink" title="1.7 查看web端"></a>1.7 查看web端</h3>两个 JobManager 和 任务历史服务器的端口号分别为 8081 、8081和 18082，界面应该如下：<br>访问 <a href="http://192.168.33.151:8081"><strong>http://192.168.33.151:8081</strong></a>或<a href="http://192.168.33.150:8081"><strong>http://192.168.33.150:8081</strong></a>,<a href="http://192.168.33.150:18082"><strong>http://192.168.33.150:18082</strong></a><br><img src="https://vip.helloimg.com/images/2023/12/26/o7yvyn.png" alt="Snipaste_2023-02-15_20-05-43.png"></li></ul><p><img src="https://vip.helloimg.com/images/2023/12/26/o7ydQ6.png" alt="Snipaste_2023-02-15_20-05-43.png"></p><p><img src="https://vip.helloimg.com/images/2023/12/26/o7ycSP.png" alt="Snipaste_2023-02-15_20-05-43.png"></p><h3 id="1-8-HA测试"><a href="#1-8-HA测试" class="headerlink" title="1.8 HA测试"></a>1.8 HA测试</h3><p><font color=blue>注意：在测试的时候，内存先调大，推荐3G内存执行任务；另外，就是网页端无法进去的情况，修改系统文件中</font><font color=red>System32/drivers/etc/hosts，</font><font color=skyblue>调整网络IP和虚拟机的用户名是否对准，或者有没有重复的。</font><br><strong>流计算词频统计案例源码：</strong><br><strong>将文件下载本地，再将文件的后缀篡改为jar，在上传群集文件当中（.txt—&gt;.jar）</strong><br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="https://www.yuque.com/attachments/yuque/0/2023/txt/33576317/1676461700284-5c77fac5-f291-43f5-85b2-d06bd0185868.txt">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="">          <i class="anzhiyufont anzhiyu-icon-link" style=""></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">flink_scala-1.0-SNAPSHOT.txt</div>            <div class="tag-link-sitename"> </div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><br>提交作业：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.虚拟机内开启端口</span></span><br><span class="line">[huser@master ~]$ nc -lk 5555</span><br><span class="line"><span class="comment"># 2.运行Flink的Jar包</span></span><br><span class="line">flink run -m yarn-cluster -ys 1 -c cs -d flink_scala-1.0-SNAPSHOT.jar master 5555</span><br><span class="line"></span><br><span class="line">注意：这个时候我们使用flink run的时候，它会默认找这个文件，然后根据这个文件找到刚才我们创建的那个永久的Flink集群，这个文件里面保存的就是刚才启动的那个Flink集群在YARN中对应的applicationid</span><br><span class="line"></span><br><span class="line"><span class="comment">#两个master节点随便一个会多出Yarnjob服务</span></span><br><span class="line">26696 YarnJobClusterEntrypoint</span><br><span class="line"><span class="comment">#进去8088网页会发现有新的任务</span></span><br><span class="line"><span class="comment">#进度条后面有一个ApplocationMaster点击</span></span><br><span class="line"><span class="comment">#然后就会进入了Flink的Job页面</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#找出哪个master节点有YarnJobClusterEntrypoint服务然后Kill掉一个</span></span><br><span class="line"><span class="built_in">kill</span> -9 YarnJobClusterEntrypoint服务端口</span><br><span class="line"><span class="comment">#重新进入刚刚的FlinkWeb页端</span></span><br><span class="line">会跳回8088端口</span><br><span class="line"><span class="comment">#然后查看另一个master </span></span><br><span class="line">jps</span><br><span class="line"><span class="comment">#是否出现</span></span><br><span class="line">YarnJobClusterEntrypoint服务</span><br><span class="line"><span class="comment">#然后再点击进度条后面的ApplocationMaster就可以重新进入Flink另一个master的JOb端</span></span><br></pre></td></tr></table></figure><p><font color=red>访问端口<a href="http://192.168.33.152:8088(例">http://192.168.33.152:8088(例</a>)</font><br><img src="https://vip.helloimg.com/images/2023/12/26/o7yNcz.png" alt="Snipaste_2023-02-15_22-03-23.png"><br>往下操作<br><img src="https://vip.helloimg.com/images/2023/12/26/o7y0mR.png" alt="Snipaste_2023-02-15_22-03-42.png"><br>运行过程中将正在服务的JobManager给kill掉，测试是否高可用<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill <span class="number">-9</span> YarnJobClusterEntrypoint服务端口</span><br></pre></td></tr></table></figure><br>此时hadoop01的8081无法访问，hadoop02会进行接管（重新提交刚才被中断的作业），这个过程需要稍等一会儿<br>再次输入数据后可以从结果看出是一个新作业：<br><img src="https://vip.helloimg.com/images/2023/12/26/o7y7M0.png" alt="Snipaste_2023-02-15_22-04-27.png"></p><p><img src="https://vip.helloimg.com/images/2023/12/26/o7yzX5.png" alt="Snipaste_2023-02-15_22-04-39.png"><br>结束任务后可以在任务历史服务器WebUI中进行查看：<br><img src="https://vip.helloimg.com/images/2023/12/26/o7yQVA.png" alt="image.png"></p><h3 id="1-9-关闭命令"><a href="#1-9-关闭命令" class="headerlink" title="1.9 关闭命令"></a>1.9 关闭命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;tip success&quot;&gt;&lt;p&gt;前置准备：&lt;/p&gt;
&lt;/div&gt;
&lt;div calss=&#39;anzhiyu-tag-link&#39;&gt;&lt;a class=&quot;tag-Link&quot; target=&quot;_blank&quot; href=&quot;/%5B%E4%B8%80%E3%80%81%</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十四、Flink组件搭建之HA-Flink集群环境搭建(Standalone模式)（四）</title>
    <link href="https://xin0203xin0203.github.io/posts/1d7b1dd3.html"/>
    <id>https://xin0203xin0203.github.io/posts/1d7b1dd3.html</id>
    <published>2023-12-18T15:31:57.182Z</published>
    <updated>2024-12-25T18:34:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="tip success"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%EF%BC%88%E4%B8%80%EF%BC%89Scala%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/ifi3zw34ztgm4bqt?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7fngS.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">（一）Scala环境搭建</div>            <div class="tag-link-sitename">Scala 是一门多范式（multi-paradigm）的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。 Scala 运行在 Java 虚拟机上，并兼容现有的 Java 程序。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%BA%8C)%20Flink%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Local%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/fbyk58l02whdr677?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7y3Nr.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">(二) Flink集群环境搭建(Local模式)</div>            <div class="tag-link-sitename">Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%B8%89)%20Flink%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Standalone%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/dxmlft2waa775lkm?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7yt6S.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">(三) Flink集群环境搭建(Standalone模式)</div>            <div class="tag-link-sitename"> </div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="tip home"><p>需要的安装包：<strong><a href="https://archive.apache.org/dist/flink/">flink</a>压缩包——&gt;flink-1.13.0-bin-scala_2.12.tgz</strong></p></div><h1 id="HA-StandAlone模式"><a href="#HA-StandAlone模式" class="headerlink" title="HA-StandAlone模式"></a>HA-StandAlone模式</h1><h3 id="1-1-修改集群配置"><a href="#1-1-修改集群配置" class="headerlink" title="1.1 修改集群配置"></a>1.1 修改集群配置</h3><h4 id="1-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件"><a href="#1-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件" class="headerlink" title="1.1.1 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件"></a>1.1.1 进入 <code>$&#123;FLINK_HOME&#125;/conf</code> 目录下，修改<strong>flink-conf.yaml文件</strong></h4><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置Flink的主节点</span></span><br><span class="line"><span class="attr">jobmanager.rpc.address:</span> <span class="string">master</span></span><br><span class="line"><span class="comment"># 配置使用zookeeper来开启高可用模式</span></span><br><span class="line"><span class="attr">high-availability:</span> <span class="string">zookeeper</span></span><br><span class="line"><span class="comment"># 配置zookeeper的地址，采用zookeeper集群时，可以使用逗号来分隔多个节点地址</span></span><br><span class="line"><span class="attr">high-availability.zookeeper.quorum:</span> <span class="string">master:2181,slave1:2181,slave2:2181</span></span><br><span class="line"><span class="comment"># 在zookeeper上存储flink集群元信息的路径</span></span><br><span class="line"><span class="attr">high-availability.zookeeper.path.root:</span> <span class="string">/ha-flink</span></span><br><span class="line"><span class="comment"># 持久化存储JobManager元数据的地址，zookeeper上存储的只是指向该元数据的指针信息</span></span><br><span class="line"><span class="attr">high-availability.storageDir:</span> <span class="string">hdfs://hacluster:8020/flink/recovery</span></span><br><span class="line"><span class="comment">#（hacluster与HAHadoop中的core-site.xml里的hadoop集群在zookeeper上注册的节点名一致）</span></span><br><span class="line"><span class="comment"># 将已完成的作业上传到此目录中，让任务历史服务器进行监控</span></span><br><span class="line"><span class="attr">jobmanager.archive.fs.dir:</span> <span class="string">hdfs://hacluster:8020/flink-jobhistory</span></span><br><span class="line"><span class="attr">historyserver.web.address:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">historyserver.web.port:</span> <span class="number">18082</span></span><br><span class="line"><span class="comment"># 任务历史服务器监控目录中已存档的作业</span></span><br><span class="line"><span class="attr">historyserver.archive.fs.dir:</span> <span class="string">hdfs://hacluster:8020/flink-jobhistory</span></span><br><span class="line"><span class="attr">historyserver.web.refresh-interval:</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure><p>除了上面的配置之外，Flink 还可以使用以下可选参数来优化集群性能：</p><ul><li><strong>jobmanager.heap.size</strong>：JobManager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.heap.size</strong>：Taskmanager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.numberOfTaskSlots</strong>：Taskmanager 上 slots 的数量，通常设置为 CPU 核心的数量，或其一半。</li><li><strong>parallelism.default</strong>：任务默认的并行度。</li><li><strong>io.tmp.dirs</strong>：存储临时文件的路径，如果没有配置，则默认采用服务器的临时目录，如 LInux 的 /tmp 目录。<h4 id="1-1-2-修改-masters-文件，指定JobManager节点"><a href="#1-1-2-修改-masters-文件，指定JobManager节点" class="headerlink" title="1.1.2 修改 masters 文件，指定JobManager节点"></a>1.1.2 修改 <code>masters</code> 文件，指定JobManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">master:<span class="number">8081</span></span><br><span class="line">slave1:<span class="number">8081</span></span><br></pre></td></tr></table></figure><h4 id="1-1-3-修改-slaves（workers）-文件，添加TaskManager节点"><a href="#1-1-3-修改-slaves（workers）-文件，添加TaskManager节点" class="headerlink" title="1.1.3 修改 slaves（workers） 文件，添加TaskManager节点"></a>1.1.3 修改 <code>slaves（workers）</code> 文件，添加TaskManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-2-导入Flink依赖flink-shaded-hadoop包到Flink-lib中去（各个节点Flink的lib）"><a href="#1-2-导入Flink依赖flink-shaded-hadoop包到Flink-lib中去（各个节点Flink的lib）" class="headerlink" title="1.2 导入Flink依赖flink-shaded-hadoop包到Flink/lib中去（各个节点Flink的lib）"></a>1.2 导入Flink依赖<strong>flink-shaded-hadoop</strong>包到Flink/lib中去（各个节点Flink的lib）</h3><strong>将文件下载本地，再将文件的后缀篡改为jar，在上传群集文件当中（.txt—&gt;.jar）</strong><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="https://www.yuque.com/attachments/yuque/0/2023/txt/33576317/1676461093792-9afc6989-aa00-46ce-aebc-2578461d1c97.txt">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="">          <i class="anzhiyufont anzhiyu-icon-link" style=""></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">flink-shaded-hadoop-2-uber-2.8.3-10.0.txt</div>            <div class="tag-link-sitename"> </div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h3 id="1-3-分发Flink给其他节点"><a href="#1-3-分发Flink给其他节点" class="headerlink" title="1.3 分发Flink给其他节点"></a>1.3 分发Flink给其他节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r $FLINK_HOME/ slave1:/opt/</span><br><span class="line">scp -r $FLINK_HOME/ slave2:/opt/</span><br></pre></td></tr></table></figure><h3 id="1-4-在HDFS上创建HIstory目录"><a href="#1-4-在HDFS上创建HIstory目录" class="headerlink" title="1.4 在HDFS上创建HIstory目录"></a>1.4 在<strong>HDFS</strong>上<strong>创建</strong>HIstory目录</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /flink</span><br><span class="line">hdfs dfs -mkdir /flink/recovery</span><br><span class="line">hdfs dfs -mkdir /flink-jobhistory</span><br><span class="line">hdfs dfs -chmod <span class="number">777</span> /flink-jobhistory</span><br></pre></td></tr></table></figure><h3 id="1-5-启动"><a href="#1-5-启动" class="headerlink" title="1.5 启动"></a>1.5 启动</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 启动HAHadoop集群</span><br><span class="line">[huser@master ~]$ ./opt/bin/start-dfs.sh--&gt;  <span class="string">&#x27;脚本启动&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-6-启动Flink集群和任务历史服务器"><a href="#1-6-启动Flink集群和任务历史服务器" class="headerlink" title="1.6 启动Flink集群和任务历史服务器"></a>1.6 启动Flink集群和任务历史服务器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[huser@master ~]$ start-cluster.sh</span><br><span class="line">[huser@master ~]$ historyserver.sh start</span><br><span class="line"><span class="meta">#jps</span></span><br><span class="line">#主节点多出:</span><br><span class="line"><span class="number">3835</span> StandaloneSessionClusterEntrypoint</span><br><span class="line"><span class="number">4148</span> TaskManagerRunner</span><br><span class="line">#其他节点多出：</span><br><span class="line"><span class="number">3437</span> TaskManagerRunner</span><br></pre></td></tr></table></figure><h3 id="1-7-查看web端"><a href="#1-7-查看web端" class="headerlink" title="1.7 查看web端"></a>1.7 查看web端</h3>启动成功后，访问 <a href="http://192.168.33.151:8081"><strong>http://192.168.33.151:8081</strong></a>或<a href="http://192.168.33.150:8081"><strong>http://192.168.33.150:8081</strong></a><br><img src="https://vip.helloimg.com/images/2023/12/26/o7ybcE.png" alt="image.png"></li></ul><p><img src="https://vip.helloimg.com/images/2023/12/26/o7yHJv.png" alt="image.png"></p><h3 id="1-8-HA测试"><a href="#1-8-HA测试" class="headerlink" title="1.8 HA测试"></a>1.8 HA测试</h3><p><strong>流计算词频统计案例源码：</strong></p><p><font color=red weight=bold>将文件下载本地，再将文件的后缀篡改为jar，在上传群集文件当中（.txt—&gt;.jar）</font><br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="https://www.yuque.com/attachments/yuque/0/2023/txt/33576317/1676452304638-4248c58f-a2be-479e-b4f8-30660c34f5c1.txt">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="">          <i class="anzhiyufont anzhiyu-icon-link" style=""></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">flink_scala-1.0-SNAPSHOT.txt</div>            <div class="tag-link-sitename"> </div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><br>提交作业：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.</span>虚拟机内开启端口</span><br><span class="line">[huser@master ~]$ nc -lk <span class="number">5555</span></span><br><span class="line"># <span class="number">2.</span>提交作业</span><br><span class="line">[huser@master ~]$ flink run -c cs flink_scala<span class="number">-1.0</span>-SNAPSHOT.jar master <span class="number">5555</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>     格式        class_path   jar_name          node_name   nc_端口  <span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>输入数据以及结果：<br><img src="https://vip.helloimg.com/images/2023/12/26/o7yiuu.png" alt="image.png"></p><p><img src="https://vip.helloimg.com/images/2023/12/26/o7y239.png" alt="image.png"><br>运行过程中将正在服务的JobManager给kill掉，测试是否高可用<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill <span class="number">-9</span> 端口号</span><br></pre></td></tr></table></figure><br>此时hadoop01的8081无法访问，hadoop02会进行接管（重新提交刚才被中断的作业），这个过程需要稍等一会儿<br>再次输入数据后可以从结果看出是一个新作业：<br><img src="https://vip.helloimg.com/images/2023/12/26/o7ylrY.png" alt="image.png"></p><p><img src="https://vip.helloimg.com/images/2023/12/26/o7yTMX.png" alt="image.png"><br>结束任务后可以在任务历史服务器WebUI中进行查看：<br><img src="https://vip.helloimg.com/images/2023/12/26/o7yW6g.png" alt="image.png"></p><h3 id="1-9-关闭命令"><a href="#1-9-关闭命令" class="headerlink" title="1.9 关闭命令"></a>1.9 关闭命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;tip success&quot;&gt;&lt;p&gt;前置准备：&lt;/p&gt;
&lt;/div&gt;
&lt;div calss=&#39;anzhiyu-tag-link&#39;&gt;&lt;a class=&quot;tag-Link&quot; target=&quot;_blank&quot; href=&quot;/%5B%E4%B8%80%E3%80%81%</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十四、Flink组件搭建之Flink集群环境搭建(Standalone模式)（三）</title>
    <link href="https://xin0203xin0203.github.io/posts/dd96b61.html"/>
    <id>https://xin0203xin0203.github.io/posts/dd96b61.html</id>
    <published>2023-12-18T15:31:57.170Z</published>
    <updated>2024-12-25T17:11:11.000Z</updated>
    
    <content type="html"><![CDATA[<div class="tip success"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%EF%BC%88%E4%B8%80%EF%BC%89Scala%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/ifi3zw34ztgm4bqt?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7fngS.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">（一）Scala环境搭建</div>            <div class="tag-link-sitename">Scala 是一门多范式（multi-paradigm）的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。 Scala 运行在 Java 虚拟机上，并兼容现有的 Java 程序。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%BA%8C)%20Flink%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Local%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/fbyk58l02whdr677?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7y3Nr.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">(二) Flink集群环境搭建(Local模式)</div>            <div class="tag-link-sitename">Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="tip home"><p>需要的安装包：<strong><a href="https://archive.apache.org/dist/flink/">flink</a>压缩包——&gt;flink-1.13.0-bin-scala_2.12.tgz</strong></p></div><h1 id="StandAlone模式"><a href="#StandAlone模式" class="headerlink" title="StandAlone模式"></a>StandAlone模式</h1><h3 id="1-1-修改集群配置"><a href="#1-1-修改集群配置" class="headerlink" title="1.1 修改集群配置"></a>1.1 修改集群配置</h3><h4 id="1-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件"><a href="#1-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件" class="headerlink" title="1.1.1 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件"></a>1.1.1 进入 <code>$&#123;FLINK_HOME&#125;/conf</code> 目录下，修改<strong>flink-conf.yaml文件</strong></h4><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">jobmanager.rpc.address:</span> <span class="string">master</span></span><br><span class="line"><span class="comment"># 将已完成的作业上传到此目录中，让任务历史服务器进行监控</span></span><br><span class="line"><span class="attr">jobmanager.archive.fs.dir:</span> <span class="string">hdfs://hacluster:8020/flink-jobhistory</span></span><br><span class="line"><span class="attr">historyserver.web.address:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">historyserver.web.port:</span> <span class="number">18082</span></span><br><span class="line"><span class="comment"># # 任务历史服务器监控目录中已存档的作业</span></span><br><span class="line"><span class="attr">historyserver.archive.fs.dir:</span> <span class="string">hdfs://hacluster:8020/flink-jobhistory</span></span><br><span class="line"><span class="attr">historyserver.web.refresh-interval:</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure><p>除了上面的配置之外，Flink 还可以使用以下可选参数来优化集群性能：</p><ul><li><strong>jobmanager.heap.size</strong>：JobManager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.heap.size</strong>：Taskmanager 的 JVM 堆内存大小，默认为 1024m 。</li><li><strong>taskmanager.numberOfTaskSlots</strong>：Taskmanager 上 slots 的数量，通常设置为 CPU 核心的数量，或其一半。</li><li><strong>parallelism.default</strong>：任务默认的并行度。</li><li><strong>io.tmp.dirs</strong>：存储临时文件的路径，如果没有配置，则默认采用服务器的临时目录，如 LInux 的 /tmp 目录。</li></ul><h4 id="1-1-2-修改-masters-文件，指定JobManager节点"><a href="#1-1-2-修改-masters-文件，指定JobManager节点" class="headerlink" title="1.1.2 修改 masters 文件，指定JobManager节点"></a>1.1.2 修改 <code>masters</code> 文件，指定JobManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master:<span class="number">8081</span></span><br></pre></td></tr></table></figure><h4 id="1-1-3-修改-slaves（workers）-文件，添加TaskManager节点"><a href="#1-1-3-修改-slaves（workers）-文件，添加TaskManager节点" class="headerlink" title="1.1.3 修改 slaves（workers） 文件，添加TaskManager节点"></a>1.1.3 修改 <code>slaves（workers）</code> 文件，添加TaskManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-2-分发Flink给其他节点"><a href="#1-2-分发Flink给其他节点" class="headerlink" title="1.2 分发Flink给其他节点"></a>1.2 分发Flink给其他节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r $FLINK_HOME/ slave1:/opt/</span><br><span class="line">scp -r $FLINK_HOME/ slave2:/opt/</span><br></pre></td></tr></table></figure><h3 id="1-3-在HDFS上创建HIstory目录"><a href="#1-3-在HDFS上创建HIstory目录" class="headerlink" title="1.3 在HDFS上创建HIstory目录"></a>1.3 在<strong>HDFS</strong>上<strong>创建</strong>HIstory目录</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /flink-jobhistory</span><br><span class="line">hdfs dfs -chmod <span class="number">777</span> /flink-jobhistory</span><br></pre></td></tr></table></figure><h3 id="1-3-启动"><a href="#1-3-启动" class="headerlink" title="1.3 启动"></a>1.3 启动</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#启动HAHadoop集群</span><br><span class="line">[huser@master ~]$ ./opt/bin/start-dfs.sh--&gt;  <span class="string">&#x27;脚本启动&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-4-启动Flink集群和任务历史服务器"><a href="#1-4-启动Flink集群和任务历史服务器" class="headerlink" title="1.4 启动Flink集群和任务历史服务器"></a>1.4 启动Flink集群和任务历史服务器</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[huser@master ~]$ start-cluster.sh</span><br><span class="line">[huser@master ~]$ historyserver.sh start</span><br><span class="line"><span class="meta">#jps</span></span><br><span class="line">#主节点多出:</span><br><span class="line"><span class="number">3835</span> StandaloneSessionClusterEntrypoint</span><br><span class="line"><span class="number">4148</span> TaskManagerRunner</span><br><span class="line">#其他节点多出：</span><br><span class="line"><span class="number">3437</span> TaskManagerRunner</span><br></pre></td></tr></table></figure><h3 id="1-5-查看web端"><a href="#1-5-查看web端" class="headerlink" title="1.5 查看web端"></a>1.5 查看web端</h3><p>启动成功后，访问 <a href="http://master:8081"><strong>http://master:8081</strong></a>或<a href="http://192.168.33.150:8081"><strong>http://192.168.33.150:8081</strong></a><br><img src="https://vip.helloimg.com/images/2023/12/25/o7ym3o.png" alt="image.png"></p><p><img src="https://vip.helloimg.com/images/2023/12/25/o7yErb.png" alt="image.png"></p><h3 id="1-6-关闭命令"><a href="#1-6-关闭命令" class="headerlink" title="1.6 关闭命令"></a>1.6 关闭命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;tip success&quot;&gt;&lt;p&gt;前置准备：&lt;/p&gt;
&lt;/div&gt;
&lt;div calss=&#39;anzhiyu-tag-link&#39;&gt;&lt;a class=&quot;tag-Link&quot; target=&quot;_blank&quot; href=&quot;/%5B%E4%B8%80%E3%80%81%</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十四、Flink组件搭建之Flink集群环境搭建(Local模式)(二)</title>
    <link href="https://xin0203xin0203.github.io/posts/3cc2c9ad.html"/>
    <id>https://xin0203xin0203.github.io/posts/3cc2c9ad.html</id>
    <published>2023-12-18T15:31:57.149Z</published>
    <updated>2024-12-25T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Flink的简介："><a href="#Flink的简介：" class="headerlink" title="Flink的简介："></a>Flink的简介：</h1><p>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。<br>Apache Flink的数据流编程模型在有限和无限数据集上提供单次事件（event-at-a-time）处理。在基础层面，Flink程序由流和转换组成。<br>Apache Flink的API：有界或无界数据流的数据流API、用于有界数据集的数据集API、表API。</p><h3 id="数据流的运行流程"><a href="#数据流的运行流程" class="headerlink" title="数据流的运行流程"></a>数据流的运行流程</h3><p>Flink程序在执行后被映射到流数据流，每个Flink数据流以一个或多个源（数据输入，例如消息队列或文件系统）开始，并以一个或多个接收器（数据输出，如消息队列、文件系统或数据库等）结束。Flink可以对流执行任意数量的变换，这些流可以被编排为有向无环数据流图，允许应用程序分支和合并数据流。</p><h3 id="Flink的数据源和接收器"><a href="#Flink的数据源和接收器" class="headerlink" title="Flink的数据源和接收器"></a>Flink的数据源和接收器</h3><p>Flink提供现成的源和<a href="https://baike.baidu.com/item/%E6%8E%A5%E6%94%B6%E8%BF%9E%E6%8E%A5%E5%99%A8/3533010?fromModule=lemma_inlink"><strong>接收连接器</strong></a>，包括Apache Kafka、Amazon Kinesis、HDFS和Apache Cassandra等。<br>Flink程序可以作为集群内的分布式系统运行，也可以以独立模式或在YARN、Mesos、基于Docker的环境和其他资源管理框架下进行部署。</p><h3 id="Flink的状态-state"><a href="#Flink的状态-state" class="headerlink" title="Flink的状态(state)"></a>Flink的状态(state)</h3><p>Flink检查点和容错：检查点是应用程序状态和源流中位置的自动异步快照。在发生故障的情况下，启用了检查点的Flink程序将在恢复时从上一个完成的检查点恢复处理，确保Flink在应用程序中保持一致性（exactly-once）状态语义。检查点机制暴露应用程序代码的接口，以便将外部系统包括在检查点机制中（如打开和提交数据库系统的事务）。<br>Flink保存点的机制是一种手动触发的检查点。用户可以生成保存点，停止正在运行的Flink程序，然后从流中的相同应用程序状态和位置恢复程序。 保存点可以在不丢失应用程序状态的情况下对Flink程序或Flink群集进行更新。</p><h3 id="Flink的数据流API"><a href="#Flink的数据流API" class="headerlink" title="Flink的数据流API"></a>Flink的数据流API</h3><p>Flink的数据流API支持有界或无界数据流上的转换（如过滤器、聚合和窗口函数），包含了20多种不同类型的转换，可以在Java和Scala中使用。<br>有状态流处理程序的一个简单Scala示例是从连续输入流发出字数并在5秒窗口中对数据进行分组的应用： [4] </p><h3 id="Apache-Beam"><a href="#Apache-Beam" class="headerlink" title="Apache Beam"></a>Apache Beam</h3><p>Apache Beam“提供了一种高级统一编程模型，允许（开发人员）实现可在在任何执行引擎上运行批处理和流数据处理作业”。Apache Flink-on-Beam运行器是功能最丰富的、由Beam社区维护的能力矩阵。<br>data Artisans与Apache Flink社区一起，与Beam社区密切合作，开发了一个强大的Flink runner。</p><h3 id="数据集API"><a href="#数据集API" class="headerlink" title="数据集API"></a>数据集API</h3><p>Flink的数据集API支持对有界数据集进行转换（如过滤、映射、连接和分组），包含了20多种不同类型的转换。 该API可用于Java、Scala和实验性的Python API。Flink的数据集API在概念上与数据流API类似。 [3] </p><h3 id="表API和SQL"><a href="#表API和SQL" class="headerlink" title="表API和SQL"></a>表API和SQL</h3><p>Flink的表API是一种类似SQL的表达式语言，用于关系流和批处理，可以嵌入Flink的Java和Scala数据集和数据流API中。表API和SQL接口在关系表抽象上运行，可以从外部数据源或现有数据流和数据集创建表。表API支持<a href="https://baike.baidu.com/item/%E5%85%B3%E7%B3%BB%E8%BF%90%E7%AE%97%E7%AC%A6/352774?fromModule=lemma_inlink"><strong>关系运算符</strong></a>，如表上的选择、聚合和连接等。<br>也可以使用常规SQL查询表。表API提供了和SQL相同的功能，可以在同一程序中混合使用。将表转换回数据集或数据流时，由<a href="https://baike.baidu.com/item/%E5%85%B3%E7%B3%BB%E8%BF%90%E7%AE%97%E7%AC%A6/352774?fromModule=lemma_inlink"><strong>关系运算符</strong></a>和SQL查询定义的逻辑计划将使用Apache Calcite进行优化，并转换为数据集或数据流程序。</p><div class="tip success"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%EF%BC%88%E4%B8%80%EF%BC%89Scala%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/ifi3zw34ztgm4bqt?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/25/o7fngS.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">（一）Scala环境搭建</div>            <div class="tag-link-sitename">Scala 是一门多范式（multi-paradigm）的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性。 Scala 运行在 Java 虚拟机上，并兼容现有的 Java 程序。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="tip ban"><p>需要的安装包：<strong><a href="https://archive.apache.org/dist/flink/">flink</a>压缩包——&gt;flink-1.13.0-bin-scala_2.12.tgz</strong></p></div><h2 id="1-本地启动"><a href="#1-本地启动" class="headerlink" title="1. 本地启动"></a>1. 本地启动</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf flink<span class="number">-1.13</span><span class="number">.0</span>-bin-scala_2<span class="number">.12</span>.tgz -C /opt/</span><br><span class="line">mv flink<span class="number">-1.13</span><span class="number">.0</span> flink</span><br></pre></td></tr></table></figure><h3 id="1-2-配置Flink环境变量"><a href="#1-2-配置Flink环境变量" class="headerlink" title="1.2 配置Flink环境变量"></a>1.2 配置Flink环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"># Flink</span><br><span class="line"><span class="keyword">export</span> FLINK_HOME=/opt/flink</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$FLINK_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="1-3-加载环境变量"><a href="#1-3-加载环境变量" class="headerlink" title="1.3 加载环境变量"></a>1.3 加载环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="1-4-开启Flink集群"><a href="#1-4-开启Flink集群" class="headerlink" title="1.4 开启Flink集群"></a>1.4 开启Flink集群</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">huser@master</span> <span class="string">flink</span>]<span class="string">$</span> <span class="string">bin/start-cluster.sh</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Starting cluster.</span></span><br><span class="line"><span class="string">Starting standalonesession daemon on host slave1.</span></span><br><span class="line"><span class="string">Starting taskexecutor daemon on host slave1.</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">[<span class="string">huser@master</span> <span class="string">~</span>]<span class="string">$</span> <span class="string">jps</span></span><br><span class="line"><span class="number">10369</span> <span class="string">StandaloneSessionClusterEntrypoint</span></span><br><span class="line"><span class="number">10680</span> <span class="string">TaskManagerRunner</span></span><br><span class="line"><span class="number">10717</span> <span class="string">Jps</span></span><br></pre></td></tr></table></figure><h3 id="1-5-访问-Web-UI"><a href="#1-5-访问-Web-UI" class="headerlink" title="1.5 访问 Web UI"></a>1.5 访问 Web UI</h3><p>启动成功后，访问 <a href="http://master:8081"><strong>http://master:8081</strong></a>或<a href="http://192.168.33.150:8081"><strong>http://192.168.33.150:8081</strong></a><br><img src="https://vip.helloimg.com/images/2023/12/25/o7yXuT.png" alt="image.png"></p><h3 id="1-6-关闭Flink集群"><a href="#1-6-关闭Flink集群" class="headerlink" title="1.6 关闭Flink集群"></a>1.6 关闭Flink集群</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="function">Stopping taskexecutor <span class="title">daemon</span> <span class="params">(pid: <span class="number">2901</span>)</span> on host slave1.</span></span><br><span class="line"><span class="function">Stopping standalonesession <span class="title">daemon</span> <span class="params">(pid: <span class="number">2635</span>)</span> on host slave1.</span></span><br><span class="line"><span class="function">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="2-远程集群启动"><a href="#2-远程集群启动" class="headerlink" title="2. 远程集群启动"></a>2. 远程集群启动</h1><h3 id="2-1-修改集群配置"><a href="#2-1-修改集群配置" class="headerlink" title="2.1 修改集群配置"></a>2.1 修改集群配置</h3><h4 id="2-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件"><a href="#2-1-1-进入-FLINK-HOME-conf-目录下，修改flink-conf-yaml文件" class="headerlink" title="2.1.1 进入 ${FLINK_HOME}/conf 目录下，修改flink-conf.yaml文件"></a>2.1.1 进入 <code>$&#123;FLINK_HOME&#125;/conf</code> 目录下，修改<strong>flink-conf.yaml文件</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jobmanager.rpc.address: master</span><br></pre></td></tr></table></figure><h4 id="2-1-2-修改-masters-文件，指定JobManager节点"><a href="#2-1-2-修改-masters-文件，指定JobManager节点" class="headerlink" title="2.1.2 修改 masters 文件，指定JobManager节点"></a>2.1.2 修改 <code>masters</code> 文件，指定JobManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">master:<span class="number">8081</span></span><br><span class="line">slave1:<span class="number">8081</span></span><br></pre></td></tr></table></figure><h4 id="2-1-3-修改-slaves（workers）-文件，添加TaskManager节点"><a href="#2-1-3-修改-slaves（workers）-文件，添加TaskManager节点" class="headerlink" title="2.1.3 修改 slaves（workers） 文件，添加TaskManager节点"></a>2.1.3 修改 <code>slaves（workers）</code> 文件，添加TaskManager节点</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="2-2-分发Flink给其他节点"><a href="#2-2-分发Flink给其他节点" class="headerlink" title="2.2 分发Flink给其他节点"></a>2.2 分发Flink给其他节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r $FLINK_HOME/ slave1:/opt/</span><br><span class="line">scp -r $FLINK_HOME/ slave2:/opt/</span><br></pre></td></tr></table></figure><h3 id="2-3-启动命令"><a href="#2-3-启动命令" class="headerlink" title="2.3 启动命令"></a>2.3 启动命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/start-cluster.sh</span><br></pre></td></tr></table></figure><h3 id="2-4-查看节点"><a href="#2-4-查看节点" class="headerlink" title="2.4 查看节点"></a>2.4 查看节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#jps多出:</span></span><br><span class="line"><span class="number">4658</span> StandaloneSessionClusterEntrypoint</span><br><span class="line"><span class="number">4978</span> TaskManagerRunner</span><br></pre></td></tr></table></figure><h3 id="2-5-查看开发端口IP"><a href="#2-5-查看开发端口IP" class="headerlink" title="2.5 查看开发端口IP"></a>2.5 <strong>查看开发端口IP</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">netstat -nltp</span><br><span class="line"># 注意：要用此命令，必须先下载组件</span><br><span class="line">yum install -y nc  OR  yum install -y netcat</span><br><span class="line"># 如果不行，就下载组件</span><br><span class="line">yum -y install net-tools</span><br><span class="line"><span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">(Not all processes could be identified, non-owned process info</span></span><br><span class="line"><span class="string"> will not be shown, you would have to be root to see it all.)</span></span><br><span class="line"><span class="string">Active Internet connections (only servers)</span></span><br><span class="line"><span class="string">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    </span></span><br><span class="line"><span class="string">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -                   </span></span><br><span class="line"><span class="string">tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      -                   </span></span><br><span class="line"><span class="string">tcp6       0      0 192.168.33.150:33308    :::*                    LISTEN      9630/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::34909                :::*                    LISTEN      9630/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::34273                :::*                    LISTEN      9630/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::43715                :::*                    LISTEN      9281/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::6123                 :::*                    LISTEN      9281/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::8081                 :::*                    LISTEN      9281/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 :::22                   :::*                    LISTEN      -                   </span></span><br><span class="line"><span class="string">tcp6       0      0 :::39481                :::*                    LISTEN      9281/java           </span></span><br><span class="line"><span class="string">tcp6       0      0 ::1:25                  :::*                    LISTEN      -  </span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="2-6-查看web端"><a href="#2-6-查看web端" class="headerlink" title="2.6 查看web端"></a>2.6 查看web端</h3><p>启动成功后，访问 <a href="http://master:8081"><strong>http://master:8081</strong></a>或<a href="http://192.168.33.150:8081"><strong>http://192.168.33.150:8081</strong></a><br><img src="https://vip.helloimg.com/images/2023/12/25/o7yqJ1.png" alt="image.png"></p><h3 id="2-7-关闭命令"><a href="#2-7-关闭命令" class="headerlink" title="2.7 关闭命令"></a>2.7 关闭命令</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master flink]$ bin/stop-cluster.sh</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Flink的简介：&quot;&gt;&lt;a href=&quot;#Flink的简介：&quot; class=&quot;headerlink&quot; title=&quot;Flink的简介：&quot;&gt;&lt;/a&gt;Flink的简介：&lt;/h1&gt;&lt;p&gt;Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>八、DataX组件搭建--数据迁移工具</title>
    <link href="https://xin0203xin0203.github.io/posts/28f6f62f.html"/>
    <id>https://xin0203xin0203.github.io/posts/28f6f62f.html</id>
    <published>2023-12-17T17:15:29.888Z</published>
    <updated>2024-12-18T12:45:30.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-dove modern"><p>简介： <a href="https://blog.csdn.net/weixin_46902396/article/details/121904705?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166731346816782395330610%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166731346816782395330610&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-121904705-null-null.142^v62^pc_rank_34_queryrelevant25,201^v3^control_1,213^v1^control&amp;utm_term=DataX&amp;spm=1018.2226.3001.4187"><strong>DataX</strong></a>是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。</p></div><div class="tip cogs"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note info simple"><p>需要的安装包：<a href="http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz"><strong>DataX</strong></a>包—-&gt;<strong>datax.tar.gz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf datax.tar.gz -C /opt/software/</span><br><span class="line"><span class="meta"># 这里解压出来的名字刚好是datax，所以不用改名</span></span><br></pre></td></tr></table></figure><h3 id="1-2-运行自检脚本"><a href="#1-2-运行自检脚本" class="headerlink" title="1.2 运行自检脚本"></a>1.2 运行自检脚本</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/datax.py job/job.json</span><br></pre></td></tr></table></figure><h3 id="1-3-部署datax到本地后首次执行任务报错"><a href="#1-3-部署datax到本地后首次执行任务报错" class="headerlink" title="1.3 部署datax到本地后首次执行任务报错"></a>1.3 部署datax到本地后首次执行任务报错</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-11-02 12:53:46.815 [main] WARN  ConfigParser - 插件[streamreader,streamwriter]加载失败，1s后重试... Exception:Code:[Common-00], Describe:[您提供的配置文件存在错误信息，请检查您的作业配置 .] - 配置信息错误，您提供的配置文件[/opt/datax/plugin/reader/._drdsreader/plugin.json]不存在. 请检查您的配置文件. </span></span><br><span class="line"><span class="string">2022-11-02 12:53:47.834 [main] ERROR Engine - </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">经DataX智能分析,该任务最可能的错误原因是:</span></span><br><span class="line"><span class="string">com.alibaba.datax.common.exception.DataXException: Code:[Common-00], Describe:[您提供的配置文件存在错误信息，请检查您的作业配置 .] - 配置信息错误，您提供的配置文件[/opt/datax/plugin/reader/._drdsreader/plugin.json]不存在. 请检查您的配置文件.</span></span><br><span class="line"><span class="string">at com.alibaba.datax.common.exception.DataXException.asDataXException(DataXException.java:26)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.common.util.Configuration.from(Configuration.java:95)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.util.ConfigParser.parseOnePluginConfig(ConfigParser.java:153)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.util.ConfigParser.parsePluginConfig(ConfigParser.java:125)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.util.ConfigParser.parse(ConfigParser.java:63)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.Engine.entry(Engine.java:137)</span></span><br><span class="line"><span class="string">at com.alibaba.datax.core.Engine.main(Engine.java:204)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">解决方案：</span><br><span class="line"><span class="built_in">cd</span> /plugin/reader</span><br><span class="line"><span class="built_in">rm</span> -rf  ./._*</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /plugin/writer</span><br><span class="line"><span class="built_in">rm</span> -rf  ./._*</span><br></pre></td></tr></table></figure><h2 id="2-基本使用"><a href="#2-基本使用" class="headerlink" title="2. 基本使用"></a>2. 基本使用</h2><h3 id="2-1-从stream读取数据并打印到控制台"><a href="#2-1-从stream读取数据并打印到控制台" class="headerlink" title="2.1 从stream读取数据并打印到控制台"></a>2.1 从stream读取数据并打印到控制台</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">python /opt/datax/bin/datax.py -r streamreader -w streamwriter</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">DataX</span> (DATAX-OPENSOURCE<span class="number">-3.0</span>), From Alibaba !</span><br><span class="line"><span class="built_in">Copyright</span> (C) <span class="number">2010</span><span class="number">-2017</span>, Alibaba Group. All Rights Reserved.</span><br><span class="line"></span><br><span class="line">Please refer to the streamreader document:</span><br><span class="line">     https:<span class="comment">//github.com/alibaba/DataX/blob/master/streamreader/doc/streamreader.md </span></span><br><span class="line"></span><br><span class="line">Please refer to the streamwriter document:</span><br><span class="line">     https:<span class="comment">//github.com/alibaba/DataX/blob/master/streamwriter/doc/streamwriter.md </span></span><br><span class="line"> </span><br><span class="line">Please save the following configuration as a json file <span class="keyword">and</span>  use</span><br><span class="line">     python &#123;DATAX_HOME&#125;/bin/datax.py &#123;JSON_FILE_NAME&#125;.json </span><br><span class="line">to run the job.</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;job&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;streamreader&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [], </span><br><span class="line">                        <span class="string">&quot;sliceRecordCount&quot;</span>: <span class="string">&quot;&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, </span><br><span class="line">                <span class="string">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;streamwriter&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;encoding&quot;</span>: <span class="string">&quot;&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;print&quot;</span>: <span class="literal">true</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ], </span><br><span class="line">        <span class="string">&quot;setting&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;channel&quot;</span>: <span class="string">&quot;&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="2-2-根据模板编写json文件-新建一个data目录下stream2stream-json文件"><a href="#2-2-根据模板编写json文件-新建一个data目录下stream2stream-json文件" class="headerlink" title="2.2 根据模板编写json文件,新建一个data目录下stream2stream.json文件"></a>2.2 根据模板编写json文件,新建一个data目录下stream2stream.json文件</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;job&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;streamreader&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;type&quot;</span>:<span class="string">&quot;string&quot;</span>,</span><br><span class="line">                                <span class="string">&quot;value&quot;</span>:<span class="string">&quot;xiaokang-微信公众号:小康新鲜事儿&quot;</span></span><br><span class="line">                            &#125;,</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;type&quot;</span>:<span class="string">&quot;string&quot;</span>,</span><br><span class="line">                                <span class="string">&quot;value&quot;</span>:<span class="string">&quot;你好，世界-DataX&quot;</span></span><br><span class="line">                            &#125;</span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;sliceRecordCount&quot;</span>: <span class="string">&quot;10&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, </span><br><span class="line">                <span class="string">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;streamwriter&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;encoding&quot;</span>: <span class="string">&quot;utf-8&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;print&quot;</span>: <span class="literal">true</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ], </span><br><span class="line">        <span class="string">&quot;setting&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;channel&quot;</span>: <span class="string">&quot;2&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-运行Job"><a href="#2-3-运行Job" class="headerlink" title="2.3 运行Job"></a>2.3 运行Job</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/datax/bin/datax.py data/stream2stream.json</span><br></pre></td></tr></table></figure><h2 id="3-MySQL数据导入到HDFS"><a href="#3-MySQL数据导入到HDFS" class="headerlink" title="3. MySQL数据导入到HDFS"></a>3. MySQL数据导入到HDFS</h2><h3 id="3-1-查看官方json配置模板"><a href="#3-1-查看官方json配置模板" class="headerlink" title="3.1 查看官方json配置模板"></a>3.1 查看官方json配置模板</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python /opt/datax/bin/datax.py -r mysqlreader -w hdfswriter</span><br></pre></td></tr></table></figure><h3 id="3-2-根据模板编写json文件-data目录下mysql2hdfs-json文件"><a href="#3-2-根据模板编写json文件-data目录下mysql2hdfs-json文件" class="headerlink" title="3.2 根据模板编写json文件,data目录下mysql2hdfs.json文件"></a>3.2 根据模板编写json文件,data目录下mysql2hdfs.json文件</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;job&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mysqlreader&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            <span class="string">&quot;help_keyword_id&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;name&quot;</span></span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;connection&quot;</span>: [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;jdbcUrl&quot;</span>: [</span><br><span class="line">                                    <span class="string">&quot;jdbc:mysql://192.168.33.147:3306/mysql&quot;</span></span><br><span class="line">                                ], </span><br><span class="line">                                <span class="string">&quot;table&quot;</span>: [</span><br><span class="line">                                    <span class="string">&quot;help_keyword&quot;</span></span><br><span class="line">                                ]</span><br><span class="line">                            &#125;</span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;password&quot;</span>: <span class="string">&quot;1&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;username&quot;</span>: <span class="string">&quot;root&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, </span><br><span class="line">                <span class="string">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;hdfswriter&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;name&quot;</span>:<span class="string">&quot;help_keyword_id&quot;</span>,</span><br><span class="line">                                <span class="string">&quot;type&quot;</span>:<span class="string">&quot;int&quot;</span></span><br><span class="line">                            &#125;,</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;name&quot;</span>:<span class="string">&quot;name&quot;</span>,</span><br><span class="line">                                <span class="string">&quot;type&quot;</span>:<span class="string">&quot;string&quot;</span></span><br><span class="line">                            &#125;</span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;defaultFS&quot;</span>: <span class="string">&quot;hdfs://192.168.33.147:9000&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fieldDelimiter&quot;</span>: <span class="string">&quot;|&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fileName&quot;</span>: <span class="string">&quot;keyword.txt&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fileType&quot;</span>: <span class="string">&quot;text&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/datax&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;writeMode&quot;</span>: <span class="string">&quot;append&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ], </span><br><span class="line">        <span class="string">&quot;setting&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;channel&quot;</span>: <span class="string">&quot;3&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-3-运行Job"><a href="#3-3-运行Job" class="headerlink" title="3.3 运行Job"></a>3.3 运行Job</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/datax/bin/datax.py data/mysql2hdfs.json</span><br></pre></td></tr></table></figure><h2 id="4-HDFS数据导出到MySQL"><a href="#4-HDFS数据导出到MySQL" class="headerlink" title="4. HDFS数据导出到MySQL"></a>4. HDFS数据导出到MySQL</h2><h3 id="4-1-将3-2中导入的文件重命名并在数据库创建表"><a href="#4-1-将3-2中导入的文件重命名并在数据库创建表" class="headerlink" title="4.1 将3.2中导入的文件重命名并在数据库创建表"></a>4.1 将3.2中导入的文件重命名并在数据库创建表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">mv</span> /datax/keyword.txt__4c0e0d04_e503_437a_a1e3_49db49cbaaed /datax/keyword.txt</span><br></pre></td></tr></table></figure><h3 id="4-2-创建表"><a href="#4-2-创建表" class="headerlink" title="4.2 创建表"></a>4.2 创建表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE help_keyword_from_hdfs_datax LIKE help_keyword;</span><br></pre></td></tr></table></figure><h3 id="4-3-查看官方json配置模板"><a href="#4-3-查看官方json配置模板" class="headerlink" title="4.3 查看官方json配置模板"></a>4.3 查看官方json配置模板</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python /opt/datax/bin/datax.py -r hdfsreader -w mysqlwriter</span><br></pre></td></tr></table></figure><h3 id="4-4-根据模板编写json文件，data目录下hdfs2mysql-json文件"><a href="#4-4-根据模板编写json文件，data目录下hdfs2mysql-json文件" class="headerlink" title="4.4 根据模板编写json文件，data目录下hdfs2mysql.json文件"></a>4.4 根据模板编写json文件，data目录下hdfs2mysql.json文件</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;job&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;hdfsreader&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            <span class="string">&quot;*&quot;</span></span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;defaultFS&quot;</span>: <span class="string">&quot;hdfs://192.168.33.147:9000&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;encoding&quot;</span>: <span class="string">&quot;UTF-8&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fieldDelimiter&quot;</span>: <span class="string">&quot;|&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;fileType&quot;</span>: <span class="string">&quot;text&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/datax/keyword.txt&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, </span><br><span class="line">                <span class="string">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mysqlwriter&quot;</span>, </span><br><span class="line">                    <span class="string">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;column&quot;</span>: [</span><br><span class="line">                            <span class="string">&quot;help_keyword_id&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;name&quot;</span></span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;connection&quot;</span>: [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="string">&quot;jdbcUrl&quot;</span>: <span class="string">&quot;jdbc:mysql://192.168.33.147:3306/mysql&quot;</span>, </span><br><span class="line">                                <span class="string">&quot;table&quot;</span>: [<span class="string">&quot;help_keyword_from_hdfs_datax&quot;</span>]</span><br><span class="line">                            &#125;</span><br><span class="line">                        ], </span><br><span class="line">                        <span class="string">&quot;password&quot;</span>: <span class="string">&quot;1&quot;</span>,  </span><br><span class="line">                        <span class="string">&quot;username&quot;</span>: <span class="string">&quot;root&quot;</span>, </span><br><span class="line">                        <span class="string">&quot;writeMode&quot;</span>: <span class="string">&quot;insert&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ], </span><br><span class="line">        <span class="string">&quot;setting&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;channel&quot;</span>: <span class="string">&quot;3&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-5-运行Job"><a href="#4-5-运行Job" class="headerlink" title="4.5 运行Job"></a>4.5 运行Job</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/datax/bin/datax.py data/hdfs2mysql.json</span><br></pre></td></tr></table></figure><h2 id="5-DataX-Web安装"><a href="#5-DataX-Web安装" class="headerlink" title="5. DataX Web安装"></a>5. DataX Web安装</h2><h3 id="5-1-Maven安装"><a href="#5-1-Maven安装" class="headerlink" title="5.1 Maven安装"></a>5.1 Maven安装</h3><div class="note green anzhiyufont anzhiyu-icon-dove modern"><p>简介：<strong>Maven</strong>是一个跨平台的项目管理工具。作为Apache组织的一个颇为成功的开源项目，其主要服务于基于Java平台的项目创建，依赖管理和项目信息管理。maven是Apache的顶级项目，解释为“专家，内行”，它是一个项目管理的工具，maven自身是纯java开发的，可以使用maven对java项目进行构建、依赖管理。</p></div><div class="note info simple"><p>需要的安装包：<strong>1.<a href="https://archive.apache.org/dist/maven/maven-3/">Maven</a>包—-&gt;apache-maven-3.6.3-bin.tar.gz</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>2.<a href="https://github.com/WeiYe-Jing/datax-web/archive/v-2.1.2.tar.gz">datax-web</a>包—-&gt;datax-web-v-2.1.2.tar.gz</strong></p></div><h4 id="5-1-1-准备工作"><a href="#5-1-1-准备工作" class="headerlink" title="5.1.1 准备工作"></a>5.1.1 准备工作</h4><h5 id="1-解压并改名"><a href="#1-解压并改名" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-maven-3.6.3-bin.tar.gz -C /opt/</span><br><span class="line"><span class="built_in">mv</span> apache-maven-3.6.3 maven</span><br></pre></td></tr></table></figure><h4 id="5-1-2-配置Sqoop环境变量"><a href="#5-1-2-配置Sqoop环境变量" class="headerlink" title="5.1.2 配置Sqoop环境变量"></a>5.1.2 配置Sqoop环境变量</h4><h5 id="1-配置Sqoop环境变量"><a href="#1-配置Sqoop环境变量" class="headerlink" title="1. 配置Sqoop环境变量"></a>1. 配置Sqoop环境变量</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="comment"># maven</span></span><br><span class="line"><span class="built_in">export</span> MAVEN_HOME=/opt/maven</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$MAVEN_HOME</span>/bin</span><br></pre></td></tr></table></figure><h5 id="2-加载环境变量"><a href="#2-加载环境变量" class="headerlink" title="2. 加载环境变量"></a>2. 加载环境变量</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h4 id="5-1-3-修改配置"><a href="#5-1-3-修改配置" class="headerlink" title="5.1.3 修改配置"></a>5.1.3 修改配置</h4><h5 id="1-创建本地目录"><a href="#1-创建本地目录" class="headerlink" title="1. 创建本地目录"></a>1. 创建本地目录</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/maven/maven_repository</span><br></pre></td></tr></table></figure><h5 id="2-配置setting-xml"><a href="#2-配置setting-xml" class="headerlink" title="2. 配置setting.xml"></a>2. 配置setting.xml</h5><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 配置本地仓库地址 --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">localRepository</span>&gt;</span>/opt/maven/maven_repository<span class="tag">&lt;/<span class="name">localRepository</span>&gt;</span></span></span><br><span class="line">&lt;!-- 阿里云仓库 --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>nexus-aliyun<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>Nexus aliyun<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span></span><br><span class="line">&lt;!-- <span class="title class_">Java</span>的<span class="variable constant_">JDK</span>版本 --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">profile</span>&gt;</span>    </span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>jdk-1.8<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">activation</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">activeByDefault</span>&gt;</span>true<span class="tag">&lt;/<span class="name">activeByDefault</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">jdk</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">jdk</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">activation</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">maven.compiler.compilerVersion</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maven.compiler.compilerVersion</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h4 id="5-1-4-验证"><a href="#5-1-4-验证" class="headerlink" title="5.1.4 验证"></a>5.1.4 验证</h4><h5 id="1-查看版本"><a href="#1-查看版本" class="headerlink" title="1. 查看版本"></a>1. 查看版本</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mvn -version</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Apache Maven 3.6.3 (cecedd343002696d0abb50b32b541b8a6ba2883f)</span></span><br><span class="line"><span class="string">Maven home: /opt/maven</span></span><br><span class="line"><span class="string">Java version: 1.8.0_341, vendor: Oracle Corporation, runtime: /usr/java/jdk1.8.0_341-amd64/jre</span></span><br><span class="line"><span class="string">Default locale: zh_CN, platform encoding: UTF-8</span></span><br><span class="line"><span class="string">OS name: &quot;linux&quot;, version: &quot;3.10.0-862.el7.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot;</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h5 id="2-打包jar到本地仓库（自己先准备一个jar包）"><a href="#2-打包jar到本地仓库（自己先准备一个jar包）" class="headerlink" title="2. 打包jar到本地仓库（自己先准备一个jar包）"></a>2. 打包jar到本地仓库（自己先准备一个jar包）</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mvn install:install-file -Dfile=/opt/bin/mysql-connector-java-5.1.37.jar  -DgroupId=cool.huser -DartifactId=mysql-connector -Dversion=5.1.37 -Dpackaging=jar</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">[INFO] Installing /opt/bin/mysql-connector-java-5.1.37.jar to /opt/maven/maven_repository/cool/huser/mysql-connector/5.1.37/mysql-connector-5.1.37.jar</span></span><br><span class="line"><span class="string">[INFO] Installing /tmp/mvninstall987975586380233206.pom to /opt/maven/maven_repository/cool/huser/mysql-connector/5.1.37/mysql-connector-5.1.37.pom</span></span><br><span class="line"><span class="string">[INFO] ------------------------------------------------------------------------</span></span><br><span class="line"><span class="string">[INFO] BUILD SUCCESS</span></span><br><span class="line"><span class="string">[INFO] ------------------------------------------------------------------------</span></span><br><span class="line"><span class="string">[INFO] Total time:  19.473 s</span></span><br><span class="line"><span class="string">[INFO] Finished at: 2022-11-02T15:09:33+08:00</span></span><br><span class="line"><span class="string">[INFO] -----</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="5-2-DataX-Web安装"><a href="#5-2-DataX-Web安装" class="headerlink" title="5.2 DataX Web安装"></a>5.2 DataX Web安装</h3><h4 id="5-2-1-准备工作"><a href="#5-2-1-准备工作" class="headerlink" title="5.2.1 准备工作"></a>5.2.1 准备工作</h4><h5 id="1-解压并改名-1"><a href="#1-解压并改名-1" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf datax-web-v<span class="number">-2.1</span><span class="number">.2</span>.tar.gz -C /opt/</span><br><span class="line">mv datax-web-v<span class="number">-2.1</span><span class="number">.2</span> datax-web</span><br></pre></td></tr></table></figure><h5 id="2-编译打包"><a href="#2-编译打包" class="headerlink" title="2. 编译打包"></a>2. 编译打包</h5><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">huser@master</span> <span class="string">datax-web</span>]<span class="string">$</span> <span class="string">mvn</span> <span class="string">clean</span> <span class="string">install</span></span><br><span class="line"><span class="string">‘’‘</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="attr">Reactor Summary for datax-web 2.1.2:</span></span><br><span class="line">[<span class="string">INFO</span>] </span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-web</span> <span class="string">..........................................</span> <span class="string">SUCCESS</span> [  <span class="number">2.238</span> <span class="string">s</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-rpc</span> <span class="string">..........................................</span> <span class="string">SUCCESS</span> [<span class="number">03</span><span class="string">:21</span> <span class="string">min</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-core</span> <span class="string">.........................................</span> <span class="string">SUCCESS</span> [<span class="number">03</span><span class="string">:20</span> <span class="string">min</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-admin</span> <span class="string">........................................</span> <span class="string">SUCCESS</span> [<span class="number">11</span><span class="string">:10</span> <span class="string">min</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-executor</span> <span class="string">.....................................</span> <span class="string">SUCCESS</span> [ <span class="number">13.001</span> <span class="string">s</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">datax-assembly</span> <span class="string">.....................................</span> <span class="string">SUCCESS</span> [ <span class="number">10.013</span> <span class="string">s</span>]</span><br><span class="line">[<span class="string">INFO</span>] <span class="string">------------------------------------------------------------------------</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="string">BUILD</span> <span class="string">SUCCESS</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="string">------------------------------------------------------------------------</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="attr">Total time:</span>  <span class="number">18</span><span class="string">:28</span> <span class="string">min</span></span><br><span class="line">[<span class="string">INFO</span>] <span class="attr">Finished at:</span> <span class="number">2022-11-02T15:32:04+08:00</span></span><br><span class="line">[<span class="string">INFO</span>]</span><br><span class="line"><span class="string">’‘’</span></span><br></pre></td></tr></table></figure><h4 id="5-2-2-安装部署"><a href="#5-2-2-安装部署" class="headerlink" title="5.2.2 安装部署"></a>5.2.2 安装部署</h4><h5 id="1-权限，不然不能执行"><a href="#1-权限，不然不能执行" class="headerlink" title="1. 权限，不然不能执行"></a><font color=red>1. 权限，不然不能执行</font></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> -R 777 install.sh s*</span><br></pre></td></tr></table></figure><h5 id="2-执行安装脚本"><a href="#2-执行安装脚本" class="headerlink" title="2. 执行安装脚本"></a>2. 执行安装脚本</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./install.sh</span><br><span class="line">’‘’</span><br><span class="line">出现以下界面说明DataX Web安装成功</span><br><span class="line">2022-11-02 15:45:37.890 [INFO] (108159)  Start to build directory</span><br><span class="line">2022-11-02 15:45:37.893 [INFO] (108159) Creating directory: [/opt/datax-web/modules/datax-executor/bin/../logs].</span><br><span class="line">2022-11-02 15:45:37.946 [INFO] (108159) Directory or file: [/opt/datax-web/modules/datax-executor/bin/../conf] has been exist</span><br><span class="line">2022-11-02 15:45:37.950 [INFO] (108159) Creating directory: [/opt/datax-web/modules/datax-executor/bin/../data].</span><br><span class="line">2022-11-02 15:45:37.989 [INFO] (108159) Creating directory: [/opt/datax-web/modules/datax-executor/bin/../json].</span><br><span class="line">2022-11-02 15:45:38.027 [INFO] (108078)  <span class="comment">####### Finish To Install Modules ######</span></span><br><span class="line">‘’‘</span><br></pre></td></tr></table></figure><h4 id="5-2-3-运行查看"><a href="#5-2-3-运行查看" class="headerlink" title="5.2.3 运行查看"></a>5.2.3 运行查看</h4><h5 id="1-启动datax-admin和datax-executor服务"><a href="#1-启动datax-admin和datax-executor服务" class="headerlink" title="1. 启动datax-admin和datax-executor服务"></a><strong>1. 启动datax-admin和datax-executor服务</strong></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./start-all.sh </span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-11-02 15:47:42.408 [INFO] (108231)  ####### Begin To Start Module: [datax-admin] ######</span></span><br><span class="line"><span class="string">2022-11-02 15:47:42.415 [INFO] (108239) load environment variables</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.091 [INFO] (108239) DATAX-ADMIN has been started in process</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.102 [INFO] (108396)  ####### Begin To Start Module: [datax-executor] ######</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.110 [INFO] (108404) load environment variables</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.592 [INFO] (108404) /usr/java/jdk1.8.0_341-amd64/bin/java</span></span><br><span class="line"><span class="string">2022-11-02 15:47:43.595 [INFO] (108404) Waiting DATAX-EXEXUTOR to start complete ...</span></span><br><span class="line"><span class="string">2022-11-02 15:48:06.153 [ERROR] (108223)  Start Modules [datax-executor] Failed!</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h5 id="2-查看启动是否成功"><a href="#2-查看启动是否成功" class="headerlink" title="2. 查看启动是否成功"></a>2. 查看启动是否成功</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">jps</span></span><br><span class="line"><span class="string">DataXExecutorApplication</span></span><br><span class="line"><span class="string">DataXAdminApplication</span></span><br><span class="line"><span class="string">Nailgun</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h5 id="3-WebUI查看-默认账号密码为：admin-123456"><a href="#3-WebUI查看-默认账号密码为：admin-123456" class="headerlink" title="3. WebUI查看,默认账号密码为：admin    123456"></a>3. WebUI查看,默认账号密码为：<strong>admin    123456</strong></h5><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span>huser@master bin<span class="punctuation">]</span>$ tail <span class="number">-50</span>f /opt/datax-web/modules/datax-admin/bin/console.out</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"><span class="number">16</span><span class="punctuation">:</span><span class="number">09</span><span class="punctuation">:</span><span class="number">10.035</span> admin <span class="punctuation">[</span>main<span class="punctuation">]</span> INFO  c.w.d.a.DataXAdminApplication - Access URLs<span class="punctuation">:</span></span><br><span class="line">----------------------------------------------------------</span><br><span class="line">Local-API<span class="punctuation">:</span> http<span class="punctuation">:</span><span class="comment">//127.0.0.1:9527/doc.html</span></span><br><span class="line">External-API<span class="punctuation">:</span> http<span class="punctuation">:</span><span class="comment">//192.168.33.147:9527/doc.html</span></span><br><span class="line">web-URL<span class="punctuation">:</span> http<span class="punctuation">:</span><span class="comment">//127.0.0.1:9527/index.html</span></span><br><span class="line">----------------------------------------------------------</span><br><span class="line"><span class="number">16</span><span class="punctuation">:</span><span class="number">09</span><span class="punctuation">:</span><span class="number">19.671</span> admin <span class="punctuation">[</span>http-nio<span class="number">-9527</span>-exec<span class="number">-1</span><span class="punctuation">]</span> INFO  o.a.c.c.C.<span class="punctuation">[</span>.<span class="punctuation">[</span>.<span class="punctuation">[</span>/<span class="punctuation">]</span> - Initializing Spring DispatcherServlet &#x27;dispatcherServlet&#x27;</span><br><span class="line"><span class="number">16</span><span class="punctuation">:</span><span class="number">09</span><span class="punctuation">:</span><span class="number">19.672</span> admin <span class="punctuation">[</span>http-nio<span class="number">-9527</span>-exec<span class="number">-1</span><span class="punctuation">]</span> INFO  o.s.w.s.DispatcherServlet - Initializing Servlet &#x27;dispatcherServlet&#x27;</span><br><span class="line"><span class="number">16</span><span class="punctuation">:</span><span class="number">09</span><span class="punctuation">:</span><span class="number">19.686</span> admin <span class="punctuation">[</span>http-nio<span class="number">-9527</span>-exec<span class="number">-1</span><span class="punctuation">]</span> INFO  o.s.w.s.DispatcherServlet - Completed initialization in <span class="number">14</span> ms</span><br><span class="line">&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>datax-web</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7lZ96.png" alt="datax-web" title="datax-web"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-dove modern&quot;&gt;&lt;p&gt;简介： &lt;a href=&quot;https://blog.csdn.net/weixin_46902396/article/details/121904705</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之Scala环境搭建(一)</title>
    <link href="https://xin0203xin0203.github.io/posts/411e35e9.html"/>
    <id>https://xin0203xin0203.github.io/posts/411e35e9.html</id>
    <published>2023-12-17T17:15:29.810Z</published>
    <updated>2024-12-18T15:44:44.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-inbox modern"><p>简介: 是一种多范式的编程语言，其设计的初衷是要集成面向对象编程和函数式编程的各种特性 。Scala 运 行 于Java平台（ Java 虚 拟 机 ）， 并 兼 容 现 有 的 Java 程 序 。</p></div><div class="tip error"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note success simple"><p>需要的安装包：<a href="https://www.scala-lang.org/download/2.11.12.html"><strong>Scala</strong></a>压缩包——&gt;<strong>scala-2.12.8.tgz</strong></p></div><h2 id="1-解压并改名"><a href="#1-解压并改名" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf scala<span class="number">-2.12</span><span class="number">.8</span>.tgz -C /opt/</span><br><span class="line">mv scala<span class="number">-2.12</span><span class="number">.8</span> scala</span><br></pre></td></tr></table></figure><h2 id="2-配置Scala环境变量"><a href="#2-配置Scala环境变量" class="headerlink" title="2. 配置Scala环境变量"></a>2. 配置Scala环境变量</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># scala</span></span><br><span class="line"><span class="keyword">export</span> SCALA_HOME=/opt/kafka</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/<span class="function">profile  <span class="title">slave2</span><span class="params">(slave1)</span>:/etc/profile</span></span><br></pre></td></tr></table></figure><h2 id="3-验证安装是否成功"><a href="#3-验证安装是否成功" class="headerlink" title="3. 验证安装是否成功"></a>3. 验证安装是否成功</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">scala</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Welcome to Scala 2.12.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_341).</span></span><br><span class="line"><span class="string">Type in expressions for evaluation. Or try :help.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; 11+6</span></span><br><span class="line"><span class="string">res0: Int = 17</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; 5</span></span><br><span class="line"><span class="string">res1: Int = 5</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-inbox modern&quot;&gt;&lt;p&gt;简介: 是一种多范式的编程语言，其设计的初衷是要集成面向对象编程和函数式编程的各种特性 。Scala 运 行 于Java平台（ Java 虚 拟 机 </summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之HA-Spark集群环境搭建(Yarn模式)(五)</title>
    <link href="https://xin0203xin0203.github.io/posts/924eec38.html"/>
    <id>https://xin0203xin0203.github.io/posts/924eec38.html</id>
    <published>2023-12-17T17:15:29.774Z</published>
    <updated>2024-12-18T19:24:51.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-shapes modern"><p>简介: <a href="https://so.csdn.net/so/search?q=Spark&amp;spm=1001.2101.3001.7020"><strong>Spark</strong></a>客户端直接连接Yarn，不需要额外构建Spark集群。有yarn-client和yarn-cluster两种模式，主要区别在于：Driver程序的运行节点。<br><a href="https://so.csdn.net/so/search?q=yarn&amp;spm=1001.2101.3001.7020"><strong>yarn</strong></a>-client：Driver程序运行在客户端，适用于交互、调试，希望立即看到app的输出。</p></div><div class="tip bolt"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%B8%89)Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Standalone%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/u25360462/nt1ri1/fchs9onh27cscex1?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7M9dh.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十三、Spark组件搭建之Spark集群环境搭建(Standalone模式)(三)</div>            <div class="tag-link-sitename">简介:SparkStandalone是**Master-Slaves架构的集群模式**，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E5%9B%9B)HA-Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Standalone%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/u25360462/nt1ri1/drrs4br8o8b4q51g?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MWsm.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十三、Spark组件搭建之HA-Spark集群环境搭建(Standalone模式)(四)</div>            <div class="tag-link-sitename">简介:SparkStandalone是**Master-Slaves架构的集群模式**，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-集群配置"><a href="#1-集群配置" class="headerlink" title="1. 集群配置"></a>1. 集群配置</h2><h3 id="1-1-配置spark-env-sh-SPARK-HOME-conf-目录下"><a href="#1-1-配置spark-env-sh-SPARK-HOME-conf-目录下" class="headerlink" title="1.1 配置spark-env.sh,${SPARK_HOME}/conf/目录下"></a>1.1 配置<strong>spark-env.sh</strong>,<code>$&#123;SPARK_HOME&#125;/conf/</code>目录下</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 添加:</span><br><span class="line"><span class="keyword">export</span> JAVA_HOME=/usr/java/jdk1<span class="number">.8</span><span class="number">.0</span>_341-amd64</span><br><span class="line"><span class="keyword">export</span> SCALA_HOME=/opt/scala</span><br><span class="line">YARN_CONF_DIR=/opt/hadoop/etc/hadoop</span><br><span class="line"><span class="keyword">export</span> SPARK_HISTORY_OPTS=<span class="string">&quot;-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=24 -Dspark.history.fs.logDirectory=hdfs://master:9000/spark-jobhistory&quot;</span></span><br><span class="line"><span class="keyword">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 -Dspark.deploy.zookeeper.dir=/opt/spark/data/&quot;</span></span><br></pre></td></tr></table></figure><h3 id="1-2-配置spark-defaults-conf"><a href="#1-2-配置spark-defaults-conf" class="headerlink" title="1.2 配置spark-defaults.conf"></a>1.2 <strong>配置spark-defaults.conf</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># spark.master                     spark:<span class="comment">//master:7077</span></span></span><br><span class="line">spark.master                     spark:<span class="comment">//master:7077,slave1:7077</span></span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line">spark.eventLog.dir               hdfs:<span class="comment">//master:9000/spark-jobhistory</span></span><br><span class="line">spark.yarn.historyServer.address               master:<span class="number">18080</span></span><br></pre></td></tr></table></figure><h3 id="1-3-配置workers-lt-font-color-red-gt-（如果配置，可以跳过）-lt-font-gt"><a href="#1-3-配置workers-lt-font-color-red-gt-（如果配置，可以跳过）-lt-font-gt" class="headerlink" title="1.3 配置workers&lt;/font color=red&gt;（如果配置，可以跳过）&lt;/font&gt;"></a>1.3 <strong>配置workers</strong>&lt;/font color=red&gt;（如果配置，可以跳过）&lt;/font&gt;</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-4-配置hadoop的yarn-site-xml"><a href="#1-4-配置hadoop的yarn-site-xml" class="headerlink" title="1.4 配置hadoop的yarn-site.xml"></a>1.4 <strong>配置hadoop的yarn-site.xml</strong></h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 由于测试环境的虚拟机内存太少, 防止将来任务被意外杀死, 做如下配置 --&gt;</span><br><span class="line">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是<span class="literal">true</span> --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是<span class="literal">true</span> --&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://master:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="1-5-拷贝到slave1和slave2节点"><a href="#1-5-拷贝到slave1和slave2节点" class="headerlink" title="1.5 拷贝到slave1和slave2节点"></a>1.5 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/spark/<span class="function">conf  <span class="title">slave2</span><span class="params">(slave1)</span>:/opt/spark/</span></span><br><span class="line"><span class="function">sudo scp -r /opt/hadoop/etc/hadoop/yarn-site.xml  slave2(slave1):/opt/hadoop/etc/hadoop/</span></span><br></pre></td></tr></table></figure><h2 id="2-启动群集"><a href="#2-启动群集" class="headerlink" title="2. 启动群集"></a>2. 启动群集</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ HA-spark-allstart.sh(脚本)</span><br><span class="line">-------------------------&lt;-- <span class="string">&#x27;或者&#x27;</span> --&gt;-------------------------</span><br><span class="line"><span class="comment"># 启动ha-hadoop集群</span></span><br><span class="line">[huser@master bin]$ ./startdfs.sh(脚本)</span><br><span class="line"><span class="comment"># 在master启动spark集群</span></span><br><span class="line">[huser@master sbin]$ ./start-all.sh</span><br><span class="line"><span class="comment"># 在slave1上启动备Master</span></span><br><span class="line">[huser@slave1 sbin]$ ./start-master.sh</span><br><span class="line"><span class="comment"># 在master上启动任务历史服务器</span></span><br><span class="line">[huser@master sbin]$ ./start-history-server.sh</span><br></pre></td></tr></table></figure><h2 id="3-查看集群"><a href="#3-查看集群" class="headerlink" title="3. 查看集群"></a>3. 查看集群</h2><h3 id="3-1-jps进程查看"><a href="#3-1-jps进程查看" class="headerlink" title="3.1 jps进程查看"></a>3.1 jps进程查看</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">-----------master jps--------------</span><br><span class="line"><span class="number">27136</span> Master</span><br><span class="line"><span class="number">24961</span> QuorumPeerMain</span><br><span class="line"><span class="number">25937</span> NodeManager</span><br><span class="line"><span class="number">25587</span> JournalNode</span><br><span class="line"><span class="number">27203</span> Worker</span><br><span class="line"><span class="number">26149</span> JobHistoryServer</span><br><span class="line"><span class="number">27591</span> Jps</span><br><span class="line"><span class="number">25209</span> NameNode</span><br><span class="line"><span class="number">25785</span> DFSZKFailoverController</span><br><span class="line"><span class="number">25342</span> DataNode</span><br><span class="line">-----------slave1 jps--------------</span><br><span class="line"><span class="number">14130</span> Worker</span><br><span class="line"><span class="number">14195</span> Master</span><br><span class="line"><span class="number">14307</span> Jps</span><br><span class="line"><span class="number">12982</span> DataNode</span><br><span class="line"><span class="number">13190</span> DFSZKFailoverController</span><br><span class="line"><span class="number">12791</span> QuorumPeerMain</span><br><span class="line"><span class="number">13431</span> NodeManager</span><br><span class="line"><span class="number">13085</span> JournalNode</span><br><span class="line"><span class="number">12894</span> NameNode</span><br><span class="line"><span class="number">13342</span> ResourceManager</span><br><span class="line">-----------slave2 jps--------------</span><br><span class="line"><span class="number">14016</span> ResourceManager</span><br><span class="line"><span class="number">14818</span> Jps</span><br><span class="line"><span class="number">13638</span> DFSZKFailoverController</span><br><span class="line"><span class="number">13431</span> DataNode</span><br><span class="line"><span class="number">14679</span> Worker</span><br><span class="line"><span class="number">13534</span> JournalNode</span><br><span class="line"><span class="number">14142</span> NodeManager</span><br><span class="line"><span class="number">13247</span> QuorumPeerMain</span><br><span class="line"><span class="number">13343</span> NameNode</span><br></pre></td></tr></table></figure><h3 id="3-2-Web-UI查看"><a href="#3-2-Web-UI查看" class="headerlink" title="3.2 Web UI查看"></a>3.2 Web UI查看</h3><p>查看master日志信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@master sbin]$ <span class="built_in">cat</span> /opt/spark/logs/spark-huser-org.apache.spark.deploy.master.Master-1-master.out | grep MasterWebUI</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">22/11/08 16:37:29 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://master:8081</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>通过启动日志可以看到master的MasterWebUI的端口号为8081</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MKeQ.png" alt="HA-spark--Standalone--master--MasterWebUI" title="HA-spark--Standalone--master--MasterWebUI"></p><p>查看slave1日志信息<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 sbin]$ cat /opt/spark/logs/spark-huser-org.apache.spark.deploy.master.Master<span class="number">-1</span>-slave1.out | grep MasterWebUI</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">22</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">16</span>:<span class="number">37</span>:<span class="number">39</span> INFO MasterWebUI: Bound MasterWebUI to <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>, <span class="keyword">and</span> started at http:<span class="comment">//slave1:8082</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>通过启动日志可以看到slave1的MasterWebUI的端口号为8082</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--slave1--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MUTt.png" alt="HA-spark--Standalone--slave1--MasterWebUI" title="HA-spark--Standalone--slave1--MasterWebUI"></p><p>master上的任务历史服务器端口号为18080</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7M6fC.png" alt="HA-spark--Standalone--master--HistoryServer" title="HA-spark--Standalone--master--HistoryServer"></p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BHA-Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Yarn%E6%A8%A1%E5%BC%8F)-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/qOWSgXY8y7Lk0JOELoie_Q)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MgKu.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">HA-Spark集群环境搭建(Yarn模式)</div>            <div class="tag-link-sitename">HA-Spark集群环境搭建(Yarn模式)-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="4-计算-PI"><a href="#4-计算-PI" class="headerlink" title="4. 计算 PI"></a>4. 计算 PI</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[huser@master spark]$ bin/spark-submit --master yarn --class org.apache.spark.examples.SparkPi /opt/spark/examples/jars/spark-examples_2.12-3.1.3.jar 1000</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--executor-memory 1G 指定每个executor可用内存为1G</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--total-executor-cores 8 指定所有executor使用的cpu核数为8个</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--executor-cores 2 表示每个executor使用的 cpu 的核数</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Pi is roughly 3.1415244714152446</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,024 INFO server.AbstractConnector: Stopped Spark@182b435b&#123;HTTP/1.1, (http/1.1)&#125;&#123;0.0.0.0:4040&#125;</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,059 INFO ui.SparkUI: Stopped Spark web UI at http://master:4040</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,111 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,353 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,353 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down</span></span><br><span class="line"><span class="string">2022-11-09 16:55:36,447 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,420 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,529 INFO memory.MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,530 INFO storage.BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,585 INFO storage.BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,596 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,615 INFO spark.SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,691 INFO util.ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,691 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-6860512e-a45c-4717-b9a4-5eb730761572</span></span><br><span class="line"><span class="string">2022-11-09 16:55:37,728 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-b5d11fa0-c090-4ef7-b1fb-5d8fb95e7edd</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>报错：<br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BSpark%20%E5%BC%82%E5%B8%B8%E6%80%BB%E7%BB%93%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95_%E7%81%B5%E4%BD%91666%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2%5D(https:/blog.csdn.net/onway_goahead/article/details/107688786?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-5-107688786-blog-107319283.pc_relevant_3mothn_strategy_recovery&spm=1001.2101.3001.4242.4&utm_relevant_index=7)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7M7Bo.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Spark 异常总结及解决办法</div>            <div class="tag-link-sitename">前言总结Spark开发中遇到的异常及解决办法，之前也写过几篇，之所以不再一个异常写一篇博客，是因为现在Spark</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><p>WebUI查看应用执行资源分配情况：</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone(yarn)--master--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MrFv.png" alt="HA-spark--Standalone(yarn)--master--MasterWebUI" title="HA-spark--Standalone(yarn)--master--MasterWebUI"></p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone(yarn)--slave1--yarn</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MVnE.png" alt="HA-spark--Standalone(yarn)--slave1--yarn" title="HA-spark--Standalone(yarn)--slave1--yarn"></p><p>最终计算结果如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">469</span> INFO scheduler.TaskSetManager: Finished task <span class="number">997.0</span> in stage <span class="number">0.0</span> (TID <span class="number">997</span>) in <span class="number">35</span> <span class="function">ms on <span class="title">master</span> <span class="params">(executor <span class="number">2</span>)</span> <span class="params">(<span class="number">998</span>/<span class="number">1000</span>)</span></span></span><br><span class="line"><span class="function">2022-11-09 18:<span class="number">22</span>:<span class="number">38</span>,<span class="number">469</span> INFO scheduler.TaskSetManager: Finished task <span class="number">998.0</span> in stage <span class="number">0.0</span> (TID <span class="number">998</span>) in <span class="number">21</span> ms on slave2 (executor <span class="number">1</span>) (<span class="number">999</span>/<span class="number">1000</span>)</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">500</span> INFO scheduler.TaskSetManager: Finished task <span class="number">999.0</span> in stage <span class="number">0.0</span> (TID <span class="number">999</span>) in <span class="number">36</span> ms on master (executor <span class="number">2</span>) (<span class="number">1000</span>/<span class="number">1000</span>)</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">506</span> INFO scheduler.DAGScheduler: ResultStage <span class="number">0</span> (reduce at SparkPi.scala:<span class="number">38</span>) finished in <span class="number">28.572</span> s</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">501</span> INFO cluster.YarnScheduler: Removed TaskSet <span class="number">0.0</span>, whose tasks have all completed, from pool </span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">546</span> INFO scheduler.DAGScheduler: Job <span class="number">0</span> is finished. Cancelling potential speculative or zombie tasks for this job</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">552</span> INFO cluster.YarnScheduler: Killing all running tasks in stage <span class="number">0</span>: Stage finished</span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">570</span> INFO scheduler.DAGScheduler: Job <span class="number">0</span> finished: reduce at SparkPi.scala:<span class="number">38</span>, took <span class="number">29.256770</span> s</span></span><br><span class="line"><span class="function">Pi is roughly <span class="number">3.14160799141608</span></span></span><br><span class="line"><span class="function"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">756</span> INFO server.AbstractConnector: Stopped Spark@<span class="number">182b</span>435b&#123;</span>HTTP/<span class="number">1.1</span>, (http/<span class="number">1.1</span>)&#125;&#123;<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">4040</span>&#125;</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">768</span> INFO ui.SparkUI: Stopped Spark web UI at http:<span class="comment">//master:4040</span></span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">804</span> INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">889</span> INFO cluster.YarnClientSchedulerBackend: Shutting down all executors</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">890</span> INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">38</span>,<span class="number">915</span> INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">558</span> INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">792</span> INFO memory.MemoryStore: MemoryStore cleared</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">797</span> INFO storage.BlockManager: BlockManager stopped</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">818</span> INFO storage.BlockManagerMaster: BlockManagerMaster stopped</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">830</span> INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">900</span> INFO spark.SparkContext: Successfully stopped SparkContext</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">931</span> INFO util.ShutdownHookManager: Shutdown hook called</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">932</span> INFO util.ShutdownHookManager: Deleting directory /tmp/spark<span class="number">-93</span>c34fa9-d1bb<span class="number">-4574</span>-a749<span class="number">-68424b</span>2b6b52</span><br><span class="line"><span class="number">2022</span><span class="number">-11</span><span class="number">-09</span> <span class="number">18</span>:<span class="number">22</span>:<span class="number">39</span>,<span class="number">936</span> INFO util.ShutdownHookManager: Deleting directory /tmp/spark<span class="number">-2726b</span>04f<span class="number">-7</span>a71<span class="number">-44</span>d0<span class="number">-91</span>ce-a027bb47ea76</span><br></pre></td></tr></table></figure></p><p><strong>通过slave1上YARN的8088可以查看历史任务</strong></p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone(yarn)--slave1--yarn</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MYzY.png" alt="HA-spark--Standalone(yarn)--slave1--yarn" title="HA-spark--Standalone(yarn)--slave1--yarn"></p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone(yarn)--slave1--HistoryServer</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MhB9.png" alt="HA-spark--Standalone(yarn)--slave1--HistoryServer" title="HA-spark--Standalone(yarn)--slave1--HistoryServer"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-shapes modern&quot;&gt;&lt;p&gt;简介: &lt;a href=&quot;https://so.csdn.net/so/search?q=Spark&amp;amp;spm=1001.2101.3001.</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之HA-Spark集群环境搭建(Standalone模式)(四)</title>
    <link href="https://xin0203xin0203.github.io/posts/1ec96998.html"/>
    <id>https://xin0203xin0203.github.io/posts/1ec96998.html</id>
    <published>2023-12-17T17:15:29.748Z</published>
    <updated>2024-12-14T17:48:48.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-shapes modern"><p>简介:SparkStandalone是<strong>Master-Slaves架构的集群模式</strong>，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</p><ul><li>spark的集群主要有三种运行模式<a href="https://cn.bing.com/search?q=sparkstandalone%E6%A8%A1%E5%BC%8F&amp;qs=n&amp;form=QBRE&amp;sp=-1&amp;pq=sparkstandalone%E6%A8%A1%E5%BC%8F&amp;sc=0-17&amp;sk=&amp;cvid=D98F9B81667C42C1A400D5113697851B&amp;ghsh=0&amp;ghacc=0&amp;ghpl="><strong>standalone</strong></a><strong>、</strong><a href="yarn"><strong>yarn</strong></a><strong>、</strong><a href="https://blog.csdn.net/chikoucha6215/article/details/100855233?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166784048216782417079675%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166784048216782417079675&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-100855233-null-null.142^v63^pc_rank_34_queryrelevant25,201^v3^control_1,213^v1^control&amp;utm_term=mesos&amp;spm=1018.2226.3001.4187"><strong>mesos</strong></a>，其中常被使用的是standalone和yarn</li><li>standalone模式，是spark自己实现的，它是一个资源调度<a href="https://so.csdn.net/so/search?q=%E6%A1%86%E6%9E%B6&amp;spm=1001.2101.3001.7020">框架</a>。</li><li>spark应用程序有一个Driver驱动，Driver可以运行在Client上也可以运行在master上。如果你使用spark-shell去提交job的话它会是运行在master上的，如果你使用spark-submit或者IDEA开发工具方式运行，那么它是运行在Client上的。这样我们知道了，Client的主体作用就是运行Driver。而master除了资源调度的作用还可以运行Driver。</li></ul></div><div class="tip bolt"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%B8%89)Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(Standalone%E6%A8%A1%E5%BC%8F)%5D(https:/www.yuque.com/u25360462/nt1ri1/fchs9onh27cscex1?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7M9dh.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十三、Spark组件搭建之Spark集群环境搭建(Standalone模式)(三)</div>            <div class="tag-link-sitename">简介:SparkStandalone是**Master-Slaves架构的集群模式**，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-集群配置"><a href="#1-集群配置" class="headerlink" title="1. 集群配置"></a>1. 集群配置</h2><h3 id="1-1-配置spark-env-sh-SPARK-HOME-conf-目录下"><a href="#1-1-配置spark-env-sh-SPARK-HOME-conf-目录下" class="headerlink" title="1.1 配置spark-env.sh,${SPARK_HOME}/conf/ 目录下"></a>1.1 <strong>配置spark-env.sh</strong>,<code>$&#123;SPARK_HOME&#125;/conf/</code> 目录下</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> JAVA_HOME=/usr/java/jdk1<span class="number">.8</span><span class="number">.0</span>_341-amd64</span><br><span class="line"># 添加:</span><br><span class="line"><span class="keyword">export</span> SCALA_HOME=/opt/scala</span><br><span class="line"><span class="keyword">export</span> SPARK_HISTORY_OPTS=<span class="string">&quot;-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=24 -Dspark.history.fs.logDirectory=hdfs://master:9000/spark-jobhistory&quot;</span></span><br><span class="line"><span class="keyword">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 -Dspark.deploy.zookeeper.dir=/opt/spark/data/&quot;</span></span><br></pre></td></tr></table></figure><h3 id="1-2-配置spark-defaults-conf"><a href="#1-2-配置spark-defaults-conf" class="headerlink" title="1.2 配置spark-defaults.conf"></a>1.2 <strong>配置spark-defaults.conf</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># spark.master                     spark:<span class="comment">//master:7077</span></span></span><br><span class="line">spark.master                     spark:<span class="comment">//master:7077,slave1:7077</span></span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line">spark.eventLog.dir               hdfs:<span class="comment">//master:9000/spark-jobhistory</span></span><br></pre></td></tr></table></figure><h3 id="1-3-配置workers（如果配置，可以跳过）"><a href="#1-3-配置workers（如果配置，可以跳过）" class="headerlink" title="1.3 配置workers（如果配置，可以跳过）"></a>1.3 <strong>配置workers</strong><font color=red>（如果配置，可以跳过）</font></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="1-4-拷贝到slave1和slave2节点"><a href="#1-4-拷贝到slave1和slave2节点" class="headerlink" title="1.4 拷贝到slave1和slave2节点"></a>1.4 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/spark/<span class="function">conf  <span class="title">slave2</span><span class="params">(slave1)</span>:/opt/spark/</span></span><br></pre></td></tr></table></figure><h2 id="2-启动群集"><a href="#2-启动群集" class="headerlink" title="2. 启动群集"></a>2. 启动群集</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">huser@master</span> <span class="string">bin</span>]<span class="string">$</span> <span class="string">HA-spark-allstart.sh(脚本)</span></span><br><span class="line"><span class="string">-------------------------&lt;--</span> <span class="string">&#x27;或者&#x27;</span> <span class="string">--&gt;-------------------------</span></span><br><span class="line"><span class="comment"># 启动ha-hadoop集群</span></span><br><span class="line">[<span class="string">huser@master</span> <span class="string">bin</span>]<span class="string">$</span> <span class="string">./startdfs.sh(脚本)</span></span><br><span class="line"><span class="comment"># 在master启动spark集群</span></span><br><span class="line">[<span class="string">huser@master</span> <span class="string">sbin</span>]<span class="string">$</span> <span class="string">./start-all.sh</span></span><br><span class="line"><span class="comment"># 在slave1上启动备Master</span></span><br><span class="line">[<span class="string">huser@slave1</span> <span class="string">sbin</span>]<span class="string">$</span> <span class="string">./start-master.sh</span></span><br><span class="line"><span class="comment"># 在master上启动任务历史服务器</span></span><br><span class="line">[<span class="string">huser@master</span> <span class="string">sbin</span>]<span class="string">$</span> <span class="string">./start-history-server.sh</span></span><br></pre></td></tr></table></figure><h2 id="3-查看集群"><a href="#3-查看集群" class="headerlink" title="3. 查看集群"></a>3. 查看集群</h2><h3 id="3-1-jps进程查看"><a href="#3-1-jps进程查看" class="headerlink" title="3.1 jps进程查看"></a>3.1 jps进程查看</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">-----------master jps--------------</span><br><span class="line"><span class="number">125346</span> DataNode</span><br><span class="line"><span class="number">124965</span> QuorumPeerMain</span><br><span class="line"><span class="number">125591</span> JournalNode</span><br><span class="line"><span class="number">125959</span> NodeManager</span><br><span class="line"><span class="number">126360</span> Worker</span><br><span class="line"><span class="number">126267</span> Master</span><br><span class="line"><span class="number">125213</span> NameNode</span><br><span class="line"><span class="number">126477</span> HistoryServer</span><br><span class="line"><span class="number">126541</span> Jps</span><br><span class="line"><span class="number">126172</span> JobHistoryServer</span><br><span class="line"><span class="number">125790</span> DFSZKFailoverController</span><br><span class="line">-----------slave1 jps--------------</span><br><span class="line"><span class="number">95617</span> DataNode</span><br><span class="line"><span class="number">96464</span> Worker</span><br><span class="line"><span class="number">96547</span> Master</span><br><span class="line"><span class="number">95429</span> QuorumPeerMain</span><br><span class="line"><span class="number">95957</span> ResourceManager</span><br><span class="line"><span class="number">95828</span> DFSZKFailoverController</span><br><span class="line"><span class="number">95723</span> JournalNode</span><br><span class="line"><span class="number">96619</span> Jps</span><br><span class="line"><span class="number">96042</span> NodeManager</span><br><span class="line"><span class="number">95532</span> NameNode</span><br><span class="line">-----------slave2 jps--------------</span><br><span class="line"><span class="number">92272</span> DataNode</span><br><span class="line"><span class="number">92483</span> DFSZKFailoverController</span><br><span class="line"><span class="number">93190</span> Worker</span><br><span class="line"><span class="number">92984</span> NodeManager</span><br><span class="line"><span class="number">92091</span> QuorumPeerMain</span><br><span class="line"><span class="number">92187</span> NameNode</span><br><span class="line"><span class="number">93259</span> Jps</span><br><span class="line"><span class="number">92378</span> JournalNode</span><br><span class="line"><span class="number">92860</span> ResourceManager</span><br></pre></td></tr></table></figure><h3 id="3-2-Web-UI查看"><a href="#3-2-Web-UI查看" class="headerlink" title="3.2 Web UI查看"></a>3.2 Web UI查看</h3><p>查看master日志信息<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@master sbin]$ cat /opt/spark/logs/spark-huser-org.apache.spark.deploy.master.Master<span class="number">-1</span>-master.out | grep MasterWebUI</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">22</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">16</span>:<span class="number">37</span>:<span class="number">29</span> INFO MasterWebUI: Bound MasterWebUI to <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>, <span class="keyword">and</span> started at http:<span class="comment">//master:8081</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>通过启动日志可以看到master的MasterWebUI的端口号为8081</p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MwKT.png" alt="HA-spark--Standalone--master--MasterWebUI" title="HA-spark--Standalone--master--MasterWebUI"></p><p>查看slave1日志信息<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 sbin]$ cat /opt/spark/logs/spark-huser-org.apache.spark.deploy.master.Master<span class="number">-1</span>-slave1.out | grep MasterWebUI</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">22</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">16</span>:<span class="number">37</span>:<span class="number">39</span> INFO MasterWebUI: Bound MasterWebUI to <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>, <span class="keyword">and</span> started at http:<span class="comment">//slave1:8082</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>通过启动日志可以看到slave1的MasterWebUI的端口号为8082</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--slave1--MasterWebUI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MQiK.png" alt="HA-spark--Standalone--slave1--MasterWebUI" title="HA-spark--Standalone--slave1--MasterWebUI"></p><p>master上的任务历史服务器端口号为18080</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--HistoryServer</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MNF1.png" alt="HA-spark--Standalone--master--HistoryServer" title="HA-spark--Standalone--master--HistoryServer"></p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="https://vip.helloimg.com/images/2023/12/18/o7Mpzb.jpg">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="">          <i class="anzhiyufont anzhiyu-icon-link" style=""></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">HA-Spark集群环境搭建(Standalone模式)</div>            <div class="tag-link-sitename">HA-Spark集群环境搭建(Standalone模式)-视频教程[HA-Spark集群环境搭建(Standalone模式)-视频教程](https://mp.weixin.qq.com/s/9EBu5GD_jHUoLfOL3mntvA)</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="4-计算-PI"><a href="#4-计算-PI" class="headerlink" title="4. 计算 PI"></a>4. 计算 PI</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[huser@master spark]$ bin/spark-submit --master spark://master:7077,slave1:7077,slave2:7077 --executor-memory 1G --total-executor-cores 2 --executor-cores 1 --class org.apache.spark.examples.SparkPi /opt/spark/examples/jars/spark-examples_2.12-3.1.3.jar 10000</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--executor-memory 1G 指定每个executor可用内存为1G</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--total-executor-cores 8 指定所有executor使用的cpu核数为8个</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--executor-cores 2 表示每个executor使用的 cpu 的核数</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Endpoint stopped!</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-7a0bd8da-0f5f-43a2-adeb-6c48c3169cdc</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-ba12bd46-aaa1-4b2a-9a25-111bb963027c</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>报错：<br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BSpark%20%E5%BC%82%E5%B8%B8%E6%80%BB%E7%BB%93%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95_%E7%81%B5%E4%BD%91666%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2%5D(https:/blog.csdn.net/onway_goahead/article/details/107688786?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-5-107688786-blog-107319283.pc_relevant_3mothn_strategy_recovery&spm=1001.2101.3001.4242.4&utm_relevant_index=7)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7M7Bo.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Spark 异常总结及解决办法</div>            <div class="tag-link-sitename">前言总结Spark开发中遇到的异常及解决办法，之前也写过几篇，之所以不再一个异常写一篇博客，是因为现在Spark</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><p>WebUI查看应用执行资源分配情况：</p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--master--PI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MDsD.png" alt="HA-spark--Standalone--master--PI" title="HA-spark--Standalone--master--PI"></p><font color=#425aef weight=bold style='display: flex; justify-content: center; align-items: center;'>HA-spark--Standalone--slave1--PI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MIvS.png" alt="HA-spark--Standalone--slave1--PI" title="HA-spark--Standalone--slave1--PI"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-shapes modern&quot;&gt;&lt;p&gt;简介:SparkStandalone是&lt;strong&gt;Master-Slaves架构的集群模式&lt;/strong&gt;，和大部分的Master-Slave</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之Spark集群环境搭建(Standalone模式)(三)</title>
    <link href="https://xin0203xin0203.github.io/posts/e1fbbea6.html"/>
    <id>https://xin0203xin0203.github.io/posts/e1fbbea6.html</id>
    <published>2023-12-17T17:15:29.724Z</published>
    <updated>2024-12-18T17:00:03.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-shapes modern"><p>简介:SparkStandalone是<strong>Master-Slaves架构的集群模式</strong>，和大部分的Master-Slaves结构集群类似，都存在着Master单点故障的问题。</p><ul><li>spark的集群主要有三种运行模式<a href="https://cn.bing.com/search?q=sparkstandalone%E6%A8%A1%E5%BC%8F&amp;qs=n&amp;form=QBRE&amp;sp=-1&amp;pq=sparkstandalone%E6%A8%A1%E5%BC%8F&amp;sc=0-17&amp;sk=&amp;cvid=D98F9B81667C42C1A400D5113697851B&amp;ghsh=0&amp;ghacc=0&amp;ghpl="><strong>standalone</strong></a><strong>、</strong><a href="yarn"><strong>yarn</strong></a><strong>、</strong><a href="https://blog.csdn.net/chikoucha6215/article/details/100855233?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166784048216782417079675%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166784048216782417079675&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-100855233-null-null.142^v63^pc_rank_34_queryrelevant25,201^v3^control_1,213^v1^control&amp;utm_term=mesos&amp;spm=1018.2226.3001.4187"><strong>mesos</strong></a>，其中常被使用的是standalone和yarn</li><li>standalone模式，是spark自己实现的，它是一个资源调度<a href="https://so.csdn.net/so/search?q=%E6%A1%86%E6%9E%B6&amp;spm=1001.2101.3001.7020">框架</a>。</li><li>spark应用程序有一个Driver驱动，Driver可以运行在Client上也可以运行在master上。如果你使用spark-shell去提交job的话它会是运行在master上的，如果你使用spark-submit或者IDEA开发工具方式运行，那么它是运行在Client上的。这样我们知道了，Client的主体作用就是运行Driver。而master除了资源调度的作用还可以运行Driver。</li></ul></div><div class="tip bolt"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note warning simple"><p><strong>[</strong>Spark<strong>](<a href="https://spark.apache.org/downloads.html)压缩包----&gt;spark-3.1.3-bin-hadoop3.2.tgz">https://spark.apache.org/downloads.html)压缩包----&gt;spark-3.1.3-bin-hadoop3.2.tgz</a></strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-3.1.3-bin-hadoop3.2.tgz -C /opt/</span><br><span class="line"><span class="built_in">mv</span> spark-3.1.3-bin-hadoop3.2 spark</span><br></pre></td></tr></table></figure><h2 id="2-配置Spark环境变量"><a href="#2-配置Spark环境变量" class="headerlink" title="2. 配置Spark环境变量"></a>2. 配置Spark环境变量</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># 添加：</span></span><br><span class="line"><span class="comment"># spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/opt/kafka</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/profile  slave2(slave1):/etc/profile</span><br></pre></td></tr></table></figure><h2 id="3-配置文件"><a href="#3-配置文件" class="headerlink" title="3. 配置文件"></a>3. 配置文件</h2><h3 id="3-1-配置spark-env-sh-SPARK-HOME-conf-目录下"><a href="#3-1-配置spark-env-sh-SPARK-HOME-conf-目录下" class="headerlink" title="3.1 配置spark-env.sh,${SPARK_HOME}/conf/ 目录下"></a>3.1 <strong>配置spark-env.sh</strong>,<code>$&#123;SPARK_HOME&#125;/conf/</code> 目录下</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> spark-env.sh.template spark-env.sh</span><br><span class="line"><span class="comment"># 添加:</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_341-amd64</span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/opt/scala</span><br><span class="line">SPARK_MASTER_HOST=master</span><br><span class="line"><span class="comment"># 默认端口就是7077, 可以省略不配</span></span><br><span class="line">SPARK_MASTER_PORT=7077</span><br></pre></td></tr></table></figure><h3 id="3-2-配置workers"><a href="#3-2-配置workers" class="headerlink" title="3.2 配置workers"></a>3.2 <strong>配置workers</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> workers.template workers</span><br><span class="line"><span class="comment"># 添加:</span></span><br><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="3-3-拷贝到slave1和slave2节点"><a href="#3-3-拷贝到slave1和slave2节点" class="headerlink" title="3.3 拷贝到slave1和slave2节点"></a>3.3 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/spark  slave2(slave1):/opt/</span><br></pre></td></tr></table></figure><h2 id="4-启动群集"><a href="#4-启动群集" class="headerlink" title="4. 启动群集"></a>4. 启动群集</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master sbin]$ ./start-all.sh</span><br></pre></td></tr></table></figure><h2 id="5-查看集群"><a href="#5-查看集群" class="headerlink" title="5. 查看集群"></a>5. 查看集群</h2><h3 id="5-1-jps进程查看"><a href="#5-1-jps进程查看" class="headerlink" title="5.1 jps进程查看"></a>5.1 jps进程查看</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">101990 Jps</span><br><span class="line">101944 Worker</span><br><span class="line">101870 Master</span><br></pre></td></tr></table></figure><h3 id="5-2-Web-UI查看"><a href="#5-2-Web-UI查看" class="headerlink" title="5.2 Web UI查看"></a>5.2 Web UI查看</h3><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>spark--Standalone</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MOYc.png" alt="spark--Standalone" title="spark--Standalone"></p><h2 id="6-计算-PI"><a href="#6-计算-PI" class="headerlink" title="6. 计算 PI"></a>6. 计算 PI</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[huser@master spark]$ bin/spark-submit --master spark://master:7077 --executor-memory 1G --total-executor-cores 2 --executor-cores 1 --class org.apache.spark.examples.SparkPi /opt/spark/examples/jars/spark-examples_2.12-3.1.3.jar 1000</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--executor-memory 1G 指定每个executor可用内存为1G</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--total-executor-cores 8 指定所有executor使用的cpu核数为8个</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">--executor-cores 2 表示每个executor使用的 cpu 的核数</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Endpoint stopped!</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO MemoryStore: MemoryStore cleared</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO BlockManager: BlockManager stopped</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO BlockManagerMaster: BlockManagerMaster stopped</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO SparkContext: Successfully stopped SparkContext</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Shutdown hook called</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-7a0bd8da-0f5f-43a2-adeb-6c48c3169cdc</span></span><br><span class="line"><span class="string">22/11/08 12:49:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-ba12bd46-aaa1-4b2a-9a25-111bb963027c</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>WebUI查看应用执行资源分配情况：</p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>spark--Standalone--PI</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7Mdeq.png" alt="spark--Standalone--PI" title="spark--Standalone--PI"></p><h2 id="7-配置任务历史服务器"><a href="#7-配置任务历史服务器" class="headerlink" title="7. 配置任务历史服务器"></a>7. 配置任务历史服务器</h2><p>在 Spark-shell 没有退出之前， 我们是可以看到正在执行的任务的日志情况：<font color=orange><a href="http://hadoop01:4040">http://hadoop01:4040</a></font>, 但是退出 Spark-shell 之后， 执行的所有任务记录全部丢失。所以需要配置任务的历史服务器, 方便在任何需要的时候去查看日志。</p><h3 id="7-1-配置spark-defaults-conf-进入-SPARK-HOME-conf目录下"><a href="#7-1-配置spark-defaults-conf-进入-SPARK-HOME-conf目录下" class="headerlink" title="7.1 配置spark-defaults.conf, 进入 ${SPARK_HOME}/conf目录下"></a>7.1 <strong>配置spark-defaults.conf</strong>, 进入 <code>$&#123;SPARK_HOME&#125;/conf</code>目录下</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> spark-defaults.conf.template spark-defaults.conf</span><br><span class="line">vim spark-defaults.conf</span><br><span class="line"><span class="comment"># 添加:</span></span><br><span class="line">spark.master                     spark://master:7077</span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line">spark.eventLog.<span class="built_in">dir</span>               hdfs://master:9000/directory</span><br></pre></td></tr></table></figure><h3 id="7-2-配置spark-env-sh"><a href="#7-2-配置spark-env-sh" class="headerlink" title="7.2 配置spark-env.sh"></a>7.2 <strong>配置spark-env.sh</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HISTORY_OPTS=<span class="string">&quot;-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=30 -Dspark.history.fs.logDirectory=hdfs://master:9000/spark-jobhistory&quot;</span></span><br></pre></td></tr></table></figure><h3 id="7-3-拷贝到slave1和slave2节点"><a href="#7-3-拷贝到slave1和slave2节点" class="headerlink" title="7.3 拷贝到slave1和slave2节点"></a>7.3 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/spark/conf/  slave2(slave1):/opt/spark/</span><br></pre></td></tr></table></figure><h3 id="7-4-启动"><a href="#7-4-启动" class="headerlink" title="7.4 启动"></a>7.4 启动</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./startdfs.<span class="built_in">sh</span>(脚本)  ----   启动集群</span><br><span class="line">[huser@master sbin]$ ./start-all.sh  ----   启动spark服务</span><br><span class="line">[huser@master sbin]$ ./start-history-server.sh  ----   启动spark日志</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">104222</span> HistoryServer</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="7-5-在HDFS上创建spark-jobhistory目录"><a href="#7-5-在HDFS上创建spark-jobhistory目录" class="headerlink" title="7.5 在HDFS上创建spark-jobhistory目录"></a>7.5 在HDFS上创建<code>spark-jobhistory目录</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">mkdir</span> /spark-jobhistory</span><br></pre></td></tr></table></figure><h3 id="7-6-jps进程查看"><a href="#7-6-jps进程查看" class="headerlink" title="7.6 jps进程查看"></a>7.6 jps进程查看</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./allJps.sh.sh(脚本)  ----   查看节点</span><br><span class="line">-----------master jps--------------</span><br><span class="line">109888 QuorumPeerMain</span><br><span class="line">110515 JournalNode</span><br><span class="line">110883 NodeManager</span><br><span class="line">111095 JobHistoryServer</span><br><span class="line">111990 HistoryServer</span><br><span class="line">110136 NameNode</span><br><span class="line">112139 Jps</span><br><span class="line">110714 DFSZKFailoverController</span><br><span class="line">110269 DataNode</span><br><span class="line">111405 Worker</span><br><span class="line">111279 Master</span><br><span class="line">-----------slave1 jps--------------</span><br><span class="line">90992 NameNode</span><br><span class="line">91504 NodeManager</span><br><span class="line">92483 Jps</span><br><span class="line">91077 DataNode</span><br><span class="line">90889 QuorumPeerMain</span><br><span class="line">91288 DFSZKFailoverController</span><br><span class="line">91418 ResourceManager</span><br><span class="line">92077 Worker</span><br><span class="line">91183 JournalNode</span><br><span class="line">-----------slave2 jps--------------</span><br><span class="line">86897 QuorumPeerMain</span><br><span class="line">86993 NameNode</span><br><span class="line">87185 JournalNode</span><br><span class="line">87667 ResourceManager</span><br><span class="line">88581 Jps</span><br><span class="line">87078 DataNode</span><br><span class="line">88153 Worker</span><br><span class="line">87290 DFSZKFailoverController</span><br><span class="line">87791 NodeManager</span><br></pre></td></tr></table></figure><h3 id="7-7-Web-UI查看"><a href="#7-7-Web-UI查看" class="headerlink" title="7.7 Web UI查看"></a>7.7 Web UI查看</h3><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>spark--Standalone--HistoryServer</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7Mv2r.png" alt="spark--Standalone--HistoryServer" title="spark--Standalone--HistoryServer"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-shapes modern&quot;&gt;&lt;p&gt;简介:SparkStandalone是&lt;strong&gt;Master-Slaves架构的集群模式&lt;/strong&gt;，和大部分的Master-Slave</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十三、Spark组件搭建之Spark-Local模式环境搭建(二)</title>
    <link href="https://xin0203xin0203.github.io/posts/dc6661ea.html"/>
    <id>https://xin0203xin0203.github.io/posts/dc6661ea.html</id>
    <published>2023-12-17T17:15:29.689Z</published>
    <updated>2024-12-18T16:14:01.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-history modern"><p>简介：Spark是一种<font color=red>快速、通用、可扩展的大数据分析引擎</font>，2009年诞生于加州大学伯克利分校AMPLab，2010年开源，2013年6月成为Apache孵化项目，2014年2月成为Apache顶级项目。目前，Spark生态系统已经发展成为一个包含多个子项目的集合，其中包含SparkSQL、SparkStreaming、GraphX、MLlib等子项目，Spark是基于内存计算的大数据并行计算框架。Spark基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了<font color=red>高容错性和高可伸缩性</font>，允许用户将Spark部署在大量廉价硬件之上，形成集群。Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于凤巢、大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。</p><ul><li><strong>与Hadoop的MapReduce相比，Spark基于内存的运算要快100倍以上，基于硬盘的运算也要快10倍以上。Spark实现了高效的DAG(有向无环图)执行引擎，可以通过基于内存来高效处理数据流。</strong></li><li><strong>Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。</strong></li><li><strong>Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。</strong></li><li><strong>Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。</strong></li></ul></div><div class="tip warning"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B(%E4%B8%80)Scala%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/u25360462/nt1ri1/grya7qs4bau5x7q0?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MliA.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十三、Spark组件搭建之Scala环境搭建(一)</div>            <div class="tag-link-sitename">简介: 是一种多范式的编程语言，其设计的初衷是要集成面向对象编程和函数式编程的各种特性 。Scala 运 行 于Java平台（ Java 虚 拟 机 ）， 并 兼 容 现 有 的 Java 程 序 。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note info simple"><p><a href="https://spark.apache.org/downloads.html"><strong>Spark</strong></a>压缩包——&gt;<strong>spark-3.1.3-bin-hadoop3.2.tgz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark<span class="number">-3.1</span><span class="number">.3</span>-bin-hadoop3<span class="number">.2</span>.tgz -C /opt/</span><br><span class="line">mv spark<span class="number">-3.1</span><span class="number">.3</span>-bin-hadoop3<span class="number">.2</span> spark</span><br></pre></td></tr></table></figure><h2 id="2-配置Spark环境变量"><a href="#2-配置Spark环境变量" class="headerlink" title="2. 配置Spark环境变量"></a>2. 配置Spark环境变量</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># spark</span></span><br><span class="line"><span class="keyword">export</span> SPARK_HOME=/opt/kafka</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/<span class="function">profile  <span class="title">slave2</span><span class="params">(slave1)</span>:/etc/profile</span></span><br></pre></td></tr></table></figure><h2 id="3-配置spark-env-sh-SPARK-HOME-conf-目录下"><a href="#3-配置spark-env-sh-SPARK-HOME-conf-目录下" class="headerlink" title="3. 配置spark-env.sh,${SPARK_HOME}/conf/目录下"></a>3. <strong>配置spark-env.sh</strong>,<code>$&#123;SPARK_HOME&#125;/conf/</code>目录下</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cp spark-env.sh.<span class="keyword">template</span> spark-env.sh</span><br><span class="line"># 添加:</span><br><span class="line"><span class="keyword">export</span> JAVA_HOME=/usr/java/jdk1<span class="number">.8</span><span class="number">.0</span>_341-amd64</span><br><span class="line"><span class="keyword">export</span> SCALA_HOME=/opt/scala</span><br><span class="line">SPARK_LOCAL_IP=master</span><br><span class="line">    </span><br><span class="line"># Options read when launching programs locally with</span><br><span class="line"># ./bin/run-example <span class="keyword">or</span> ./bin/spark-submit</span><br><span class="line"># - HADOOP_CONF_DIR, to point Spark towards Hadoop configuration files</span><br><span class="line"># - SPARK_PUBLIC_DNS, to set the <span class="keyword">public</span> dns name of the driver program</span><br></pre></td></tr></table></figure><h2 id="4-启动测试"><a href="#4-启动测试" class="headerlink" title="4. 启动测试"></a>4. 启动测试</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./spark-shell</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">22</span>/<span class="number">11</span>/<span class="number">08</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">59</span> WARN NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... <span class="keyword">using</span> builtin-java classes where applicable</span><br><span class="line">Using Spark<span class="number">&#x27;</span>s <span class="keyword">default</span> log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line">Setting <span class="keyword">default</span> log level to <span class="string">&quot;WARN&quot;</span>.</span><br><span class="line">To adjust logging level use sc.<span class="built_in">setLogLevel</span>(newLevel). For SparkR, <span class="function">use <span class="title">setLogLevel</span><span class="params">(newLevel)</span>.</span></span><br><span class="line"><span class="function">Spark context Web UI available at http://master:<span class="number">4040</span></span></span><br><span class="line"><span class="function">Spark context available as <span class="string">&#x27;sc&#x27;</span> (master =</span> local[*], app id = local<span class="number">-1667838916404</span>).</span><br><span class="line">Spark session available as <span class="string">&#x27;spark&#x27;</span>.</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  <span class="string">&#x27;_/</span></span><br><span class="line"><span class="string">   /___/ .__/\_,_/_/ /_/\_\   version 3.1.3</span></span><br><span class="line"><span class="string">      /_/</span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">Using Scala version 2.12.10 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_341)</span></span><br><span class="line"><span class="string">Type in expressions to have them evaluated.</span></span><br><span class="line"><span class="string">Type :help for more information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt; </span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="5-wordcount案例"><a href="#5-wordcount案例" class="headerlink" title="5. wordcount案例"></a>5. wordcount案例</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 准备一个需要统计词频的小文件，部分词频数据：</span><br><span class="line">● 支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；</span><br><span class="line">● 支持数据实时处理；</span><br><span class="line">● 能保证消息的可靠性投递；</span><br><span class="line">● 支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；</span><br><span class="line">● 高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Spark之WordCount案例实操：</span><br><span class="line">scala&gt; val result=sc.<span class="built_in">textFile</span>(<span class="string">&quot;file:///opt/spark/data/cs.txt&quot;</span>).<span class="built_in">flatMap</span>(_.<span class="built_in">split</span>(<span class="string">&quot;\t&quot;</span>)).<span class="built_in">map</span>((_,<span class="number">1</span>)).<span class="built_in">reduceByKey</span>(_ + _).collect</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">[Stage <span class="number">0</span>:&gt;                                                          (<span class="number">0</span> + <span class="number">1</span>) / </span><br><span class="line">result: Array[(String, Int)] = <span class="built_in">Array</span>((● 支持数据实时处理；,<span class="number">1</span>), (● 支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；,<span class="number">1</span>), (● 支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；,<span class="number">1</span>), (● 能保证消息的可靠性投递；,<span class="number">1</span>), (● 高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。,<span class="number">1</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>查看 Spark Web UI 界面，端口为4040：</p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>spark--wordcount</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MT50.png" alt="spark--wordcount" title="spark--wordcount"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-history modern&quot;&gt;&lt;p&gt;简介：Spark是一种&lt;font color=red&gt;快速、通用、可扩展的大数据分析引擎&lt;/font&gt;，2009年诞生于加州大学伯克利分校AMPL</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>五、HBase组件(hive模块等更新)</title>
    <link href="https://xin0203xin0203.github.io/posts/ff0c941c.html"/>
    <id>https://xin0203xin0203.github.io/posts/ff0c941c.html</id>
    <published>2023-12-17T17:15:29.673Z</published>
    <updated>2024-12-17T20:12:52.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-file-word modern"><p>介绍：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的<a href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/6608875?fromModule=lemma_inlink"><strong>分布式存储系统</strong></a>”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。</p></div><div class="tip warning"><p>前提准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%BA%8C%E3%80%81zookeeper%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/u25360462/nt1ri1/wzn655?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7LkQP.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">二、zookeeper组件搭建</div>            <div class="tag-link-sitename">介绍：Zookeeper 是一个开源的分布式协调服务，目前由 Apache 进行维护。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note success simple"><p>需要的安装包：<a href="http://archive.apache.org/dist/hbase/"><strong>HBase</strong></a>镜像——&gt;<strong>hbase-1.4.13-bin.tar.gz</strong></p></div><h1 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h1><h3 id="4-1-1-软件下载并解压"><a href="#4-1-1-软件下载并解压" class="headerlink" title="4.1.1 软件下载并解压"></a>4.1.1 软件下载并解压</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget http://archive.apache.org/dist/hbase/1.4.13/hbase-1.4.13-bin.tar.gz</span><br><span class="line">tar -zxvf hbase-1.4.13-bin.tar.gz</span><br></pre></td></tr></table></figure><h3 id="4-1-2-改名"><a href="#4-1-2-改名" class="headerlink" title="4.1.2 改名"></a>4.1.2 改名</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> hbase-1.4.13/ /opt/hbase</span><br></pre></td></tr></table></figure><h3 id="4-1-3-配置环境变量"><a href="#4-1-3-配置环境变量" class="headerlink" title="4.1.3 配置环境变量"></a>4.1.3 配置环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># HBASE_HOME</span></span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/opt/hbase</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HBASE_HOME</span>/bin</span><br></pre></td></tr></table></figure><h3 id="4-1-4-生效并查看版本"><a href="#4-1-4-生效并查看版本" class="headerlink" title="4.1.4 生效并查看版本"></a>4.1.4 生效并查看版本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line">hbase</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Usage: hbase [&lt;options&gt;] &lt;command&gt; [&lt;args&gt;]</span></span><br><span class="line"><span class="string">Options:</span></span><br><span class="line"><span class="string">  --config DIR     Configuration direction to use. Default: ./conf</span></span><br><span class="line"><span class="string">  --hosts HOSTS    Override the list in &#x27;</span>regionservers<span class="string">&#x27; file</span></span><br><span class="line"><span class="string">  --auth-as-server Authenticate to ZooKeeper using servers configuration</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Commands:</span></span><br><span class="line"><span class="string">Some commands take arguments. Pass no args or -h for usage.</span></span><br><span class="line"><span class="string">  shell           Run the HBase shell</span></span><br><span class="line"><span class="string">  hbck            Run the hbase &#x27;</span>fsck<span class="string">&#x27; tool</span></span><br><span class="line"><span class="string">  snapshot        Tool for managing snapshots</span></span><br><span class="line"><span class="string">  snapshotinfo    Tool for dumping snapshot information</span></span><br><span class="line"><span class="string">  wal             Write-ahead-log analyzer</span></span><br><span class="line"><span class="string">  hfile           Store file analyzer</span></span><br><span class="line"><span class="string">  zkcli           Run the ZooKeeper shell</span></span><br><span class="line"><span class="string">  upgrade         Upgrade hbase</span></span><br><span class="line"><span class="string">  master          Run an HBase HMaster node</span></span><br><span class="line"><span class="string">  regionserver    Run an HBase HRegionServer node</span></span><br><span class="line"><span class="string">  zookeeper       Run a Zookeeper server</span></span><br><span class="line"><span class="string">  rest            Run an HBase REST server</span></span><br><span class="line"><span class="string">  thrift          Run the HBase Thrift server</span></span><br><span class="line"><span class="string">  thrift2         Run the HBase Thrift2 server</span></span><br><span class="line"><span class="string">  clean           Run the HBase clean up script</span></span><br><span class="line"><span class="string">  classpath       Dump hbase CLASSPATH</span></span><br><span class="line"><span class="string">  mapredcp        Dump CLASSPATH entries required by mapreduce</span></span><br><span class="line"><span class="string">  pe              Run PerformanceEvaluation</span></span><br><span class="line"><span class="string">  ltt             Run LoadTestTool</span></span><br><span class="line"><span class="string">  canary          Run the Canary tool</span></span><br><span class="line"><span class="string">  hbtop           Run the HBTop tool</span></span><br><span class="line"><span class="string">  version         Print the version</span></span><br><span class="line"><span class="string">  CLASSNAME       Run the class named CLASSNAME</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="4-1-5-拷贝到slave1和slave2节点"><a href="#4-1-5-拷贝到slave1和slave2节点" class="headerlink" title="4.1.5 拷贝到slave1和slave2节点"></a>4.1.5 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/profile slave2(slave1):/etc/profile</span><br></pre></td></tr></table></figure><h1 id="2-修改配置"><a href="#2-修改配置" class="headerlink" title="2. 修改配置"></a>2. 修改配置</h1><h3 id="4-2-1-添加存储元数据文件-创建在目录-opt-hbase下"><a href="#4-2-1-添加存储元数据文件-创建在目录-opt-hbase下" class="headerlink" title="4.2.1 添加存储元数据文件,创建在目录/opt/hbase下"></a>4.2.1 添加存储元数据文件,创建在<code>目录/opt/hbase下</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> tmp zookeeper_data</span><br></pre></td></tr></table></figure><h3 id="4-2-1-目录下的-opt-hbase-conf-配置hbase-env-sh-把原基础的配置信息全去掉"><a href="#4-2-1-目录下的-opt-hbase-conf-配置hbase-env-sh-把原基础的配置信息全去掉" class="headerlink" title="4.2.1 目录下的/opt/hbase/conf, 配置hbase-env.sh,把原基础的配置信息全去掉"></a>4.2.1 目录下的<code>/opt/hbase/conf</code>, <strong>配置hbase-env.sh</strong>,把原基础的配置信息全去掉</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_341-amd64</span><br><span class="line"><span class="comment">#表示不引用hbase自带的zookeeper，用我们自己安装的</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure><h3 id="4-2-2-配置hbase-site-xml"><a href="#4-2-2-配置hbase-site-xml" class="headerlink" title="4.2.2 配置hbase-site.xml"></a>4.2.2 <strong>配置hbase-site.xml</strong></h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">    &lt;!-- 指定 <span class="title class_">HBase</span> 以分布式模式运行 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">    &lt;!-- 指定 <span class="title class_">HBase</span> 数据存储路径为 <span class="variable constant_">HDFS</span> 上的 hbase 目录,hbase 目录不需要预先创建，程序会自动创</span><br><span class="line">建 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hacluster/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">    &lt;!-- <span class="title class_">HBase</span>临时数据存储目录 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hbase/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">    &lt;!-- 指定 zookeeper 地址和端口 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:2181,slave1:2181,slave2:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">    &lt;!-- zookeeper数据存放位置 --&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hbase/zookeeper_data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="4-2-3-配置regionservers服务器列表"><a href="#4-2-3-配置regionservers服务器列表" class="headerlink" title="4.2.3 配置regionservers服务器列表"></a>4.2.3 <strong>配置regionservers服务器列表</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h3 id="4-2-4-链接hdfs配置"><a href="#4-2-4-链接hdfs配置" class="headerlink" title="4.2.4 链接hdfs配置"></a>4.2.4 <strong>链接hdfs配置</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s <span class="variable">$HADOOP_HOME</span>/etc/hadoop/core-site.xml /opt/hbase/conf/core-site.xml</span><br><span class="line"><span class="built_in">ln</span> -s <span class="variable">$HADOOP_HOME</span>/etc/hadoop/hdfs-site.xml /opt/hbase/conf/hdfs-site.xml</span><br></pre></td></tr></table></figure><h3 id="4-2-5-拷贝到slave1和slave2节点"><a href="#4-2-5-拷贝到slave1和slave2节点" class="headerlink" title="4.2.5 拷贝到slave1和slave2节点"></a>4.2.5 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /opt/hbase/ slave1(slave2):/opt/</span><br></pre></td></tr></table></figure><h3 id="4-2-6-如果出现权限不够，因为拷贝文件的用户是root，要修改huser用户"><a href="#4-2-6-如果出现权限不够，因为拷贝文件的用户是root，要修改huser用户" class="headerlink" title="4.2.6 如果出现权限不够，因为拷贝文件的用户是root，要修改huser用户"></a>4.2.6 如果出现权限不够，因为拷贝文件的用户是root，要修改huser用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 opt]$ sudo <span class="built_in">chown</span> -R huser:huser hbase/</span><br><span class="line">[huser@slave2 opt]$ sudo <span class="built_in">chown</span> -R huser:huser hbase/</span><br></pre></td></tr></table></figure><h1 id="3-启动HBase"><a href="#3-启动HBase" class="headerlink" title="3. 启动HBase"></a>3. 启动HBase</h1><h3 id="4-3-1-执行启动，三台机一起启动"><a href="#4-3-1-执行启动，三台机一起启动" class="headerlink" title="4.3.1 执行启动，三台机一起启动"></a>4.3.1 执行启动，三台机一起启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 必须先开集群</span></span><br><span class="line">start-hbase.sh</span><br><span class="line"><span class="comment"># 关闭HBase</span></span><br><span class="line">stop-hbase.sh</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">节点：HMaster</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>端口号为: 16010 三台机都有</p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>hbase--HRegionServer--master</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7bQgT.png" alt="hbase--HRegionServer--master" title="hbase--HRegionServer--master"></p><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>hbase--HRegionServer--slave1</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7bza1.png" alt="hbase--HRegionServer--slave1" title="hbase--HRegionServer--slave1"></p><h1 id="4-Hive与Hbase整合"><a href="#4-Hive与Hbase整合" class="headerlink" title="4. Hive与Hbase整合"></a>4. Hive与Hbase整合</h1><font color=red>有需求，反馈更新</font>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-file-word modern&quot;&gt;&lt;p&gt;介绍：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>四、tez引擎组件</title>
    <link href="https://xin0203xin0203.github.io/posts/6e1f6090.html"/>
    <id>https://xin0203xin0203.github.io/posts/6e1f6090.html</id>
    <published>2023-12-17T17:15:29.647Z</published>
    <updated>2024-12-17T17:40:40.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-dice modern"><p>简介：Tez采用了DAG（<a href="https://so.csdn.net/so/search?q=%E6%9C%89%E5%90%91%E6%97%A0%E7%8E%AF%E5%9B%BE&amp;spm=1001.2101.3001.7020"><strong>有向无环图</strong></a>）来组织MR任务（DAG中一个节点就是一个RDD，边表示对RDD的操作）。它的核心思想是把将Map任务和Reduce任务进一步拆分，Map任务拆分为Input-Processor-Sort-Merge-Output，Reduce任务拆分为Input-Shuffer-Sort-Merge-Process-output，Tez将若干小任务灵活重组，形成一个大的DAG作业。</p></div><div class="tip "><p>前提准备：</p></div><div class="note success simple"><p>需要的安装包：<a href="https://pan.baidu.com/s/1PePN7BXvQGheJxqT5bYYjQ#list/path=%2F"><strong>tez</strong></a>压缩包(提取码：i9yb)——&gt;<strong><em>tez-0.10.1-SNAPSHOT-minimal.tar.gz</em></strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;  <strong><em>tez-0.10.1-SNAPSHOT.tar.gz</em></strong></p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%89%E3%80%81Hive%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA--%3E%E5%86%85%E5%90%ABMySQL%E5%AE%89%E8%A3%85%5D(https:/www.yuque.com/u25360462/nt1ri1/zamxgf?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bvhc.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">三、Hive组件搭建-->内含MySQL安装</div>            <div class="tag-link-sitename">Hive：由Facebook开源用于解决海量结构化日志的数据统计。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1.准备工作"></a>1.准备工作</h2><h3 id="1-1-上传并解压"><a href="#1-1-上传并解压" class="headerlink" title="1.1 上传并解压"></a>1.1 上传并解压</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/tez</span><br><span class="line">tar -zxvf /opt/software/tez-0.10.1-SNAPSHOT-minimal.tar.gz -C /opt/tez</span><br></pre></td></tr></table></figure><h3 id="1-2-上传至HDFS，存放tez依赖包"><a href="#1-2-上传至HDFS，存放tez依赖包" class="headerlink" title="1.2  上传至HDFS，存放tez依赖包"></a>1.2  上传至HDFS，存放tez依赖包</h3><font color=red size=3px weight=bold>注意: 要开集群</font><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">mkdir</span> /tez</span><br><span class="line">hdfs dfs -put /opt/tez-0.10.1-SNAPSHOT.tar.gz /tez</span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>hive--tez引擎--存放tez依赖包</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7b0xq.png" alt="hive--tez引擎--存放tez依赖包" title="hive--tez引擎--存放tez依赖包"></p><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BHive%E5%AE%89%E8%A3%85%20Tez%20%E5%BC%95%E6%93%8E_%E6%89%9B%E9%BA%BB%E8%A2%8B%E7%9A%84%E5%B0%91%E5%B9%B4%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2_hive%20tez%5D(https:/blog.csdn.net/lzb348110175/article/details/117817055?app_version=5.10.0&code=app_1562916241&csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22117817055%22,%22source%22:%22qq672596289%22%7D&uLinkId=usr1mkqgl919blen&utm_source=app)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bNWr.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Hive安装 Tez</div>            <div class="tag-link-sitename">Hive安装 Tez 引擎_扛麻袋的少年的博客-CSDN博客_hive tez</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BHive%E6%9B%B4%E6%8D%A2Tez%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/BRz4uiogyMT4xta9N6IygA)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bNWr.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Hive更换Tez计算引擎</div>            <div class="tag-link-sitename">Hive更换Tez计算引擎-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="2-修改配置"><a href="#2-修改配置" class="headerlink" title="2.修改配置"></a>2.修改配置</h2><h3 id="2-1-新建-tez-site-xml"><a href="#2-1-新建-tez-site-xml" class="headerlink" title="2.1 新建 tez-site.xml"></a>2.1 新建 <code>tez-site.xml</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="variable">$HADOOP_HOME</span>/etc/hadoop/tez-site.xml</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.lib.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;fs.defaultFS&#125;/tez/tez-0.10.1-SNAPSHOT.tar.gz<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.use.cluster.hadoop-libs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.am.resource.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.am.resource.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.container.max.java.heap.fraction<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.task.resource.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.task.resource.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="2-2-修改-Hadoop-环境变量"><a href="#2-2-修改-Hadoop-环境变量" class="headerlink" title="2.2 修改 Hadoop 环境变量"></a>2.2 <strong>修改 Hadoop 环境变量</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="variable">$HADOOP_HOME</span>/etc/hadoop/shellprofile.d/tez.sh</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hadoop_add_profile tez</span><br><span class="line"><span class="keyword">function</span> _tez_hadoop_classpath</span><br><span class="line">&#123;</span><br><span class="line"> hadoop_add_classpath <span class="string">&quot;<span class="variable">$HADOOP_HOME</span>/etc/hadoop&quot;</span> after</span><br><span class="line"> hadoop_add_classpath <span class="string">&quot;/opt/tez/*&quot;</span> after</span><br><span class="line"> hadoop_add_classpath <span class="string">&quot;/opt/tez/lib/*&quot;</span> after</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-修改-Hive-的计算引擎"><a href="#2-3-修改-Hive-的计算引擎" class="headerlink" title="2.3 修改 Hive 的计算引擎"></a>2.3 <strong>修改 Hive 的计算引擎</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="variable">$HIVE_HOME</span>/conf/hive-site.xml</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.execution.engine<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">value</span>&gt;</span>tez<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line">&lt;/property&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.tez.container.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="2-4-解决日志-Jar-包冲突"><a href="#2-4-解决日志-Jar-包冲突" class="headerlink" title="2.4 解决日志 Jar 包冲突"></a>2.4 解决日志 Jar 包冲突</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf /opt/tez/slf4j-log4j12-1.7.10.jar</span><br></pre></td></tr></table></figure><h2 id="3-测试"><a href="#3-测试" class="headerlink" title="3.测试"></a>3.测试</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Hive时，要启动集群</span></span><br><span class="line">[<span class="string">huser@master</span> <span class="string">~</span>]<span class="string">$</span> <span class="string">hive</span></span><br><span class="line"><span class="comment"># 创建一张测试表</span></span><br><span class="line"><span class="string">hive</span> <span class="string">(default)&gt;</span> <span class="string">create</span> <span class="string">table</span> <span class="string">ods_user(id</span> <span class="string">int,name</span> <span class="string">string);</span></span><br><span class="line"><span class="comment"># 插入数据</span></span><br><span class="line"><span class="string">hive</span> <span class="string">(default)&gt;</span> <span class="string">insert</span> <span class="string">into</span> <span class="string">ods_user</span> <span class="string">values(1,&quot;root&quot;);</span></span><br><span class="line"><span class="comment"># 验证数据是否插入成功</span></span><br><span class="line"><span class="string">hive</span> <span class="string">(default)&gt;</span> <span class="string">select</span> <span class="string">*</span> <span class="string">from</span> <span class="string">ods_user;</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">ods_user.id</span>    <span class="string">ods_user.name</span></span><br><span class="line"><span class="number">1</span>    <span class="string">xiaokang</span></span><br><span class="line"><span class="attr">Time taken:</span> <span class="number">0.301</span> <span class="string">seconds,</span> <span class="attr">Fetched:</span> <span class="number">1</span> <span class="string">row(s)</span></span><br></pre></td></tr></table></figure><h2 id="4-报错解决"><a href="#4-报错解决" class="headerlink" title="4. 报错解决"></a>4. 报错解决</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">hive&gt;</span> <span class="string">insert</span> <span class="string">into</span> <span class="string">test</span> <span class="string">values(1);</span></span><br><span class="line"><span class="string">Query</span> <span class="string">ID</span> <span class="string">=</span> <span class="string">huser_20221130013916_16e5ccf9-5b68-48bb-a967-287dabf447fa</span></span><br><span class="line"><span class="string">Total</span> <span class="string">jobs</span> <span class="string">=</span> <span class="number">1</span></span><br><span class="line"><span class="string">Launching</span> <span class="string">Job</span> <span class="number">1</span> <span class="string">out</span> <span class="string">of</span> <span class="number">1</span></span><br><span class="line"><span class="attr">FAILED:</span> <span class="string">Execution</span> <span class="string">Error,</span> <span class="string">return</span> <span class="string">code</span> <span class="number">1</span> <span class="string">from</span> <span class="string">org.apache.hadoop.hive.ql.exec.tez.TezTask</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>尝试添加<code>/opt/hadoop/etc/hadoop目录</code>下的<code>yarn-site.xml文件</code>配置<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">　　    <span class="language-xml"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line">　　    <span class="language-xml"><span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line">&lt;/property&gt;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">　　    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">　　    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-dice modern&quot;&gt;&lt;p&gt;简介：Tez采用了DAG（&lt;a href=&quot;https://so.csdn.net/so/search?q=%E6%9C%89%E5%90%91%E6%</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十一、Flume组件搭建--_日志收集</title>
    <link href="https://xin0203xin0203.github.io/posts/1c48292.html"/>
    <id>https://xin0203xin0203.github.io/posts/1c48292.html</id>
    <published>2023-12-17T17:15:29.627Z</published>
    <updated>2024-12-18T13:22:23.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-circle-half-stroke modern"><p>简介：<font color=red>Apache Flume</font>  是 Cloudera 公司开发，是一个分布式的、高可靠的、高可用的用于海量日志收集、聚合和传输的系统。它可以从不同的数据源收集数据，经过聚合后发送到存储系统中，通常用于日志数据的收集。Flume 分为 NG 和 OG (1.0 之前) 两个版本，NG 在 OG 的基础上进行了完全的重构，是目前使用最为广泛的版本。下面的介绍均以 NG 为基础。</p></div><div class="tip info"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note default simple"><p>需要的安装包：<a href="http://archive.apache.org/dist/flume/"><strong>flume</strong></a>压缩包——&gt;<strong>apache-flume-1.7.0-bin.tar.gz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-flume<span class="number">-1.9</span><span class="number">.0</span>-bin.tar.gz -C /opt/</span><br><span class="line">mv apache-flume<span class="number">-1.9</span><span class="number">.0</span> flume</span><br></pre></td></tr></table></figure><h2 id="2-配置flume环境变量"><a href="#2-配置flume环境变量" class="headerlink" title="2. 配置flume环境变量"></a>2. 配置flume环境变量</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># flume</span></span><br><span class="line"><span class="keyword">export</span> FLUME_HOME=/opt/flume</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$FLUME_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/profile  slave2(slave1):/etc/profile</span><br></pre></td></tr></table></figure><h2 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h2><h3 id="3-1-进入安装目录下的-conf目录，拷贝-Flume-的环境配置模板-flume-env-sh-template"><a href="#3-1-进入安装目录下的-conf目录，拷贝-Flume-的环境配置模板-flume-env-sh-template" class="headerlink" title="3.1 进入安装目录下的 conf目录，拷贝 Flume 的环境配置模板 flume-env.sh.template"></a>3.1 进入安装目录下的 <code>conf目录</code>，拷贝 <strong>Flume</strong> 的环境配置模板 <strong>flume-env.sh.template</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp flume-env.sh.<span class="keyword">template</span> flume-env.sh</span><br></pre></td></tr></table></figure><h3 id="3-2-配置flume-env-sh"><a href="#3-2-配置flume-env-sh" class="headerlink" title="3.2 配置flume-env.sh"></a>3.2 <strong>配置flume-env.sh</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> JAVA_HOME=/usr/java/jdk1<span class="number">.8</span><span class="number">.0</span>_341-amd64</span><br></pre></td></tr></table></figure><h2 id="4-验证"><a href="#4-验证" class="headerlink" title="4. 验证"></a>4. 验证</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">flume-ng version</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Flume 1.9.0</span></span><br><span class="line"><span class="string">Source code repository: https://git-wip-us.apache.org/repos/asf/flume.git</span></span><br><span class="line"><span class="string">Revision: d4fcab4f501d41597bc616921329a4339f73585e</span></span><br><span class="line"><span class="string">Compiled by fszabo on Mon Dec 17 20:45:25 CET 2018</span></span><br><span class="line"><span class="string">From source with checksum 35db629a3bda49d23e9b3690c80737f9</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BFlume%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/FtkDp8qwVxl85DXL9wEQ2Q)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MAYP.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Flume安装及基本使用</div>            <div class="tag-link-sitename">Flume安装及基本使用-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="5-基本使用"><a href="#5-基本使用" class="headerlink" title="5. 基本使用"></a>5. 基本使用</h2><h3 id="5-1-新建配置文件telnet-logger-properties"><a href="#5-1-新建配置文件telnet-logger-properties" class="headerlink" title="5.1 新建配置文件telnet-logger.properties"></a>5.1 新建配置文件<strong>telnet-logger.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources、channels、sinks</span></span><br><span class="line"><span class="string">a1.sources</span> <span class="string">=</span> <span class="string">s1</span></span><br><span class="line"><span class="string">a1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">a1.sinks</span> <span class="string">=</span> <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置source属性</span></span><br><span class="line"><span class="string">a1.sources.s1.type</span> <span class="string">=</span> <span class="string">netcat</span></span><br><span class="line"><span class="string">a1.sources.s1.bind</span> <span class="string">=</span> <span class="string">master</span></span><br><span class="line"><span class="string">a1.sources.s1.port</span> <span class="string">=</span> <span class="number">44444</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line"><span class="string">a1.channels.c1.type</span> <span class="string">=</span> <span class="string">memory</span></span><br><span class="line"><span class="string">a1.channels.c1.capacity</span> <span class="string">=</span> <span class="number">10000</span></span><br><span class="line"><span class="string">a1.channels.c1.transactionCapacity</span> <span class="string">=</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line"><span class="string">a1.sinks.k1.type</span> <span class="string">=</span> <span class="string">logger</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources和channels绑定</span></span><br><span class="line"><span class="string">a1.sources.s1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks和channels绑定</span></span><br><span class="line"><span class="string">a1.sinks.k1.channel</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">NetCat Source ：监听一个指定端口，并接收监听到的数据（接收的数据是字符串形式）。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">NetCat Source 配置项说明:</span></span><br><span class="line"><span class="string">channels    |   绑定的通道</span></span><br><span class="line"><span class="string">    type    |   netcat</span></span><br><span class="line"><span class="string">    bind    |   指定要监听的主机</span></span><br><span class="line"><span class="string">    port    |   指定要监听的端口号</span></span><br><span class="line"><span class="string">    selector.*    |   选择器配置</span></span><br><span class="line"><span class="string">    interceptors.*    |   拦截器列表配置</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://vip.helloimg.com/images/2023/12/18/o7Mi2n.png" alt=""></p><h3 id="5-2-启动"><a href="#5-2-启动" class="headerlink" title="5.2 启动"></a>5.2 启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -n a1 -c /opt/flume/conf/ -f conf/telnet-logger.properties -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">SLF4J: Class path contains multiple SLF4J bindings.</span></span><br><span class="line"><span class="string">SLF4J: Found binding in [jar:file:/opt/flume/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span></span><br><span class="line"><span class="string">SLF4J: Found binding in [jar:file:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span></span><br><span class="line"><span class="string">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span></span><br><span class="line"><span class="string">SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</span></span><br><span class="line"><span class="string">2022-11-05 17:40:48,862 (main) [ERROR - org.apache.flume.node.Application.main(Application.java:374)] A fatal error occurred while running. Exception follows.</span></span><br><span class="line"><span class="string">org.apache.commons.cli.ParseException: The specified configuration file does not exist: /opt/bin/telnet-logger.properties</span></span><br><span class="line"><span class="string">at org.apache.flume.node.Application.main(Application.java:342)</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">删掉一个jar包/opt/flume/lib/slf4j-log4j12-1.7.25.jar</span><br></pre></td></tr></table></figure><h3 id="5-3-测试"><a href="#5-3-测试" class="headerlink" title="5.3 测试"></a>5.3 测试</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">第一种：</span></span><br><span class="line"><span class="string">telnet</span> <span class="string">master</span> <span class="number">44444</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="string">证明成功，如果是下面一种，则按下面来:</span></span><br><span class="line">    </span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;bash: telnet: 未找到命令&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#解决方案：使用yum命令安装即可</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">yum</span> <span class="string">-y</span> <span class="string">install</span> <span class="string">telnet</span></span><br><span class="line"><span class="string">第二种：</span></span><br><span class="line"><span class="string">nc</span> <span class="string">master</span> <span class="number">44444</span></span><br><span class="line"><span class="comment"># sudo yum -y install nc</span></span><br></pre></td></tr></table></figure><h2 id="6-官方案例一"><a href="#6-官方案例一" class="headerlink" title="6. 官方案例一"></a>6. 官方案例一</h2><h3 id="6-1-新建配置文件execsource-properties"><a href="#6-1-新建配置文件execsource-properties" class="headerlink" title="6.1  新建配置文件execsource.properties"></a>6.1  新建配置文件<strong>execsource.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources、channels、sinks</span></span><br><span class="line"><span class="string">a1.sources</span> <span class="string">=</span> <span class="string">s1</span></span><br><span class="line"><span class="string">a1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">a1.sinks</span> <span class="string">=</span> <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置source属性 </span></span><br><span class="line"><span class="string">a1.sources.s1.type</span> <span class="string">=</span> <span class="string">exec</span></span><br><span class="line"><span class="string">a1.sources.s1.command</span> <span class="string">=</span> <span class="string">tail</span> <span class="string">-f</span> <span class="string">/opt/flume/data/log.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型 </span></span><br><span class="line"><span class="string">a1.channels.c1.type</span> <span class="string">=</span> <span class="string">memory</span></span><br><span class="line"><span class="string">a1.channels.c1.capacity</span> <span class="string">=</span> <span class="number">10000</span></span><br><span class="line"><span class="string">a1.channels.c1.transactionCapacity</span> <span class="string">=</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line"><span class="string">a1.sinks.k1.type</span> <span class="string">=</span> <span class="string">logger</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources和channels绑定</span></span><br><span class="line"><span class="string">a1.sources.s1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks和channels绑定</span></span><br><span class="line"><span class="string">a1.sinks.k1.channel</span> <span class="string">=</span> <span class="string">c1</span></span><br></pre></td></tr></table></figure><h3 id="6-2-启动"><a href="#6-2-启动" class="headerlink" title="6.2 启动"></a>6.2 启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -n a1 -c /opt/flume/conf/ -f conf/execsource.properties -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><h3 id="6-3-测试"><a href="#6-3-测试" class="headerlink" title="6.3 测试"></a>6.3 测试</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> /opt/flume/data/log.txt</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">sdgfsdfg</span></span><br><span class="line"><span class="string">sdgfsdfg</span></span><br><span class="line"><span class="string">sdgfsdfg</span></span><br><span class="line"><span class="string">sdgfsdfg</span></span><br><span class="line"><span class="string">sdgfsdfgkldfjgkldj</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>使用 Flume 监听文件内容变动，将新添的内容输出到控制台</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MSX6.png" alt="使用 Flume 监听文件内容变动，将新添的内容输出到控制台" title="使用 Flume 监听文件内容变动，将新添的内容输出到控制台"></p><h2 id="7-官方案例二"><a href="#7-官方案例二" class="headerlink" title="7. 官方案例二"></a>7. 官方案例二</h2><h3 id="7-1-新建配置文件xinexecsource-properties"><a href="#7-1-新建配置文件xinexecsource-properties" class="headerlink" title="7.1 新建配置文件xinexecsource.properties"></a>7.1 新建配置文件<strong>xinexecsource.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources、channels、sinks</span></span><br><span class="line"><span class="string">a1.sources</span> <span class="string">=</span> <span class="string">s1</span></span><br><span class="line"><span class="string">a1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">a1.sinks</span> <span class="string">=</span> <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置source属性</span></span><br><span class="line"><span class="string">a1.sources.s1.type</span> <span class="string">=</span> <span class="string">spooldir</span></span><br><span class="line"><span class="string">a1.sources.s1.spoolDir</span> <span class="string">=</span> <span class="string">/opt/flume/data/</span></span><br><span class="line"><span class="string">a1.sources.s1.basenameHeader</span> <span class="string">=</span> <span class="literal">true</span></span><br><span class="line"><span class="string">a1.sources.s1.basenameHeaderKey</span> <span class="string">=</span> <span class="string">fileName</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line"><span class="string">a1.channels.c1.type</span> <span class="string">=</span> <span class="string">memory</span></span><br><span class="line"><span class="string">a1.channels.c1.capacity</span> <span class="string">=</span> <span class="number">10000</span></span><br><span class="line"><span class="string">a1.channels.c1.transactionCapacity</span> <span class="string">=</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line"><span class="string">a1.sinks.k1.type</span> <span class="string">=</span> <span class="string">hdfs</span></span><br><span class="line"><span class="string">a1.sinks.k1.hdfs.path</span> <span class="string">=</span> <span class="string">/flume/%y-%m-%d/%H/</span></span><br><span class="line"><span class="string">a1.sinks.k1.hdfs.filePrefix</span> <span class="string">=</span> <span class="string">%&#123;fileName&#125;</span></span><br><span class="line"><span class="comment">#生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本</span></span><br><span class="line"><span class="string">a1.sinks.k1.hdfs.fileType</span> <span class="string">=</span> <span class="string">DataStream</span></span><br><span class="line"><span class="string">a1.sinks.k1.hdfs.useLocalTimeStamp</span> <span class="string">=</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources和channels绑定</span></span><br><span class="line"><span class="string">a1.sources.s1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks和channels绑定</span></span><br><span class="line"><span class="string">a1.sinks.k1.channel</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Spooling Directory Source 配置项说明:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">channels    |   绑定的通道</span></span><br><span class="line"><span class="string">type    |   spooldir</span></span><br><span class="line"><span class="string">spoolDir    |   读取文件的路径，即“搜集目录”</span></span><br><span class="line"><span class="string">【selector.*    |   选择器配置】</span></span><br><span class="line"><span class="string">【interceptors.*    |   拦截器列表配置】</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="7-2-启动"><a href="#7-2-启动" class="headerlink" title="7.2 启动"></a>7.2 启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -n a1 -c /opt/flume/conf/ -f conf/xinexecsource.properties -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><h3 id="7-3-测试"><a href="#7-3-测试" class="headerlink" title="7.3 测试"></a>7.3 测试</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> 1.txt /opt/flume/data</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">2022-11-07 22:33:57,624 (hdfs-k1-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:393)] Writer callback called.</span></span><br><span class="line"><span class="string">2022-11-07 22:33:57,624 (hdfs-k1-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.doClose(BucketWriter.java:438)] Closing /flume/22-11-07/22//1.txt.1667831605570.tmp</span></span><br><span class="line"><span class="string">2022-11-07 22:33:57,681 (hdfs-k1-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$7.call(BucketWriter.java:681)] Renaming /flume/22-11-07/22/1.txt.1667831605570.tmp to /flume/22-11-07/22/1.txt.1667831605570</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><font color=red size=3px weight=bold>查看上传到 **HDFS** 上的文件内容与本地是否一致：</font><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">cat</span> /flume/22-11-07/22//1.txt.1667831605570.tmp</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">jdaljfaj</span></span><br><span class="line"><span class="string">ajlf;ajfa</span></span><br><span class="line"><span class="string">af;jfa;jfa</span></span><br><span class="line"><span class="string">faj;fja;</span></span><br><span class="line"><span class="string">afjfewjf;q</span></span><br><span class="line"><span class="string">[efjqa;f</span></span><br><span class="line"><span class="string">qafael;f</span></span><br><span class="line"><span class="string">an</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>flume--hdfs</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7M4dM.png" alt="flume--hdfs" title="flume--hdfs"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-circle-half-stroke modern&quot;&gt;&lt;p&gt;简介：&lt;font color=red&gt;Apache Flume&lt;/font&gt;  是 Cloudera 公司开发，是一个分布式</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十二、Kafka组件搭建--_日志收集</title>
    <link href="https://xin0203xin0203.github.io/posts/115d586a.html"/>
    <id>https://xin0203xin0203.github.io/posts/115d586a.html</id>
    <published>2023-12-17T17:15:29.602Z</published>
    <updated>2024-12-18T13:33:33.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-eye-outline modern"><p>简介：Kafka 由LinkedIn(领英)全球职场社交平台公司开发，贡献给Apache成为顶级项目，是一个分布式的流平台。它具有以下特点：</p><ul><li><font color=red>支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；</font></li><li><font color=red>支持数据实时处理；</font></li><li><font color=red>能保证消息的可靠性投递；</font></li><li><font color=red>支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；</font></li><li><font color=red>高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。</font></li></ul></div><div class="tip success"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E5%8D%81%E3%80%81Flume%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA--%3E%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%5D(https:/www.yuque.com/u25360462/nt1ri1/ilmsg4?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MnKR.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">十、Flume组件搭建-->日志收集</div>            <div class="tag-link-sitename">简介：<font color=red>Apache Flume</font> 是 Cloudera 公司开发，是一个分布式的、高可靠的、高可用的用于海量日志收集、聚合和传输的系统。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note primary simple"><p>需要的安装包：<a href="https://kafka.apache.org/downloads"><strong>kafka</strong></a>压缩包——&gt;<strong>kafka_2.12-3.0.0.tgz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-解压并改名"><a href="#1-1-解压并改名" class="headerlink" title="1.1 解压并改名"></a>1.1 解压并改名</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2<span class="number">.12</span><span class="number">-3.0</span><span class="number">.0</span>.tgz -C /opt/</span><br><span class="line">mv kafka_2<span class="number">.12</span><span class="number">-3.0</span><span class="number">.0</span> kafka</span><br></pre></td></tr></table></figure><h2 id="2-配置kafka环境变量"><a href="#2-配置kafka环境变量" class="headerlink" title="2. 配置kafka环境变量"></a>2. 配置kafka环境变量</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># kafka</span></span><br><span class="line"><span class="keyword">export</span> KAFKA_HOME=/opt/kafka</span><br><span class="line"><span class="keyword">export</span> PATH=$PATH:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2-3-拷贝到slave1和slave2节点"><a href="#2-3-拷贝到slave1和slave2节点" class="headerlink" title="2.3 拷贝到slave1和slave2节点"></a>2.3 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo scp -r /etc/<span class="function">profile  <span class="title">slave2</span><span class="params">(slave1)</span>:/etc/profile</span></span><br></pre></td></tr></table></figure><h2 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h2><h3 id="3-1-在-Kafka-安装目录下创建kafka-logs文件夹（用来存储分区信息的，不要把它与存放错误日志的目录混淆了，日志目录是配置在-log4j-properties-文件-里的）"><a href="#3-1-在-Kafka-安装目录下创建kafka-logs文件夹（用来存储分区信息的，不要把它与存放错误日志的目录混淆了，日志目录是配置在-log4j-properties-文件-里的）" class="headerlink" title="3.1 在 Kafka 安装目录下创建kafka-logs文件夹（用来存储分区信息的，不要把它与存放错误日志的目录混淆了，日志目录是配置在 log4j.properties 文件 里的）"></a>3.1 在 <code>Kafka</code> 安装目录下创建<code>kafka-logs文件夹</code>（用来存储分区信息的，不要把它与存放错误日志的目录混淆了，日志目录是配置在 <code>log4j.properties 文件</code> 里的）</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/kafka/kafka-logs</span><br></pre></td></tr></table></figure><h3 id="3-2-配置server-properties"><a href="#3-2-配置server-properties" class="headerlink" title="3.2 配置server.properties"></a>3.2 <strong>配置server.properties</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># broker的全局唯一标识号，不能重复. 给集群中的每个broker配置一个不同的id</span></span><br><span class="line">broker.id=<span class="number">0</span></span><br><span class="line"># 分区数据的存储位置</span><br><span class="line">log.dirs=/opt/kafka/kafka-logs</span><br><span class="line"># 连接Zookeeper集群地址</span><br><span class="line">zookeeper.connect=master:<span class="number">2181</span>,slave1:<span class="number">2181</span>,slave2:<span class="number">2181</span></span><br></pre></td></tr></table></figure><h3 id="3-3-拷贝到slave1和slave2节点"><a href="#3-3-拷贝到slave1和slave2节点" class="headerlink" title="3.3 拷贝到slave1和slave2节点"></a>3.3 拷贝到slave1和slave2节点</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 分发之后需要修改 broker.<span class="built_in">id</span>( id 值一定不能重复 )的值，同时建议其他节点的环境变量也配置下。</span><br><span class="line">sudo scp -r /opt/kafka/  <span class="built_in">slave2</span>(slave1):/opt/</span><br></pre></td></tr></table></figure><h2 id="4-启动前-先启动zookeeper"><a href="#4-启动前-先启动zookeeper" class="headerlink" title="4. 启动前,先启动zookeeper"></a>4. 启动前,先启动zookeeper</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh /opt/kafka/config/server.properties</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">[<span class="number">2022</span><span class="number">-11</span><span class="number">-07</span> <span class="number">22</span>:<span class="number">47</span>:<span class="number">20</span>,<span class="number">485</span>] INFO [Partition kkjjssdd<span class="number">-0</span> broker=<span class="number">1</span>] Log loaded <span class="keyword">for</span> partition kkjjssdd<span class="number">-0</span> with initial high watermark <span class="number">0</span> (kafka.cluster.Partition)</span><br><span class="line">[<span class="number">2022</span><span class="number">-11</span><span class="number">-07</span> <span class="number">22</span>:<span class="number">47</span>:<span class="number">20</span>,<span class="number">485</span>] INFO [Partition kkjjss<span class="number">-1</span> broker=<span class="number">1</span>] Log loaded <span class="keyword">for</span> partition kkjjss<span class="number">-1</span> with initial high watermark <span class="number">0</span> (kafka.cluster.Partition)</span><br><span class="line">[<span class="number">2022</span><span class="number">-11</span><span class="number">-07</span> <span class="number">22</span>:<span class="number">47</span>:<span class="number">20</span>,<span class="number">492</span>] INFO [BrokerToControllerChannelManager broker=<span class="number">1</span> name=alterIsr]: Recorded <span class="keyword">new</span> controller, from now on will use broker slave1:<span class="number">9092</span> (id: <span class="number">1</span> rack: null) (kafka.server.BrokerToControllerRequestThread)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="5-验证"><a href="#5-验证" class="headerlink" title="5. 验证"></a>5. 验证</h2><p>创建测试主题：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --create --topic kkjjssdd --bootstrap-server master:9092,slave1:9092,slave2:9092 --partitions 2 --replication-factor 1</span><br><span class="line"></span><br><span class="line"><span class="comment">#kafka-topics.sh 任何和 topic 相关的操作都使用这个命令</span></span><br><span class="line"><span class="comment">#--create 表示创建一个 topic</span></span><br><span class="line"><span class="comment">#--zookeeper 指明任意一个 zookeeper 服务器地址</span></span><br><span class="line"><span class="comment">#--replication-factor 表示每个 topic 的副本数. 注意: 副本数必须小于等于 kafka 集群的数量.</span></span><br><span class="line"><span class="comment">#--partitions 这个 topic 的分区的数量</span></span><br><span class="line"><span class="comment">#--topic 这个 topic 的名字.</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Created topic kkjjssdd.</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>创建完成后可以使用以下命令查看创建的主题信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --list --bootstrap-server master:9092,slave1:9092,slave2:9092</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">kkjjssdd</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p><h1 id="Flume整合Kafka"><a href="#Flume整合Kafka" class="headerlink" title="Flume整合Kafka"></a>Flume整合Kafka</h1><h2 id="6-启动zookeeper，和kafka节点"><a href="#6-启动zookeeper，和kafka节点" class="headerlink" title="6. 启动zookeeper，和kafka节点"></a>6. 启动zookeeper，和kafka节点</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br><span class="line">kafka-server-start.sh /opt/kafka/config/server.properties</span><br></pre></td></tr></table></figure><h2 id="7-创建主题"><a href="#7-创建主题" class="headerlink" title="7. 创建主题"></a>7. 创建主题</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建主题</span></span><br><span class="line"><span class="string">kafka-topics.sh</span> <span class="string">--create</span> <span class="string">--zookeeper</span> <span class="string">master:2181</span> <span class="string">--topic</span> <span class="string">flume2kafka</span> <span class="string">--partitions</span> <span class="number">1</span> <span class="string">--replication-factor</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看创建的主题</span></span><br><span class="line"><span class="string">kafka-topics.sh</span> <span class="string">--zookeeper</span> <span class="string">master:2181</span> <span class="string">--list</span></span><br></pre></td></tr></table></figure><h2 id="8-启动kafka消费者"><a href="#8-启动kafka消费者" class="headerlink" title="8. 启动kafka消费者"></a>8. 启动kafka消费者</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server master:9092 --topic flume2kafka</span><br></pre></td></tr></table></figure><h2 id="9-配置flume的文件"><a href="#9-配置flume的文件" class="headerlink" title="9. 配置flume的文件"></a>9. <strong>配置flume的文件</strong></h2><p>新建配置文件 <strong>flume-kafka.properties</strong>，文件内容如下：<br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources、channels、sinks</span></span><br><span class="line"><span class="string">a1.sources</span> <span class="string">=</span> <span class="string">s1</span></span><br><span class="line"><span class="string">a1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"><span class="string">a1.sinks</span> <span class="string">=</span> <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置source属性</span></span><br><span class="line"><span class="string">a1.sources.s1.type</span> <span class="string">=</span> <span class="string">exec</span></span><br><span class="line"><span class="string">a1.sources.s1.command</span> <span class="string">=</span> <span class="string">tail</span> <span class="string">-f</span> <span class="string">/opt/kafka/data/kafka.log</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line"><span class="string">a1.channels.c1.type</span> <span class="string">=</span> <span class="string">memory</span></span><br><span class="line"><span class="string">a1.channels.c1.capacity</span> <span class="string">=</span> <span class="number">10000</span></span><br><span class="line"><span class="string">a1.channels.c1.transactionCapacity</span> <span class="string">=</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line"><span class="comment">#设置Kafka接收器</span></span><br><span class="line"><span class="string">a1.sinks.k1.type</span> <span class="string">=</span> <span class="string">org.apache.flume.sink.kafka.KafkaSink</span></span><br><span class="line"><span class="comment">#设置Kafka地址</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.bootstrap.servers</span> <span class="string">=</span> <span class="string">master:9092</span></span><br><span class="line"><span class="comment">#设置发送到Kafka上的主题</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.topic</span> <span class="string">=</span> <span class="string">flume2kafka</span></span><br><span class="line"><span class="comment">#设置一批中消息的条数</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.flumeBatchSize</span> <span class="string">=</span> <span class="number">6</span></span><br><span class="line"><span class="comment">#0代表不需要等待确认，1代表仅需要leader确认，-1代表所有副本确认</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.producer.acks</span> <span class="string">=</span> <span class="number">1</span></span><br><span class="line"><span class="comment">#设置 linger.ms=1，将达到减少发送的请求数量的效果，但对于在没有负载情况，将增加1ms的延迟。</span></span><br><span class="line"><span class="string">a1.sinks.k1.kafka.producer.linger.ms</span> <span class="string">=</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources和channels绑定</span></span><br><span class="line"><span class="string">a1.sources.s1.channels</span> <span class="string">=</span> <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks和channels绑定</span></span><br><span class="line"><span class="string">a1.sinks.k1.channel</span> <span class="string">=</span> <span class="string">c1</span></span><br></pre></td></tr></table></figure></p><h2 id="10-启动Flume"><a href="#10-启动Flume" class="headerlink" title="10. 启动Flume"></a>10. 启动Flume</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> flume-ng agent -n a1 -c /op/flume/conf/ -f /opt/flume/conf/flume-kafka.properties -Dflume.root.logger=INFO,console &amp;&gt;&gt;flume-ng.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h2 id="11-测试"><a href="#11-测试" class="headerlink" title="11. 测试"></a>11. 测试</h2><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>flume-kafka--flume2kafka</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7Mboz.png" alt="flume-kafka--flume2kafka" title="flume-kafka--flume2kafka"><br>向监听的 <code>/home/xiaokang/docker_teach/kafka.log</code> 文件中追加内容，查看 <code>Kafka</code> 消费者的输出：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> alfhlaflkaEJFl &gt;&gt; kafka.log</span><br><span class="line"><span class="built_in">echo</span> aflkajlkf &gt;&gt; kafka.log</span><br><span class="line"><span class="built_in">echo</span> afilajf &gt;&gt; kafka.log</span><br></pre></td></tr></table></figure><br>可以看到 <code>flume2kafka</code> 主题的消费端已经收到了对应的消息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alfhlaflkaEJFl</span><br><span class="line">aflkajlkf</span><br><span class="line">afilajf</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-eye-outline modern&quot;&gt;&lt;p&gt;简介：Kafka 由LinkedIn(领英)全球职场社交平台公司开发，贡献给Apache成为顶级项目，是一个分布式的流平台。它具有以下特点</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>十、Azkaban-two-server--工作流调度</title>
    <link href="https://xin0203xin0203.github.io/posts/1a829385.html"/>
    <id>https://xin0203xin0203.github.io/posts/1a829385.html</id>
    <published>2023-12-17T17:15:29.590Z</published>
    <updated>2024-12-18T13:11:02.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-fire modern"><p>简介：two server mode（双进程服务模式 ）：存放元数据的数据库为 MySQL，MySQL 应采用主从模式进行备份和容错。这种模式下 webServer 和 executorServer 在不同进程中运行（ 同一服务器 ）。该模式适合生产环境，更新和升级时对用户的影响较小。</p></div><div class="tip "><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E5%85%AB%E3%80%81Azkaban-solo-server--%3E%E5%B7%A5%E4%BD%9C%E6%B5%81%E8%B0%83%E5%BA%A6%5D(https:/www.yuque.com/u25360462/nt1ri1/fwil15?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MxoE.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">八、Azkaban-solo-server-->工作流调度</div>            <div class="tag-link-sitename">简介：Gradle是一款Google推出的 **基于JVM**、 通用灵活的 项目构建工具， 支持**Maven**，JCenter多种第三方仓库;支持传递性依赖管理、废弃了繁杂的xml文件，转而使用 **简洁的 、 支持多种语言** (例如：java、**groovy**等)的 build脚本文件。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BAzkaban-two-server%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/a8z5gqCrBaWzTYqohvKWfQ)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MESY.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Azkaban-two-server环境搭建</div>            <div class="tag-link-sitename">Azkaban-two-server环境搭建-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-创建目录，并解压和改名"><a href="#1-1-创建目录，并解压和改名" class="headerlink" title="1-1 创建目录，并解压和改名"></a>1-1 创建目录，并解压和改名</h3><p><font color=red size=3px weight=bold>分别解压azkaban目录下的</font><br><strong>1.azkaban-web-server/build/distributions/azkaban-web-server-0.1.0-SNAPSHOT.tar.gz<br>2.azkaban-exec-server/build/distributions/azkaban-exec-server-0.1.0-SNAPSHOT.tar.gz<br>3.azkaban-db/build/distributions/azkaban-db-0.1.0-SNAPSHOT.tar.gz</strong></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">mkdir</span> <span class="string">/opt/azkaban-two</span></span><br><span class="line"><span class="string">tar</span> <span class="string">-zxvf</span> <span class="string">azkaban-web-server-0.1.0-SNAPSHOT.tar.gz</span> <span class="string">-C</span> <span class="string">/opt/azkaben-two</span></span><br><span class="line"><span class="string">tar</span> <span class="string">-zxvf</span> <span class="string">azkaban-exec-server-0.1.0-SNAPSHOT.tar.gz</span> <span class="string">-C</span> <span class="string">/opt/azkaben-two</span></span><br><span class="line"><span class="string">tar</span> <span class="string">-zxvf</span> <span class="string">azkaban-web-server-0.1.0-SNAPSHOT.tar.gz</span> <span class="string">-C</span> <span class="string">/opt/azkaben-two</span></span><br><span class="line"><span class="string">mv</span> <span class="string">azkaban-web-server-0.1.0-SNAPSHOT/</span> <span class="string">web-server</span></span><br><span class="line"><span class="string">mv</span> <span class="string">azkaban-exec-server-0.1.0-SNAPSHOT/</span> <span class="string">executor-server</span></span><br><span class="line"><span class="string">mv</span> <span class="string">azkaban-db-0.1.0-SNAPSHOT/</span> <span class="string">sql-db</span></span><br></pre></td></tr></table></figure><h3 id="1-2-创建MySQL数据库"><a href="#1-2-创建MySQL数据库" class="headerlink" title="1-2 创建MySQL数据库"></a>1-2 创建MySQL数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database azkaban_two;</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;Query OK, 1 row affected (0.01 sec)&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">mysql&gt; use azkaban_two;</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;Database changed&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="built_in">source</span> /opt/azkaban-two/azkaban-db/create-all-sql-0.1.0-SNAPSHOT.sql</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Query OK, 0 rows affected (0.09 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Query OK, 0 rows affected (0.02 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Query OK, 0 rows affected (0.02 sec)</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-3-生成密钥和证书"><a href="#1-3-生成密钥和证书" class="headerlink" title="1-3 生成密钥和证书"></a>1-3 生成密钥和证书</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[huserg@master azkaban-two]$ keytool -keystore /opt/azkaban-two/web-server/keystore -<span class="built_in">alias</span> huser -genkey -keyalg rsa</span><br><span class="line"></span><br><span class="line">keytool是 Java 数据证书的管理工具，使用户能够管理自己的公 /私钥 对及相关证书 。</span><br><span class="line">-keystore 指定密钥库的名称及位置 (产生的各类信息将存在 .keystore文件中)</span><br><span class="line">-genkey (或者 -genkeypair) 生成密钥对</span><br><span class="line">-<span class="built_in">alias</span> 为生成的密钥对指定别名，如果没有默认是 mykey</span><br><span class="line">-keyalg 指定密钥的算法 RSA/DSA，默认是 DSA</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Warning:</span></span><br><span class="line"><span class="string">JKS 密钥库使用专用格式。建议使用 &quot;keytool -importkeystore -srckeystore /opt/azkaban-two/web-server/keystore -destkeystore /opt/azkaban-two/web-server/keystore -deststoretype pkcs12&quot; 迁移到行业标准格式 PKCS12。</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-4-查看密钥库信息"><a href="#1-4-查看密钥库信息" class="headerlink" title="1-4 查看密钥库信息"></a>1-4 查看密钥库信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[huser@slave1 web-server]$ keytool -list -keystore keystore</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">输入密钥库口令:  </span></span><br><span class="line"><span class="string">密钥库类型: JKS</span></span><br><span class="line"><span class="string">密钥库提供方: SUN</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">您的密钥库包含 1 个条目</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">huser, 2022-11-3, PrivateKeyEntry, </span></span><br><span class="line"><span class="string">证书指纹 (SHA-256): C7:07:73:D9:81:19:43:6F:C3:8E:5A:E4:0D:0F:08:AA:98:C4:0A:D9:C4:C7:5A:B1:27:E9:1B:80:2C:68:66:5D</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Warning:</span></span><br><span class="line"><span class="string">JKS 密钥库使用专用格式。建议使用 &quot;keytool -importkeystore -srckeystore keystore -destkeystore keystore -deststoretype pkcs12&quot; 迁移到行业标准格式 PKCS12。</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="2-web-服务器配置"><a href="#2-web-服务器配置" class="headerlink" title="2. web 服务器配置"></a>2. web 服务器配置</h2><h3 id="2-1-在web服务器目录下创建多级文件夹plugins-jobtypes："><a href="#2-1-在web服务器目录下创建多级文件夹plugins-jobtypes：" class="headerlink" title="2-1 在web服务器目录下创建多级文件夹plugins/jobtypes："></a>2-1 在web服务器目录下创建多级文件夹<code>plugins/jobtypes</code>：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/azkaban-two/web-server/plugins/jobtypes</span><br></pre></td></tr></table></figure><h3 id="2-2-进入-azkaban-web-服务器安装目录的conf目录下，修改azkaban-properties"><a href="#2-2-进入-azkaban-web-服务器安装目录的conf目录下，修改azkaban-properties" class="headerlink" title="2-2 进入 azkaban web 服务器安装目录的conf目录下，修改azkaban.properties"></a>2-2 进入 <code>azkaban web</code> 服务器安装目录的<code>conf目录</code>下，修改<strong>azkaban.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Azkaban Personalization Settings</span></span><br><span class="line"><span class="string">azkaban.name=huser</span></span><br><span class="line"><span class="string">azkaban.label=huser-Azkaban</span></span><br><span class="line"><span class="string">azkaban.color=#FF3601</span></span><br><span class="line"><span class="string">azkaban.default.servlet.path=/index</span></span><br><span class="line"><span class="string">web.resource.dir=/opt/azkaban-two/web-server/web</span></span><br><span class="line"><span class="string">default.timezone.id=Asia/Shanghai</span></span><br><span class="line"><span class="comment"># Azkaban UserManager class</span></span><br><span class="line"><span class="string">user.manager.class=azkaban.user.XmlUserManager</span></span><br><span class="line"><span class="string">user.manager.xml.file=/opt/azkaban-two/web-server/conf/azkaban-users.xml</span></span><br><span class="line"><span class="comment"># Loader for projects</span></span><br><span class="line"><span class="string">executor.global.properties=/opt/azkaban-two/web-server/conf/global.properties</span></span><br><span class="line"><span class="string">azkaban.project.dir=projects</span></span><br><span class="line"><span class="comment"># Velocity dev mode</span></span><br><span class="line"><span class="string">velocity.dev.mode=false</span></span><br><span class="line"><span class="comment"># Azkaban Jetty server properties.</span></span><br><span class="line"><span class="string">jetty.ssl.port=8443</span></span><br><span class="line"><span class="string">jetty.port=8081</span></span><br><span class="line"><span class="string">jetty.keystore=/opt/azkaban-two/web-server/keystore</span></span><br><span class="line"><span class="string">jetty.password=123456</span></span><br><span class="line"><span class="string">jetty.keypassword=123456</span></span><br><span class="line"><span class="string">jetty.truststore=/opt/azkaban-two/web-server/keystore</span></span><br><span class="line"><span class="string">jetty.trustpassword=huser</span></span><br><span class="line"><span class="string">jetty.maxThreads=25</span></span><br><span class="line"><span class="comment"># Azkaban Executor settings</span></span><br><span class="line"><span class="string">executor.port=11241</span></span><br><span class="line"><span class="comment"># mail settings</span></span><br><span class="line"><span class="string">mail.sender=</span></span><br><span class="line"><span class="string">mail.host=</span></span><br><span class="line"><span class="comment"># User facing web server configurations used to construct the user facing server URLs. They are useful when there is a reverse proxy between Azkaban web servers and users.</span></span><br><span class="line"><span class="comment"># enduser -&gt; myazkabanhost:443 -&gt; proxy -&gt; localhost:8081</span></span><br><span class="line"><span class="comment"># when this parameters set then these parameters are used to generate email links.</span></span><br><span class="line"><span class="comment"># if these parameters are not set then jetty.hostname, and jetty.port(if ssl configured jetty.ssl.port) are used.</span></span><br><span class="line"><span class="comment"># azkaban.webserver.external_hostname=myazkabanhost.com</span></span><br><span class="line"><span class="comment"># azkaban.webserver.external_ssl_port=443</span></span><br><span class="line"><span class="comment"># azkaban.webserver.external_port=8081</span></span><br><span class="line"><span class="string">job.failure.email=</span></span><br><span class="line"><span class="string">job.success.email=</span></span><br><span class="line"><span class="string">lockdown.create.projects=false</span></span><br><span class="line"><span class="string">cache.directory=cache</span></span><br><span class="line"><span class="comment"># JMX stats</span></span><br><span class="line"><span class="string">jetty.connector.stats=true</span></span><br><span class="line"><span class="string">executor.connector.stats=true</span></span><br><span class="line"><span class="comment"># Azkaban plugin settings</span></span><br><span class="line"><span class="string">azkaban.jobtype.plugin.dir=/opt/azkaban-two/web-server/plugins/jobtypes</span></span><br><span class="line"><span class="comment"># Azkaban mysql settings by default. Users should configure their own username and password.</span></span><br><span class="line"><span class="string">database.type=mysql</span></span><br><span class="line"><span class="string">mysql.port=3306</span></span><br><span class="line"><span class="string">mysql.host=192.168.33.147</span></span><br><span class="line"><span class="string">mysql.database=azkaban_two</span></span><br><span class="line"><span class="string">mysql.user=root</span></span><br><span class="line"><span class="string">mysql.password=1</span></span><br><span class="line"><span class="string">mysql.numconnections=100</span></span><br><span class="line"><span class="comment">#Multiple Executor</span></span><br><span class="line"><span class="string">azkaban.use.multiple.executors=true</span></span><br><span class="line"><span class="string">azkaban.executorselector.filters=StaticRemainingFlowSize,CpuStatus</span></span><br><span class="line"><span class="string">azkaban.executorselector.comparator.NumberOfAssignedFlowComparator=1</span></span><br><span class="line"><span class="string">azkaban.executorselector.comparator.Memory=1</span></span><br><span class="line"><span class="string">azkaban.executorselector.comparator.LastDispatched=1</span></span><br><span class="line"><span class="string">azkaban.executorselector.comparator.CpuUsage=1</span></span><br></pre></td></tr></table></figure><h3 id="2-3-log4j-properties修改日志文件路径"><a href="#2-3-log4j-properties修改日志文件路径" class="headerlink" title="2-3 log4j.properties修改日志文件路径"></a>2-3 <strong>log4j.properties</strong>修改日志文件路径</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log4j.appender.server.File=/opt/azkaban-two/web-server/logs/azkaban-webserver.log</span><br></pre></td></tr></table></figure><h3 id="2-4-在azkaban-web-服务器安装目录的conf目录下，-按照如下配置修改-azkaban-users-xml文件，增加自定义管理员用户"><a href="#2-4-在azkaban-web-服务器安装目录的conf目录下，-按照如下配置修改-azkaban-users-xml文件，增加自定义管理员用户" class="headerlink" title="2-4 在azkaban web 服务器安装目录的conf目录下， 按照如下配置修改 azkaban-users.xml文件，增加自定义管理员用户"></a>2-4 在<code>azkaban web</code> 服务器安装目录的<code>conf目录</code>下， 按照如下配置修改 <code>azkaban-users.xml文件</code>，增加自定义管理员用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;azkaban-users&gt;</span><br><span class="line">  &lt;user <span class="built_in">groups</span>=<span class="string">&quot;azkaban&quot;</span> password=<span class="string">&quot;azkaban&quot;</span> roles=<span class="string">&quot;admin&quot;</span> username=<span class="string">&quot;azkaban&quot;</span>/&gt;</span><br><span class="line">  &lt;user <span class="built_in">groups</span>=<span class="string">&quot;azkaban&quot;</span> password=<span class="string">&quot;xiaokang&quot;</span> roles=<span class="string">&quot;admin&quot;</span> username=<span class="string">&quot;xiaokang&quot;</span>/&gt;</span><br><span class="line">  &lt;user password=<span class="string">&quot;metrics&quot;</span> roles=<span class="string">&quot;metrics&quot;</span> username=<span class="string">&quot;metrics&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line">  &lt;role name=<span class="string">&quot;admin&quot;</span> permissions=<span class="string">&quot;ADMIN&quot;</span>/&gt;</span><br><span class="line">  &lt;role name=<span class="string">&quot;metrics&quot;</span> permissions=<span class="string">&quot;METRICS&quot;</span>/&gt;</span><br><span class="line">&lt;/azkaban-users&gt;</span><br></pre></td></tr></table></figure><h2 id="3-Executor-服务器配置"><a href="#3-Executor-服务器配置" class="headerlink" title="3. Executor 服务器配置"></a>3. <strong>Executor</strong> 服务器配置</h2><h3 id="3-1-进入-azkaban-executor服务器安装目录的conf目录下，修改azkaban-properties"><a href="#3-1-进入-azkaban-executor服务器安装目录的conf目录下，修改azkaban-properties" class="headerlink" title="3-1  进入 azkaban executor服务器安装目录的conf目录下，修改azkaban.properties"></a>3-1  进入 <code>azkaban executor</code>服务器安装目录的<code>conf目录</code>下，修改<strong>azkaban.properties</strong></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Azkaban Personalization Settings</span></span><br><span class="line"><span class="string">default.timezone.id=Asia/Shanghai</span></span><br><span class="line"><span class="comment"># Azkaban UserManager class</span></span><br><span class="line"><span class="comment"># Loader for projects</span></span><br><span class="line"><span class="string">executor.global.properties=/opt/azkaban-two/executor-server/conf/global.properties</span></span><br><span class="line"><span class="string">azkaban.project.dir=projects</span></span><br><span class="line"><span class="string">azkaban.webserver.url=https://master:8443</span></span><br><span class="line"><span class="comment"># Azkaban plugin settings</span></span><br><span class="line"><span class="string">azkaban.jobtype.plugin.dir=/opt/azkaban-two/executor-server/plugins/jobtypes</span></span><br><span class="line"><span class="comment"># Azkaban mysql settings by default. Users should configure their own username and password.</span></span><br><span class="line"><span class="string">database.type=mysql</span></span><br><span class="line"><span class="string">mysql.port=3306</span></span><br><span class="line"><span class="string">mysql.host=192.168.33.147</span></span><br><span class="line"><span class="string">mysql.database=azkaban_two</span></span><br><span class="line"><span class="string">mysql.user=root</span></span><br><span class="line"><span class="string">mysql.password=1</span></span><br><span class="line"><span class="string">mysql.numconnections=100</span></span><br><span class="line"><span class="comment"># Azkaban Executor settings</span></span><br><span class="line"><span class="string">executor.maxThreads=50</span></span><br><span class="line"><span class="string">executor.flow.threads=30</span></span><br><span class="line"><span class="string">executor.port=11241</span></span><br></pre></td></tr></table></figure><h3 id="3-2-log4j-properties修改日志文件路径"><a href="#3-2-log4j-properties修改日志文件路径" class="headerlink" title="3-2 log4j.properties修改日志文件路径"></a>3-2 <strong>log4j.properties</strong>修改日志文件路径</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log4j.appender.server.File=/opt/azkaban-two/executor-server/logs/azkaban-execserver.log</span><br></pre></td></tr></table></figure><h2 id="4-启动"><a href="#4-启动" class="headerlink" title="4.启动"></a>4.启动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># executor服务器bin目录下执行启动命令</span></span><br><span class="line">[huser@master bin]$ ./start-exec.sh</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;AzkabanExecutorServer&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动激活executor服务器</span></span><br><span class="line">[huser@master ~]$ curl http://master:11241/executor?action=activate</span><br><span class="line"></span><br><span class="line"><span class="comment"># web服务器bin目录下执行启动命令</span></span><br><span class="line">[huser@master bin]$ ./start-web.sh </span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;AzkabanWebServer&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><font color=red size=3px weight=bold>以下内容跟   <code>基本任务调度</code>  一样</font><br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E5%85%AB%E3%80%81Azkaban-solo-server--%3E%E5%B7%A5%E4%BD%9C%E6%B5%81%E8%B0%83%E5%BA%A6%5D(https:/www.yuque.com/u25360462/nt1ri1/fwil15?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7MxoE.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">八、Azkaban-solo-server-->工作流调度</div>            <div class="tag-link-sitename">简介：Gradle是一款Google推出的 **基于JVM**、 通用灵活的 项目构建工具， 支持**Maven**，JCenter多种第三方仓库;支持传递性依赖管理、废弃了繁杂的xml文件，转而使用 **简洁的 、 支持多种语言** (例如：java、**groovy**等)的 build脚本文件。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div></p><p><strong>Azkaban-multiple-executor的操作</strong>只是把Azkaban-two-server的文件发给三台机，在跟Azkaban-two-server的操作任务一样</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-fire modern&quot;&gt;&lt;p&gt;简介：two server mode（双进程服务模式 ）：存放元数据的数据库为 MySQL，MySQL 应采用主从模式进行备份和容错。这种模式下 web</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>七、Sqoop组件搭建--数据迁移工具</title>
    <link href="https://xin0203xin0203.github.io/posts/da145f53.html"/>
    <id>https://xin0203xin0203.github.io/posts/da145f53.html</id>
    <published>2023-12-17T17:15:29.569Z</published>
    <updated>2024-12-18T12:35:20.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-cube modern"><p>简介：Apache Sqoop 是一个常用的数据迁移工具，主要用于在不同存储系统之间实现数据的导入与导出：</p><ul><li>导入数据：从 MySQL、Oracle 等关系型数据库中导入数据到 HDFS、Hive、HBase 等分布式文件存储系统中；</li><li>导出数据：从分布式文件系统中导出数据到关系数据库中。</li></ul><p><strong>Sqoop名字的由来：SQL—-Hadoop=Sq+oop=Sqoop</strong></p></div><div class="tip sync"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note success simple"><p>需要的安装包：<a href="https://archive.apache.org/dist/sqoop/"><strong>Sqoop</strong></a>包—-&gt;<strong>sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz</strong></p></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-解压并改名"><a href="#1-解压并改名" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf sqoop<span class="number">-1.4</span><span class="number">.6</span>.bin__hadoop<span class="number">-2.0</span><span class="number">.4</span>-alpha.tar.gz -C /opt/</span><br><span class="line">mv sqoop<span class="number">-1.4</span><span class="number">.6</span>.bin__hadoop<span class="number">-2.0</span><span class="number">.4</span>-alpha/ sqoop</span><br></pre></td></tr></table></figure><h2 id="2-配置Sqoop环境变量"><a href="#2-配置Sqoop环境变量" class="headerlink" title="2. 配置Sqoop环境变量"></a>2. 配置Sqoop环境变量</h2><h3 id="2-1-配置Sqoop环境变量"><a href="#2-1-配置Sqoop环境变量" class="headerlink" title="2.1 配置Sqoop环境变量"></a>2.1 配置Sqoop环境变量</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="meta"># sqoop</span></span><br><span class="line">export SQOOP_HOME=/opt/sqoop</span><br><span class="line">export PATH=$PATH:$SQOOP_HOME/bin</span><br></pre></td></tr></table></figure><h3 id="2-2-加载环境变量"><a href="#2-2-加载环境变量" class="headerlink" title="2.2 加载环境变量"></a>2.2 加载环境变量</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h2 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h2><h3 id="3-1-配置sqoop-env-sh"><a href="#3-1-配置sqoop-env-sh" class="headerlink" title="3.1 配置sqoop-env.sh"></a>3.1 <strong>配置sqoop-env.sh</strong></h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 拷贝 Sqoop 的环境配置模板</span></span><br><span class="line">cp sqoop-env-template.cmd sqoop-env.sh</span><br><span class="line"></span><br><span class="line">修改内容：</span><br><span class="line">export HADOOP_COMMON_HOME=/opt/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME=/opt/hadoop</span><br><span class="line">export HBASE_HOME=/opt/hbase</span><br><span class="line">export HIVE_HOME=/opt/hive</span><br><span class="line">export ZOOCFGDIR=/opt/zookeeper</span><br><span class="line">export ZOOKEEPER=/opt/zookeeper</span><br></pre></td></tr></table></figure><h3 id="3-2-拷贝数据库驱动"><a href="#3-2-拷贝数据库驱动" class="headerlink" title="3.2 拷贝数据库驱动"></a>3.2 拷贝数据库驱动</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp mysql-connector-java<span class="number">-5.1</span><span class="number">.37</span>.jar /opt/sqoop/lib</span><br></pre></td></tr></table></figure><h3 id="3-3-验证"><a href="#3-3-验证" class="headerlink" title="3.3 验证"></a>3.3 验证</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sqoop version</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">Sqoop 1.4.7</span></span><br><span class="line"><span class="string">git commit id 2328971411f57f0cb683dfb79d19d4d19d185dd8</span></span><br><span class="line"><span class="string">Compiled by maugli on Thu Dec 21 15:59:58 STD 2017</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="4-Sqoop基本命令"><a href="#4-Sqoop基本命令" class="headerlink" title="4.Sqoop基本命令"></a>4.Sqoop基本命令</h2><h3 id="4-1-查看所有命令"><a href="#4-1-查看所有命令" class="headerlink" title="4.1 查看所有命令"></a>4.1 查看所有命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop <span class="built_in">help</span></span><br></pre></td></tr></table></figure><h3 id="4-2-查看某条命令的具体使用方法"><a href="#4-2-查看某条命令的具体使用方法" class="headerlink" title="4.2 查看某条命令的具体使用方法"></a>4.2 查看某条命令的具体使用方法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sqoop <span class="built_in">help</span> 命令名</span><br><span class="line"><span class="comment">#例如sqoop help import</span></span><br></pre></td></tr></table></figure><h2 id="5-Sqoop-与-MySQL"><a href="#5-Sqoop-与-MySQL" class="headerlink" title="5. Sqoop 与 MySQL"></a>5. Sqoop 与 MySQL</h2><h3 id="5-1-查询MySQL所有数据库"><a href="#5-1-查询MySQL所有数据库" class="headerlink" title="5.1 查询MySQL所有数据库"></a>5.1 查询MySQL所有数据库</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">sqoop</span> <span class="string">list-databases</span> <span class="string">--connect</span> <span class="string">jdbc:mysql://192.168.33.171:3306</span> <span class="string">--username</span> <span class="string">root</span> <span class="string">--password</span> <span class="number">000000</span></span><br></pre></td></tr></table></figure><h3 id="5-2-查询指定数据库种所有数据表"><a href="#5-2-查询指定数据库种所有数据表" class="headerlink" title="5.2 查询指定数据库种所有数据表"></a>5.2 查询指定数据库种所有数据表</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">sqoop</span> <span class="string">list-tables</span> <span class="string">--connect</span> <span class="string">jdbc:mysql://192.168.33.171:3306/mysql</span> <span class="string">--username</span> <span class="string">root</span> <span class="string">--password</span> <span class="number">000000</span></span><br></pre></td></tr></table></figure><h2 id="6-Sqoop-与-HDFS"><a href="#6-Sqoop-与-HDFS" class="headerlink" title="6. Sqoop 与 HDFS"></a>6. Sqoop 与 HDFS</h2><h3 id="6-1-MySQL数据导入到HDFS"><a href="#6-1-MySQL数据导入到HDFS" class="headerlink" title="6.1 MySQL数据导入到HDFS"></a>6.1 MySQL数据导入到HDFS</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.171:3306/test \</span><br><span class="line">--username root \</span><br><span class="line">--password 000000 \</span><br><span class="line">--table runoob_tbl \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--target-dir /sqoop \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;\t&#x27;</span> \</span><br><span class="line">-m 3</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--table help_keyword \    # 待导入的表</span></span><br><span class="line"><span class="string">--delete-target-dir \    # 目标目录存在则先删除</span></span><br><span class="line"><span class="string">--target-dir /sqoop \    # 导入的目标目录</span></span><br><span class="line"><span class="string">--fields-terminated-by &#x27;</span>\t<span class="string">&#x27; \    # 指定导出数据的分隔符</span></span><br><span class="line"><span class="string">-m 3    # 指定并行执行的 map tasks 数量  </span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="6-2-导入验证"><a href="#6-2-导入验证" class="headerlink" title="6.2 导入验证"></a>6.2 导入验证</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看导入后的目录</span></span><br><span class="line">hdfs dfs -<span class="built_in">ls</span> -R /sqoop</span><br><span class="line"><span class="comment"># 查看导入内容</span></span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> /sqoop/part-m-00000</span><br></pre></td></tr></table></figure><h3 id="6-3-增量导入"><a href="#6-3-增量导入" class="headerlink" title="6.3 增量导入"></a>6.3 增量导入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.147:3306/mysql \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table help_keyword \</span><br><span class="line">--target-dir /sqoop  \</span><br><span class="line">--append \</span><br><span class="line">--incremental  append  \             </span><br><span class="line">--fields-terminated-by <span class="string">&#x27;\t&#x27;</span> \</span><br><span class="line">--check-column  help_keyword_id \</span><br><span class="line">--last-value 463  \ </span><br><span class="line">-m 1</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--fields-terminated-by &#x27;</span>\t<span class="string">&#x27; \    # 指定导出数据的分隔符</span></span><br><span class="line"><span class="string">--check-column  help_keyword_id \    # 指明用于增量导入的参考列</span></span><br><span class="line"><span class="string">--last-value 463  \    # 指定参考列上次导入的最大值 </span></span><br><span class="line"><span class="string">-m 1</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="6-4-HDFS数据导出到MySQL"><a href="#6-4-HDFS数据导出到MySQL" class="headerlink" title="6.4 HDFS数据导出到MySQL"></a>6.4 HDFS数据导出到MySQL</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE help_keyword_from_hdfs LIKE help_keyword;</span><br><span class="line">sqoop <span class="built_in">export</span> \</span><br><span class="line">--connect jdbc:mysql://192.168.33.147:3306/mysql \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table help_keyword_from_hdfs \</span><br><span class="line">--export-dir /sqoop/* \</span><br><span class="line">--input-fields-terminated-by <span class="string">&#x27;\t&#x27;</span> \</span><br><span class="line">-m 3</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">--table help_keyword_from_hdfs \     # 导出数据存储在 MySQL 的 help_keyword_from_hdf 的表中</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-cube modern&quot;&gt;&lt;p&gt;简介：Apache Sqoop 是一个常用的数据迁移工具，主要用于在不同存储系统之间实现数据的导入与导出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;导入数据：从 My</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>六、Kylin(麒麟)安装及基本使用--多维分析</title>
    <link href="https://xin0203xin0203.github.io/posts/e170afa6.html"/>
    <id>https://xin0203xin0203.github.io/posts/e170afa6.html</id>
    <published>2023-12-17T17:15:29.541Z</published>
    <updated>2024-12-18T12:18:44.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note green anzhiyufont anzhiyu-icon-book modern"><p>简介:  <a href="https://kylin.apache.org/cn/"><strong>Apache Kylin™</strong></a>是一个开源的、分布式的分析引擎，提供 Hadoop/Spark 之上的 SQL 查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由 eBay 开发并贡献至开源社区。它能在亚秒内查询巨大的表。Apache Kylin也是中国人主导的、唯一的Apache顶级开源项目，在开源社区有世界级的影响力。</p></div><div class="tip bolt"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%BA%8C%E3%80%81zookeeper%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA%5D(https:/www.yuque.com/u25360462/nt1ri1/wzn655?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7LkQP.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">二、zookeeper组件搭建</div>            <div class="tag-link-sitename">介绍：Zookeeper 是一个开源的分布式协调服务，目前由 Apache 进行维护。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%89%E3%80%81Hive%E7%BB%84%E4%BB%B6%E6%90%AD%E5%BB%BA--%3E%E5%86%85%E5%90%ABMySQL%E5%AE%89%E8%A3%85%5D(https:/www.yuque.com/u25360462/nt1ri1/zamxgf?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bvhc.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">三、Hive组件搭建-->内含MySQL安装</div>            <div class="tag-link-sitename">Hive：由Facebook开源用于解决海量结构化日志的数据统计。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E5%9B%9B%E3%80%81HBase%E7%BB%84%E4%BB%B6%5D(https:/www.yuque.com/u25360462/nt1ri1/rncd28?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bDDb.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">四、HBase组件</div>            <div class="tag-link-sitename">介绍：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note primary simple"><p>需要的安装包：<a href="http://kylin.apache.org/cn/download/"><strong>Kylin(麒麟)</strong></a>包—-&gt;<strong>apache-kylin-4.0.2-bin.tar.gz</strong></p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BKylin(%E9%BA%92%E9%BA%9F)%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/mfvldzG9VFU6_jZSUJFuSg)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7byG9.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Kylin(麒麟)安装及基本使用</div>            <div class="tag-link-sitename">Apache Kylin™是一个开源的、分布式的分析引擎，提供 Hadoop/Spark 之上的 SQL 查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由 eBay 开发并贡献至开源社区。它能在亚秒内查询巨大的表。</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BKylin%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2_%E5%BF%84%E5%87%9D%5E%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2_kylin%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E9%83%A8%E7%BD%B2%5D(https:/blog.csdn.net/weixin_43660536/article/details/119773857)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7bjDY.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Kylin集群安装部署</div>            <div class="tag-link-sitename">这里目录标题3、`Kylin`集群安装部署3.1. 下载上传3.1.2 修改 hive 配置文件3.1.3 修改 hbase 配置文件3.1.4 配置 kylin 相关环境变量3.1.5 修改配置文件3.1.6 拷贝kylin到其他节点3.1.7 启动3.1.8 关机拍照3、Kylin集群安装部署安装前提OS: CentOS 7java 1.8zookeeper 3.4.5</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1 准备工作"></a>1 准备工作</h2><h3 id="1-解压并改名"><a href="#1-解压并改名" class="headerlink" title="1. 解压并改名"></a>1. 解压并改名</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-kylin-4.0.2-bin.tar.gz -C /opt/</span><br><span class="line"><span class="built_in">mv</span> apache-kylin-4.0.2-bin kylin</span><br></pre></td></tr></table></figure><h2 id="2-配置Kylin环境变量"><a href="#2-配置Kylin环境变量" class="headerlink" title="2. 配置Kylin环境变量"></a>2. 配置Kylin环境变量</h2><h3 id="1-配置Kylin环境变量"><a href="#1-配置Kylin环境变量" class="headerlink" title="1. 配置Kylin环境变量"></a>1. 配置Kylin环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"></span><br><span class="line">修改内容：</span><br><span class="line"><span class="built_in">export</span> KYLIN_HOME=/opt/kylin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KYLIN_HOME</span>/bin</span><br></pre></td></tr></table></figure><h3 id="2-加载环境变量"><a href="#2-加载环境变量" class="headerlink" title="2. 加载环境变量"></a>2. 加载环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h2 id="3-修改配置"><a href="#3-修改配置" class="headerlink" title="3. 修改配置"></a>3. 修改配置</h2><p>3.1.1 配置<code>conf目录</code>下的<code>kylin.properties</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 改成东八区, 否则会出现时间显示不准的问题</span></span><br><span class="line">kylin.web.timezone=GMT+8</span><br></pre></td></tr></table></figure><br>3.1.2 配置bin目录下的kylin.sh<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [[ -z <span class="variable">$reload_dependency</span> &amp;&amp; `<span class="built_in">ls</span> -1 <span class="variable">$&#123;dir&#125;</span>/cached-* 2&gt;/dev/null | <span class="built_in">wc</span> -l` -eq 5 ]]</span><br><span class="line">   <span class="keyword">then</span></span><br><span class="line">       <span class="built_in">echo</span> <span class="string">&quot;Using cached dependency...&quot;</span></span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/cached-hive-dependency.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/cached-hbase-dependency.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/cached-hadoop-conf-dir.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/cached-kafka-dependency.sh</span><br><span class="line">       <span class="comment">#source $&#123;dir&#125;/cached-spark-dependency.sh</span></span><br><span class="line">   <span class="keyword">else</span></span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/find-hive-dependency.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/find-hbase-dependency.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/find-hadoop-conf-dir.sh</span><br><span class="line">       <span class="built_in">source</span> <span class="variable">$&#123;dir&#125;</span>/find-kafka-dependency.sh</span><br><span class="line">       <span class="comment">#source $&#123;dir&#125;/find-spark-dependency.sh</span></span><br><span class="line">   <span class="keyword">fi</span></span><br></pre></td></tr></table></figure><br>3.1.3 配置HBased的<strong>hbase-site.xml</strong><br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--指定 zookeeper 地址--&gt;</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master,slave1,slave2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br></pre></td></tr></table></figure></p><h2 id="4-启动Kylin"><a href="#4-启动Kylin" class="headerlink" title="4. 启动Kylin"></a>4. 启动Kylin</h2><p><strong>4.1.1 启动Kylin之前确保HDFS、YARN、Zookeeper、HBase已经启动</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kylin.sh start</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">A new Kylin instance is started by root. To stop it, run &#x27;</span>kylin.sh stop<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Check the log at /opt/kylin/logs/kylin.log</span></span><br><span class="line"><span class="string">Web UI is at http://master:7070/kylin</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">A new Kylin instance is started by root. To stop it, run &#x27;</span>kylin.sh stop<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Check the log at /opt/kylin/logs/kylin.log</span></span><br><span class="line"><span class="string">Web UI is at http://slave1:7070/kylin</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">A new Kylin instance is started by root. To stop it, run &#x27;</span>kylin.sh stop<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Check the log at /opt/kylin/logs/kylin.log</span></span><br><span class="line"><span class="string">Web UI is at http://slave2:7070/kylin</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">访问 https://slave2:7070/kylin ；默认的用户名和密码为 ADMIN 和 KYLIN</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note green anzhiyufont anzhiyu-icon-book modern&quot;&gt;&lt;p&gt;简介:  &lt;a href=&quot;https://kylin.apache.org/cn/&quot;&gt;&lt;strong&gt;Apache Kylin™&lt;/strong&gt;&lt;/</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>九、Azkaban-solo-server--工作流调度</title>
    <link href="https://xin0203xin0203.github.io/posts/682fb25a.html"/>
    <id>https://xin0203xin0203.github.io/posts/682fb25a.html</id>
    <published>2023-12-17T17:15:29.529Z</published>
    <updated>2024-12-18T12:59:51.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Gradle安装"><a href="#1-Gradle安装" class="headerlink" title="1. Gradle安装"></a>1. <a href="https://blog.csdn.net/qq_42055933/article/details/125923776?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166737555116782395381760%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=166737555116782395381760&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-125923776-null-null.142^v62^pc_rank_34_queryrelevant25,201^v3^control_1,213^v1^control&amp;utm_term=Gradle&amp;spm=1018.2226.3001.4187"><strong>Gradle</strong></a>安装</h1><div class="note green anzhiyufont anzhiyu-icon-gear modern"><p>简介：Gradle是一款Google推出的 <strong>基于JVM</strong>、 通用灵活的 项目构建工具， 支持<a href="https://so.csdn.net/so/search?q=Maven&amp;spm=1001.2101.3001.7020"><strong>Maven</strong></a>，JCenter多种第三方仓库;支持传递性依赖管理、废弃了繁杂的xml文件，转而使用 <strong>简洁的 、 支持多种语言</strong> (例如：java、<a href="https://so.csdn.net/so/search?q=groovy&amp;spm=1001.2101.3001.7020"><strong>groovy</strong></a>等)的 build脚本文件 。</p></div><div class="tip bell"><p>前置准备：</p></div><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5B%E4%B8%80%E3%80%81%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%5D(https:/www.yuque.com/yuqueyonghub89qji/xc0gbs/kusqdo?view=doc_embed)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/15/o7ex2Q.png)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">一、集群环境搭建高可用版本配置</div>            <div class="tag-link-sitename">介绍：HDFS （Hadoop Distributed File System）是Hadoop下的分布式文件系统，具有高容错(fault-tolerant)、高吞吐量(high throughput)等特性，可以部署在低成本(low-cost)的硬件上。特点：高容错：由于 HDFS 采用数据的... HADOOP</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div><div class="note warning modern"><p>需要的安装包： <strong><a href="https://gradle.org/releases/">Gradle</a>包—-&gt;gradle-4.6-all.zip</strong></p></div><font color=red size=3px weight=bold>注意：有版本依赖，过高的版本会报错</font>## 1-1 准备工作### 1-1-1 下载zip解压组件<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install unzip</span><br></pre></td></tr></table></figure>### 1-1-2 解压并改名<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unzip gradle-4.6-all.zip -r /opt/</span><br><span class="line"><span class="built_in">mv</span> gradle-4.6 gradle</span><br></pre></td></tr></table></figure>## 1-2 配置Gradle环境变量### 1-2-1 配置Gradle环境变量<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line">添加：</span><br><span class="line"><span class="comment"># gradle</span></span><br><span class="line"><span class="built_in">export</span> GRADLE_HOME=/opt/maven</span><br><span class="line"><span class="built_in">export</span> GRADLE_USER_HOME=/opt/gradle</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$GRADLE_HOME</span>/bin</span><br></pre></td></tr></table></figure>### 1-2-2 加载环境变量<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>## 1-3 修改配置### 1-3-1 创建本地目录<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/gradle/gradle_repository</span><br></pre></td></tr></table></figure>### 1-3-2 新创建文件并配置 `init.gradle`**（ init.gradle就相当于maven中的settings.xml）**配置在`/opt/gradle/init.d`<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">allprojects &#123;</span><br><span class="line">    repositories &#123;</span><br><span class="line">        maven &#123; url <span class="string">&#x27;file:///opt/maven/maven_repository&#x27;</span>&#125;</span><br><span class="line">        <span class="built_in">mavenLocal</span>()</span><br><span class="line">        maven &#123; name <span class="string">&quot;Alibaba&quot;</span> ; url <span class="string">&quot;https://maven.aliyun.com/repository/public&quot;</span> &#125;</span><br><span class="line">        maven &#123; name <span class="string">&quot;Bstek&quot;</span> ; url <span class="string">&quot;http://nexus.bsdn.org/content/groups/public/&quot;</span> &#125;</span><br><span class="line">        <span class="built_in">mavenCentral</span>()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    buildscript &#123; </span><br><span class="line">        repositories &#123; </span><br><span class="line">            maven &#123; name <span class="string">&quot;Alibaba&quot;</span> ; url <span class="string">&#x27;https://maven.aliyun.com/repository/public&#x27;</span> &#125;</span><br><span class="line">            maven &#123; name <span class="string">&quot;Bstek&quot;</span> ; url <span class="string">&#x27;http://nexus.bsdn.org/content/groups/public/&#x27;</span> &#125;</span><br><span class="line">            maven &#123; name <span class="string">&quot;M2&quot;</span> ; url <span class="string">&#x27;https://plugins.gradle.org/m2/&#x27;</span> &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>## 1-4 验证### 1-4-1 是否安装成功<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[huser@master bin]$ ./gradle -v</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">------------------------------------------------------------</span></span><br><span class="line"><span class="string">Gradle 4.6.0</span></span><br><span class="line"><span class="string">------------------------------------------------------------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Build time:   2022-10-17 07:44:02 UTC</span></span><br><span class="line"><span class="string">Revision:     a6198e44749b18b37e26b3b3467db17e034bcff4</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Kotlin:       1.4.20</span></span><br><span class="line"><span class="string">Groovy:       2.5.12</span></span><br><span class="line"><span class="string">Ant:          Apache Ant(TM) version 1.10.9 compiled on September 27 2020</span></span><br><span class="line"><span class="string">JVM:          1.8.0_341 (Oracle Corporation 25.341-b10)</span></span><br><span class="line"><span class="string">OS:           Linux 3.10.0-862.el7.x86_64 amd64</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br><div calss='anzhiyu-tag-link'><a class="tag-Link" target="_blank" href="/%5BAzkaban-solo-server%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-%E8%A7%86%E9%A2%91%E6%95%99%E7%A8%8B%5D(https:/mp.weixin.qq.com/s/qNGI1iJVvnrjrz8z83B0Qg)">    <div class="tag-link-tips">引用站外地址</div>    <div class="tag-link-bottom">        <div class="tag-link-left" style="background-image: url(https://vip.helloimg.com/images/2023/12/18/o7labz.jpg)">          <i class="anzhiyufont anzhiyu-icon-link" style="display: none"></i>        </div>        <div class="tag-link-right">            <div class="tag-link-title">Azkaban-solo-server环境搭建</div>            <div class="tag-link-sitename">Azkaban-solo-server环境搭建-视频教程</div>        </div>        <i class="anzhiyufont anzhiyu-icon-angle-right"></i>    </div>    </a></div># 2. [**Azkaban-solo-server**](https://azkaban.readthedocs.io/en/latest/containerization-design.html)安装<div class="note green anzhiyufont anzhiyu-icon-gear modern"><p>简介：solo-server mode（单服务模式）：元数据默认存放在内置的 H2 数据库，该模式中 webServer(管理服务器) 和 executorServer(执行服务器) 运行在同一个进程中，进程名是 AzkabanSingleServer 。该模式适用于小规模工作流的调度，适合用于尝试和了解azkaban的功能。</p></div><div class="note primary simple"><p>需要的安装包： <strong><a href="https://github.com/azkaban/azkaban/releases">azkaban</a>包—-&gt;azkaban-3.57.0.tar.gz</strong></p></div>## 2-1 准备工作### 2-1-1 解压并改名<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf azkaban-3.57.0.tar.gz</span><br><span class="line"><span class="built_in">mv</span> azkaban-3.57.0 azkaban</span><br></pre></td></tr></table></figure>## 2-2 源码编译### 2-2-1 查看Azkaban 依赖 Gradle 版本<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> /opt/azkaban/gradle/wrapper/gradle-wrapper.properties</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># Copyright 2018 LinkedIn Corp.</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not</span></span><br><span class="line"><span class="string"># use this file except in compliance with the License. You may obtain a copy of</span></span><br><span class="line"><span class="string"># the License at</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="string"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT</span></span><br><span class="line"><span class="string"># WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the</span></span><br><span class="line"><span class="string"># License for the specific language governing permissions and limitations under</span></span><br><span class="line"><span class="string"># the License.</span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">distributionBase=GRADLE_USER_HOME</span></span><br><span class="line"><span class="string">distributionPath=wrapper/dists</span></span><br><span class="line"><span class="string">zipStoreBase=GRADLE_USER_HOME</span></span><br><span class="line"><span class="string">zipStorePath=wrapper/dists</span></span><br><span class="line"><span class="string">distributionUrl=https\://services.gradle.org/distributions/gradle-4.6-all.zip</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>### 2-2-2 拷贝对应gradle版本和修改`gradle-wrapper.properties`中的 **distributionUrl 属性**，指明使用本地的 `gradle`<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> gradle-4.6-all.zip /opt/azkaban/gradle/wrapper/</span><br><span class="line">vim /opt/azkaban/gradle/wrapper/gradle-wrapper.properties</span><br><span class="line">修改为：</span><br><span class="line">distributionUrl=gradle-4.6-all.zip</span><br></pre></td></tr></table></figure>### 2-2-3 在安装目录下执行编译命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[huser@master azkaban]$ ./gradlew distTar</span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">BUILD SUCCESSFUL in 25s</span></span><br><span class="line"><span class="string">54 actionable tasks: 5 executed, 49 up-to-date</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>### 2-2-4 报错解决<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Parallel execution with configuration on demand is an incubating feature.</span><br><span class="line"></span><br><span class="line">FAILURE: Build failed with an exception.</span><br><span class="line"></span><br><span class="line">* Where:</span><br><span class="line">Build file <span class="string">&#x27;/opt/azkaban/build.gradle&#x27;</span> line: 41</span><br><span class="line"></span><br><span class="line">* What went wrong:</span><br><span class="line">A problem occurred evaluating root project <span class="string">&#x27;azkaban&#x27;</span>.</span><br><span class="line">&gt; Failed to apply plugin [<span class="built_in">id</span> <span class="string">&#x27;com.cinnober.gradle.semver-git&#x27;</span>]</span><br><span class="line">   &gt; Cannot run program <span class="string">&quot;git&quot;</span> (<span class="keyword">in</span> directory <span class="string">&quot;/opt/azkaban&quot;</span>): error=2, 没有那个文件或目录</span><br><span class="line"></span><br><span class="line">* Try:</span><br><span class="line">Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more <span class="built_in">log</span> output. Run with --scan to get full insights.</span><br><span class="line"></span><br><span class="line">* Get more <span class="built_in">help</span> at https://help.gradle.org</span><br><span class="line"></span><br><span class="line">BUILD FAILED <span class="keyword">in</span> 1s</span><br><span class="line"></span><br><span class="line">解决方案：下载组件，因为linux没有下载git的渠道</span><br><span class="line">sudo yum -y install git</span><br><span class="line">sudo yum -y install gcc-c++</span><br></pre></td></tr></table></figure>## 2-3 Solo Server 模式部署### 2-3-1 解压编译后的`Solo Server`模式安装包,并改名<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/azkaban/azkaban-solo-server/build/distributions/</span><br><span class="line">tar -zxvf azkaban-solo-server-0.1.0-SNAPSHOT.tar.gz -C /opt/</span><br><span class="line"><span class="built_in">mv</span> azkaban-solo-server-0.1.0-SNAPSHOT/ azkaban-solo-serve</span><br></pre></td></tr></table></figure>### 2-3-2 修改时区，进入`conf目录`，修改**azkaban.properties**<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim azkaban.properties</span><br><span class="line">修改为：</span><br><span class="line">default.timezone.id=Asia/Shanghai</span><br></pre></td></tr></table></figure>### 2-3-3 启动，执行启动命令，需要注意的是一定要在根目录下执行，不能进入 `bin目录`下执行，不然会抛出 `Cannot find 'database.properties'` 异常。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[huser@master azkaban-solo-server]$ bin/start-solo.sh </span><br></pre></td></tr></table></figure>### 2-3-4 验证#### 第一种：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">114226</span> AzkabanSingleServer</span><br><span class="line"><span class="number">114238</span> Jps</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"># 如果节点占用端口，如：</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="number">114226</span> AzkabanSingleServer</span><br><span class="line"><span class="number">113927</span> GradleDaemon</span><br><span class="line"><span class="number">110906</span> DataXExecutorApplication</span><br><span class="line"><span class="number">114238</span> Jps</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">就直接卡掉</span><br><span class="line">kill <span class="number">-9</span> <span class="number">113927</span> <span class="number">110906</span></span><br></pre></td></tr></table></figure>#### 第二种：验证方式二：访问 8081 端口，查看 Web UI 界面，默认的登录名密码都是 `azkaban`，如果需要修改或新增用户，可以在 `conf/azkaban-users.xml` 文件中进行配置：<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;azkaban-users&gt;</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">user</span> <span class="attr">groups</span>=<span class="string">&quot;azkaban&quot;</span> <span class="attr">password</span>=<span class="string">&quot;azkaban&quot;</span> <span class="attr">roles</span>=<span class="string">&quot;admin&quot;</span> <span class="attr">username</span>=<span class="string">&quot;azkaban&quot;</span>/&gt;</span></span></span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">user</span> <span class="attr">password</span>=<span class="string">&quot;metrics&quot;</span> <span class="attr">roles</span>=<span class="string">&quot;metrics&quot;</span> <span class="attr">username</span>=<span class="string">&quot;metrics&quot;</span>/&gt;</span></span></span><br><span class="line"></span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">role</span> <span class="attr">name</span>=<span class="string">&quot;admin&quot;</span> <span class="attr">permissions</span>=<span class="string">&quot;ADMIN&quot;</span>/&gt;</span></span></span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">role</span> <span class="attr">name</span>=<span class="string">&quot;metrics&quot;</span> <span class="attr">permissions</span>=<span class="string">&quot;METRICS&quot;</span>/&gt;</span></span></span><br><span class="line">&lt;/azkaban-users&gt;</span><br></pre></td></tr></table></figure><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>Azkaban-solo-server</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MPdC.png" alt="Azkaban-solo-server" title="Azkaban-solo-server"></p><h2 id="2-3-基本任务调度"><a href="#2-3-基本任务调度" class="headerlink" title="2-3 基本任务调度"></a>2-3 基本任务调度</h2><h3 id="2-3-1-新建项目"><a href="#2-3-1-新建项目" class="headerlink" title="2-3-1 新建项目"></a>2-3-1 新建项目</h3><font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>Azkaban 主界面创建一个新项目</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MXMu.png" alt="Azkaban 主界面创建一个新项目" title="Azkaban 主界面创建一个新项目"></p><h3 id="2-3-2-任务配置"><a href="#2-3-2-任务配置" class="headerlink" title="2-3-2 任务配置"></a>2-3-2 任务配置</h3><p>新建任务配置文件 huser.job，内容如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#command.job</span></span><br><span class="line"><span class="built_in">type</span>=<span class="built_in">command</span></span><br><span class="line"><span class="built_in">command</span>=<span class="built_in">echo</span> <span class="string">&#x27;Hello Azkaban,Flow-1.0!xk1181259634!$$$$!  Azkaban &#x27;</span></span><br></pre></td></tr></table></figure><br> 通过 Web UI 界面上传：<br> <font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>Azkaban-solo-server—打包上传</font></p><p><img src="https://vip.helloimg.com/images/2023/12/18/o7M3Xt.png" alt="Azkaban-solo-server--打包上传" title="Azkaban-solo-server--打包上传"></p><h3 id="2-3-4-执行任务，-点击页面上的-Execute-Flow-执行任务："><a href="#2-3-4-执行任务，-点击页面上的-Execute-Flow-执行任务：" class="headerlink" title="2-3-4 执行任务， 点击页面上的 Execute Flow 执行任务："></a>2-3-4 执行任务， 点击页面上的 Execute Flow 执行任务：</h3> <font color=#425aef weight=bolder style='display: flex; justify-content: center; align-items: center;'>Azkaban-solo-server--执行任务</font><p><img src="https://vip.helloimg.com/images/2023/12/18/o7MaVQ.png" alt="Azkaban-solo-server--执行任务" title="Azkaban-solo-server--执行任务"></p><h3 id="2-3-5-执行结果，点击-Log-可以查看到任务的执行日志"><a href="#2-3-5-执行结果，点击-Log-可以查看到任务的执行日志" class="headerlink" title="2-3-5 执行结果，点击 Log 可以查看到任务的执行日志"></a>2-3-5 执行结果，点击 Log 可以查看到任务的执行日志</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-Gradle安装&quot;&gt;&lt;a href=&quot;#1-Gradle安装&quot; class=&quot;headerlink&quot; title=&quot;1. Gradle安装&quot;&gt;&lt;/a&gt;1. &lt;a href=&quot;https://blog.csdn.net/qq_42055933/article/d</summary>
      
    
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    
    <category term="大数据应用" scheme="https://xin0203xin0203.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8/"/>
    
    <category term="HADOOP集群搭建" scheme="https://xin0203xin0203.github.io/tags/HADOOP%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    <category term="Linux" scheme="https://xin0203xin0203.github.io/tags/Linux/"/>
    
  </entry>
  
</feed>
